## Daily Papers (2025-05-05)

### [PixelHacker: Image Inpainting with Structural and Semantic Consistency](https://arxiv.org/abs/2504.20438)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2504.20438.png)

Vote: 23

Authors: Xiaoxin Chen, Ziyang Xu, Wenyu Liu, Xinggang Wang, Kangsheng Duan, Xiaohu Ruan, Zhifeng Ding, Xiaolei Shen

- ***What's New***: PixelHacker는 이미지 복원(Image Inpainting) 분야에서 구조적 일관성과 의미적 일관성을 모두 충족하는 새로운 방식인 잠재 카테고리 가이드(Latent Categories Guidance; LCG)를 제안합니다. PixelHacker는 확산 기반 모델로서, 1400만 개의 이미지-마스크 쌍을 활용하여 훈련하며, 기존의 최신 기법들보다 뛰어난 성능을 보여줍니다.
- ***Technical Details***: PixelHacker는 '전경(foreground)'과 '배경(background)' 레이블에 따라 이미지를 구성하고, 두 개의 고정 크기 임베딩을 통해 전경 및 배경 표현을 각각 인코딩합니다. 선형 주의를 사용하여 구조적 및 의미적 상호작용을 유도하며, 모델이 구조적 및 의미적 일관성을 학습하도록 합니다. 이러한 접근은 텍스트 프롬프트의 품질 저하 문제를 피할 수 있습니다.
- ***Performance Highlights***: PixelHacker는 Places2, CelebA-HQ, FFHQ 등의 다양한 데이터셋에서 최신 기법들보다 뛰어난 성능을 기록하였습니다. 특히, Pixels2 테스트 세트에서는 FID 8.59, LPIPS 0.2026으로 가장 우수한 결과를 보였으며, 훈련된 데이터보다 적은 양의 데이터 셋에서도 뛰어난 일반화 성능을 나타냈습니다.

### [Improving Editability in Image Generation with Layer-wise Memory](https://arxiv.org/abs/2505.01079)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.01079.png)

Vote: 18

Authors: Daneul Kim, Jaeah Lee, Jaesik Park

- ***What's New***: 이 논문은 이미지 생성에서 '층별 메모리(layer-wise memory)'를 사용하여 다중 수정과 위층 요소의 일관된 통합을 지원하는 새로운 프레임워크를 소개합니다. 이는 대규모의 복합 편집 작업에서 컨텍스트를 유지하며 자연스러운 수정 통합을 지원합니다.
- ***Technical Details***: 층별 메모리는 각 편집 단계를 저장하고 편집 기록을 유지하며, 배경 일관성 유도(Background Consistency Guidance)와 다중 쿼리 분리 교차 주의(Multi-Query Disentangled Cross-Attention)를 통해 조정되지 않은 영역을 보호합니다. 또한, 새로운 객체가 기존 콘텐츠와 자연스럽게 통합될 수 있도록 쿼리를 처리합니다.
- ***Performance Highlights***: 이 프레임워크는 기존 이미지 수정 접근 방식에 비해 다중 단계 편집에서 높은 성능을 보여줍니다. 제안된 멀티-에디트 벤치(Multi-Edit Bench) 벤치마크 실험에서 콘텐츠 일관성을 유지하면서도, 사용자 노력을 최소화하고 높은 품질의 결과를 제공합니다. BLD 와 같은 기존의 편집 모델들보다 더 높은 BLEU 및 CLIP 점수를 기록합니다.

### [Beyond One-Size-Fits-All: Inversion Learning for Highly Effective NLG Evaluation Prompts](https://arxiv.org/abs/2504.21117)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2504.21117.png)

Vote: 11

Authors: Hanhua Hong, Wenge Rong, Yang Wang, Chenghao Xiao, Chenghua Lin, Yiqi Liu

- ***What's New***: 이 논문에서는 큼직한 언어 모델(LLM)을 평가하는 새로운 방법으로 역학습(Inversion Learning) 기법을 제안합니다. 이 기법은 모델의 출력에서 입력 정보를 반대로 추론하여 모델별 평가 프롬프트를 자동 생성할 수 있게 합니다. 이를 통해 수작업 프롬프트 엔지니어링의 필요성을 줄이고, 평가 작업의 효율성과 견고성을 향상할 수 있습니다.
- ***Technical Details***: 이 역학습 기법은 모델에서 생성한 출력을 사용하여 해당 출력을 유도한 입력 지시 사항으로의 역함수를 학습합니다. 특히 이 방법은 하나의 평가 샘플만으로도 매우 효과적인 모델 전용 평가 프롬프트를 생성할 수 있습니다. 이 프레임워크는 인버전 모델링과 인버전 프롬팅이라는 두 가지 주요 단계로 구성됩니다.
- ***Performance Highlights***: 제안된 방법을 사용한 인버전 프롬프트는 준지도 학습 된 프롬프트나 인간이 제작한 프롬프트보다 지속적으로 우수한 성능을 보였습니다. Qwen과 LLaMA와 같은 다양한 모델군의 테스트에서 평균적으로 스피어먼 상관계수가 전자와 후자에 비해 각각 33%와 35% 향상되었습니다. 이러한 결과는 모델별 프롬프트가 훨씬 더 효과적임을 보여주며, 수작업 대체의 필요성을 강력히 뒷받침합니다.

### [Real-World Gaps in AI Governance Research](https://arxiv.org/abs/2505.00174)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.00174.png)

Vote: 8

Authors: Ilan Strauss, Tim O'Reilly, Sruly Rosenblat, Isobel Moure

- ***What's New***: 이 논문은 AI 시스템의 배포 이후 단계에 대한 연구가 현저히 부족하다는 것을 강조합니다. 주요 AI 기업들은 모델 정렬과 사전 배포 평가에 집중하고 있으며, 배포 중 발생할 수 있는 고위험 영역에 대한 연구는 감소하고 있는 실정입니다. 헬스케어, 금융, 허위 정보, 설득 및 중독적 특징, 환각, 저작권 등의 분야에서 연구 격차가 존재합니다.
- ***Technical Details***: 본 연구는 2020년 1월부터 2025년 3월까지 주요 AI 기업(Anthropic, Google DeepMind, Meta, Microsoft, OpenAI)과 저명한 AI 연구 대학(CMU, MIT, NYU, Stanford, UC Berkeley, University of Washington)의 생성형 AI 연구 논문 9,439편 중 안전 및 신뢰성 관련 논문 1,178편을 분석한 것이다. 연구는 기업과 학계의 AI 연구 결과를 비교하며, 연구가 주로 모델 성능에 치중되어 있으며, 사후 배포 단계의 이슈는 간과되고 있다고 분석합니다.
- ***Performance Highlights***: Google DeepMind는 일반 생성형 AI 연구에서 상위 네 개의 AI 학계 기관을 합친 것보다 더 많은 인용을 기록했으며, Anthropic과 OpenAI도 높은 연구 영향력을 보여줍니다. 하지만 기업 연구는 주로 모델 정렬 및 평가에 치중되어 있으며, 윤리 및 편향 연구는 주로 학계에서 수행되고 있습니다. 배포 단계의 행동 및 비즈니스 위험에 대한 기업 AI 연구는 극도로 부족하며, 관련 논문은 4%에 불과합니다.

### [Llama-Nemotron: Efficient Reasoning Models](https://arxiv.org/abs/2505.00949)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.00949.png)

Vote: 8

Authors: Nave Assaf, Wasi Uddin Ahmad, Gerald Shen, Aleksander Ficek, Wei Du, Pablo Ribalta, Eric Chung, Nikki Pope, Fei Jia, Jocelyn Huang, Erick Galinkin, Izik Golan, Christine Harvey, Syeda Nahida Akter, Marco Rovinelli, Pedro Larroy, Ying Lin, Zhilin Wang, Shubham Toshniwal, Robert McQueen, Mehrzad Samadi, David Mosallanezhad, Bilal Kartal, Omer Ullman Argov, Deepak Narayanan, Terry Kong, Viji Balas, Eileen Long, Trisha Saar, Zijia Chen, Monika Katariya, Karthik Ramamoorthy, Abhinav Khattar, Parth Chadha, Olivier Delalleau, Guillermo Siman, Boris Ginsburg, Nicholas Edelman, Tugrul Konuk, Yoshi Suhara, Shyamala Prayaga, Haifeng Qian, Mohammad Dabbah, Shrimai Prabhumoye, Oleksii Kuchaiev, Itay Levy, George Lam, Vinh Nguyen, Sanjeev Satheesh, Ido Shahaf, Ivan Moshkov, Branislav Kisacanin, Ran Zilberstein, Jining Huang, Vahid Noroozi, Smita Ithape, Oluwatobi Olabiyi, Andrew Wang, Katherine Luna, Jonah Alben, Ameya Sunil Mahabaleshwarkar, Alexander Bukharin, Scot Junkin, Zach Moshe, Pritam Gundecha, Sahil Jain, Kari Briski, Najeeb Nabwani, Seth Schneider, Jonathan Cohen, Omri Puny, Anna Warno, Rabeeh Karimi, Sean Narenthiran, Oren Tropp, Dan Su, Roger Waleffe, Yonatan Geifman, Jiaqi Zeng, Abhilash Somasamudramath, Daria Gitman, Yuting Wu, John Kamalu, Denys Fridman, Joseph Jennings, Suguna Varshini Velury, Jimmy Zhang, Ehud Karpas, Sandip Bhaskar, Dima Rekesh, Maka Dong, Igor Gitman, Muthu Subramaniam, Krzysztof Pawelec, Yian Zhang, Izzy Putterman, Soumye Singhal, Jane Polak Scowcroft, Sergey Kashirsky, Mostofa Patwary, Akhiad Bercovich, Adi Renduchintala, Manoj Kilaru, Siddhartha Jain, Tomasz Grzegorzek, Leon Derczynski, Bor-Yiing Su, Anahita Bhiwandiwalla, Evelina Bakhturina, Omri Almog, Elad Segal, Jupinder Parmar, Tomer Ronen, Somshubra Majumdar, Sherry Wu, Joyjit Daw, Brandon Norick, Guyue Huang, Ann Guan, Shahar Mor, Kezhi Kong, Ido Galil, Matvei Novikov, George Armstrong, Ran El-Yaniv, Bryan Catanzaro, Arun Venkatesan, Joey Conway, Michael Evans, Markus Kliegl, Oleksandr Romanenko

- ***What's New***: Llama-Nemotron은 새로운 오픈소스 이종 추론 모델 시리즈로, 뛰어난 추론 능력과 추론 효율성을 제공하며, 기업 사용을 위한 개방 라이선스를 갖추고 있습니다. 이 모델은 사용자가 추론 모드를 토글할 수 있는 기능을 최초로 제공합니다.
- ***Technical Details***: Llama-Nemotron 모델은 네 가지 단계로 구성됩니다: Llama 3 모델을 사용한 신경 아키텍처 검색(Neural Architecture Search), 학습된 지식 증류(Knowledge Distillation) 및 지속적인 사전 교육, 지도 학습(Supervised Fine-Tuning), 대규모 강화 학습(Large Scale Reinforcement Learning). 새로운 퍼즐(NAS) 프레임워크를 활용하여 모델을 하드웨어 효율적인 변형으로 변환하며, FFN Fusion이 LN-Ultra 모델에 사용됩니다.
- ***Performance Highlights***: LN-Ultra는 오픈 모델들 가운데 GPQA-Diamond 등의 여러 추론 벤치마크에서 최고 성능을 보였으며, DeepSeek-R1과 비교해 더 높은 추론 처리량을 제공합니다. 다양한 추론 및 비추론 벤치마크에서 다른 오픈소스 모델을 능가하는 성과를 보였습니다.

### [CORG: Generating Answers from Complex, Interrelated Contexts](https://arxiv.org/abs/2505.00023)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.00023.png)

Vote: 5

Authors: Trung Bui, Franck Dernoncourt, Hyunji Lee, Seunghyun Yoon

- ***What's New***: CONTEXT ORGANIZER (CORG)은 복잡하고 상호 연관된 문맥에서의 정답 생성을 위한 새로운 프레임워크로, 문맥을 독립적으로 처리하여 성능과 효율성을 균형 있게 유지합니다. 이는 다양한 관계를 분류하고 그래프 생성기, 재정렬기, 집합기라는 세 가지 주요 컴포넌트를 통해 문맥을 효율적으로 분류하며 모호성을 해결합니다.
- ***Technical Details***: CORG는 복잡한 상호 관계를 그래프로 구성하여 각 문맥 간의 관계를 명확하게 표현합니다. 그래프 생성기는 GPT-4를 사용하여 문맥 간의 관계를 파악하고, 재정렬기는 문맥을 관계 기반으로 그룹화하여 불필요한 문맥을 제거합니다. 최종적으로 집합기는 각 그룹에 대한 인용과 함께 모든 가능한 답변을 생성합니다. 이는 처리 과정을 최적화하여 최소한의 추론 실행으로 높은 답변 검색률과 정확한 모호성 해소를 목표로 합니다.
- ***Performance Highlights***: CORG는 여러 언어 모델 및 여러 평가 세트에서 일관되게 기존 방법을 능가하는 성능을 보여주었습니다. 특히, 복잡한 문맥 관계를 가진 데이터셋에서 대부분의 기준선 모델을 초과하는 성능을 발휘하며, 그룹화 기반 추론을 사용하는 다른 방법들보다 우수하거나 유사한 결과를 나타냈습니다.

### [TeLoGraF: Temporal Logic Planning via Graph-encoded Flow Matching](https://arxiv.org/abs/2505.00562)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.00562.png)

Vote: 2

Authors: Yue Meng, Chuchu Fan

- ***What's New***: TeLoGraF는 신호 시각 논리(Signal Temporal Logic; STL) 명세를 통해 로봇의 복잡한 작업 계획을 학습하는 새로운 접근법을 제시합니다. 이 모델은 그래프 신경망(Graph Neural Network; GNN) 인코더와 흐름 매칭(flow-matching)을 활용하여 일반적인 STL 명세를 처리하고 만족할 수 있는 경로를 생성할 수 있습니다.
- ***Technical Details***: TeLoGraF는 네 가지 일반적으로 사용되는 STL 템플릿을 식별하고, 200K 이상의 다양한 STL 명세를 수집했습니다. 각 STL은 로봇 도메인별로 짝지어진 데모와 함께 제공됩니다. 그래프 신경망(GNN)은 STL 명세를 인코딩하고, 조건부 흐름 매칭 모델은 해당 명세에 대한 경로를 생성합니다. 다양한 인코더 아키텍처를 비교한 결과, GNN이 STL 정보를 내림 흐름 작업에 인코딩하는 데 적합하다는 것을 입증했습니다.
- ***Performance Highlights***: 5개의 시뮬레이션 환경(단순 2D 역동적 모델부터 고차원 Franka Panda 로봇 팔과 Ant 네발보행 탐색에 이르기까지)에서 실험한 결과, TeLoGraF는 STL 만족도에서 다른 기준을 능가했으며, 기존 방식 대비 추론 속도가 10-100배 빠릅니다. GNN 기반 인코더는 최고 품질의 솔루션을 제공하였고, 복잡한 STL 및 분포 외 STL 명세를 처리하는 능력도 보여줬습니다.

### [X-Cross: Dynamic Integration of Language Models for Cross-Domain Sequential Recommendation](https://arxiv.org/abs/2504.20859)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2504.20859.png)

Vote: 2

Authors: Bracha Shapira, Yotam Eshel, Lior Rokach, Haggai Roitman, Guy Hadad

- ***What's New***: X-Cross는 크로스 도메인 순차 추천(Cross-Domain Sequential Recommendation)을 위해 여러 도메인 특정 언어 모델(Domain-Specific Language Models)을 통합하는 새로운 모델을 제안합니다. 이 모델은 로라(LoRA)로 미세 조정된 각 언어 모델을 원래 변경 없이 통합하여 새로운 도메인에 대한 적응력을 향상시킵니다.
- ***Technical Details***: 제안된 X-Cross 모델은 계층별 활성화 세분화 및 통합을 통해 여러 소스 도메인 모델로부터 지식을 동적 통합합니다. 특정 레이어에서는 각 소스 모델의 출력 표현을 결합하여, 모델 간의 상호작용을 고려한 정교한 표현을 만듭니다. 이 과정은 미세 조정된 로라 어댑터를 이용하며, 기본 가중치가 동결된 상태로 진행됩니다.
- ***Performance Highlights***: X-Cross는 아마존 데이터셋에 대해 수행된 실험에서 전통적인 LoRA 모델에 비해 50-75% 적은 훈련 데이터만으로도 경쟁력 있는 성능을 보였으며, 다양한 도메인 간의 적응력도 입증하였습니다. 따라서, 이는 데이터 제약 환경에서의 스케일 가능한 솔루션을 제공합니다.

