## Daily Papers (2025-05-06)

### [Voila: Voice-Language Foundation Models for Real-Time Autonomous Interaction and Voice Role-Play](https://arxiv.org/abs/2505.02707)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.02707.png)

Vote: 56

Authors: Yu Shu, Guangyi Liu, Zhiting Hu, Yemin Shi, Jaward Sesay, Jingwen Li, Siwei Dong

- ***What's New***: Voila는 자율적 상호작용과 음성 롤플레이(Voice Role-Play)를 위한 실시간 음성-언어 기반 모델(Voice-Language Foundation Models)으로, 인간과의 자연스럽고 감정 표현이 풍부한 상호작용을 지원합니다. 전통적인 파이프라인 시스템을 넘어 새로운 종단간(end-to-end) 아키텍처를 채택하여 저지연의 실시간 대화를 가능하게 하며, 톤, 리듬, 감정과 같은 음성의 세부 뉘앙스를 보존합니다.
- ***Technical Details***: Voila는 음성-언어 변환을 위해 계층적 다중 스케일 트랜스포머(Multi-scale Transformer) 아키텍처를 사용하여, 대형 언어 모델(LLM)의 추론 기능과 강력한 음향 모델링 기능을 통합합니다. 이 모델은 108개의 파이썬 코딩 작업으로 구성된 HumanEval-V 벤치마크를 기반으로 하며, 사용자가 화자의 정체성, 톤 등을 정의할 수 있는 텍스트 지시를 활용하여 자연스러운 음성 생성을 지원합니다. Voila는 100만 이상의 사전 구축된 음성을 제공하며, 짧게는 10초의 오디오 샘플을 통해 새로운 음성을 효율적으로 사용자화합니다. ASR, TTS 및 다국어 음성 번역과 같은 다양한 음성 기반 애플리케이션을 통합한 모델로 설계되었습니다.
- ***Performance Highlights***: Voila는 최근의 오디오-언어 모델인 SpeechGPT 및 Moshi를 상회하는 성능을 보여주며, 수학 및 코드 도메인에서 특히 큰 발전을 보였습니다. 자동 음성 인식(ASR)에서는, Voila는 Whisper 모델과 유사한 WER를 가지며, 음성 합성(TTS)에서도 Voila는 3.2%의 WER을 보여주어 경쟁 모델보다 우수한 성능을 나타냅니다.

### [RM-R1: Reward Modeling as Reasoning](https://arxiv.org/abs/2505.02387)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.02387.png)

Vote: 44

Authors: Hongru Wang, Hanghang Tong, Bowen Jin, Ziqi Wang, Xiusi Chen, Gaotang Li, Yu Wang, Heng Ji, Denghui Zhang, Cheng Qian, Yu Zhang, Tong Zhang

- ***What's New***: 이 연구는 보상 모델(Reward Model; RM)을 이해 가능한 방식으로 설계하여 인간의 선호에 맞게 대형 언어 모델(LLM)을 조정하는 새로운 방법을 제안합니다. 기존의 보상 모델은 불투명한 평가 방식을 가졌으나, REASRMS라는 새로운 클래스의 생성형 보상 모델을 통해 명확한 추론 과정을 통합하여 성능과 해석 가능성을 향상시켰습니다.
- ***Technical Details***: 제안된 REASRMS는 추론 중심의 훈련 파이프라인을 채택하여 RM-R1 형태의 보상 모델을 개발했습니다. 주요 훈련 단계는 고품질 추론 체인의 증류와 검증 가능한 보상을 활용한 강화 학습(RL)입니다. 모델은 주어진 문맥에서 자체적인 추론 기록이나 채팅 특화 규칙을 생성하고, 이를 바탕으로 후보 응답을 평가합니다.
- ***Performance Highlights***: 실험 결과에 따르면, RM-R1 모델은 다수의 보상 모델 벤치마크에서 현재까지의 최첨단 성능을 기록하며, 더 큰 규모의 모델보다 최대 13.8% 더 우수한 성능을 보여줍니다. 이는 특히 추론이 중시되는 환경에서 보상 모델링의 새로운 가능성을 열어줍니다.

### [Grokking in the Wild: Data Augmentation for Real-World Multi-Hop Reasoning with Transformers](https://arxiv.org/abs/2504.20752)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2504.20752.png)

Vote: 41

Authors: Felix Steinbauer, Roman Abramov, Gjergji Kasneci

- ***What's New***: 이 논문은 Transformer 기반 모델의 다중 단계 사실 추론 능력을 개선하기 위해 실제 환경에서의 데이터 희소성 문제를 해결하는 새로운 데이터 증강 방법을 제안합니다. 기존 지식 그래프를 신중하게 설계된 합성 데이터로 보완함으로써 'grokking' 현상을 실제 데이터에서 달성합니다.
- ***Technical Details***: 제안된 방법은 기존 지식 그래프를 기반으로 신속하게 사실을 추정할 수 있는 비율(ϕ)을 증가시키기 위해 합성 데이터를 추가합니다. 잘못된 합성 데이터조차도 모델이 암기보다는 관계 구조에 의존하게 만들어, 추론 회로가 더 쉽게 형성되도록 돕습니다. Transformer 모델은 2WikiMultiHopQA라는 다중 홉 추론 벤치마크에서 테스트되었으며, 데이터 증강 전략의 효과가 확인되었습니다.
- ***Performance Highlights***: 이 방법은 2WikiMultiHopQA 데이터 세트에서 최고 95-100%의 정확도를 달성했으며, 이는 강력한 기존 기준선보다 뛰어난 성능입니다. 이는 현재 최고 수준을 유지하거나 초과하는 성능을 보입니다. 특히, 합성 데이터를 통한 추론 비율(ϕ)의 증가가 어떻게 Transformer 내부에서 일반화 회로 형성에 기여하는지를 상세히 분석하였습니다.

### [Practical Efficiency of Muon for Pretraining](https://arxiv.org/abs/2505.02222)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.02222.png)

Vote: 27

Authors: Ashish Tanwer, Anil Thomas, Andrew Ma, Platon Mazarakis, Peter Rushton, Ashish Vaswani, Ritvik Kapila, Saurabh Srivastava, Tim Romanski, Adarsh Chaluvaraju, Somanshu Singla, Darsh J Shah, Ishaan Shah, Andrew Hojel, Kurt Smith, Karl Stratos, Khoi Nguyen, Mohit Parmar, Yash Vanjani, Michael Pust, Philip Monk, Michael Callahan, Anthony M. Polloreno, Essential AI

- ***What's New***: 이 논문에서는 Muon이라는 새로운 2차 옵티마이저(optimizer)가 AdamW를 능가하여 더 높은 데이터 효율성과 대용량 배치에서의 연산 효율성을 제공하며, 학습 과정에서의 비용 절감까지 가능하다는 점을 보여줍니다.
- ***Technical Details***: Muon은 SVD(Singular Value Decomposition)의 명시적 계산을 피하는 Newton-Schulz 반복 과정을 사용하여 아담(Ada) 변화 대신 사용됩니다. Nesterov 모멘텀(momentum) 및 학습률 스케일링을 통해 Muon은 AdamW와 유사한 RMS 값을 유지합니다. 또한, Muon은 최적의 하이퍼파라미터 전환을 위해 muP(Maximal Update Parameterization)와 결합되어 실용적이고 경제적인 하이퍼파라미터 탐색을 허용합니다.
- ***Performance Highlights***: Muon은 다양한 모델 규모와 데이터 셋에서 상당한 학습 시간 감소와 빠른 벽시간(wall-clock) 수렴을 통해 AdamW를 능가했습니다. 특히, 동일한 손실에 도달하기 위해 AdamW보다 10-15% 적은 토큰을 필요로 하는 것으로 나타났습니다.

### [FormalMATH: Benchmarking Formal Mathematical Reasoning of Large Language Models](https://arxiv.org/abs/2505.02735)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.02735.png)

Vote: 20

Authors: Minghao Liu, Wenhao Huang, Yizhe Li, Keyi Ding, Zhongyuan Peng, Ge Zhang, Yandong Wen, Yifan Zhang, Zheng Yuan, Huajian Xin, Zhouliang Yu, Weiyang Liu, Ruotian Peng

- ***What's New***: FormalMATH는 대형 언어 모델(Large Language Models; LLMs)의 형식 수학적 추론 능력을 평가하기 위해 Lean4 기반의 대규모 벤치마크를 소개합니다. 이는 다양한 수학적 도메인과 난이도를 포함하여 5,560개의 형식적으로 검증된 문제로 구성되어 있으며, 고등학교 올림피아드 문제부터 학부 수준의 정리까지 포괄합니다.
- ***Technical Details***: 형식적 수학 검증의 비효율성을 해결하기 위해, Human-in-the-loop 기반의 autoformalization 파이프라인을 도입했습니다. 이는 (1) LLM을 이용한 문장 자동 formalization, (2) 다중 LLM semantic verification, 그리고 (3) 반증 기반의 negation filtering 전략을 포함하고 있습니다. 이 방법은 번역 전 step에서 72.09%의 진술을 보존하면서도 전문가 검증의 비용을 대폭 절감합니다.
- ***Performance Highlights***: 최신 LLM 기반 정리 증명기(prover)를 평가한 결과, 현재 모델들은 실용적인 샘플링 기준 하에 16.46%라는 낮은 성공률을 보였습니다. 특히, 특정 수학 도메인(예: 대수학)에서 두드러진 성과를 보였지만, 미적분학에서는 미약한 성능을 보이며 도메인간 일반화의 한계를 드러냈습니다. 또한 자연어 솔루션 지침이 오히려 증명 성공률에 부정적 영향을 미치며, 이는 CoT 시나리오에서 명확성보다 불확실성을 초래함을 시사했습니다.

### [ReplaceMe: Network Simplification via Layer Pruning and Linear Transformations](https://arxiv.org/abs/2505.02819)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.02819.png)

Vote: 19

Authors: Sergey Zagoruyko, Nikos Komodakis, Valentin Malykh, Ammar Ali, Dmitriy Shopkhoev, Magauiya Zhussip, Stamatios Lefkimmiatis

- ***What's New***: ReplaceMe는 트랜스포머 블록을 선형 변환(Linear Transformation)으로 대체하는 새로운 트레이닝 프리(Training-Free) 방법으로, 적은 압축 비율에서도 높은 성능을 유지합니다. 이는 추가 트레이닝이나 미세 조정 없이 소량의 보정 데이터셋으로만 변환을 예측해, 새로운 네트워크 파라미터 없이 통합됩니다.
- ***Technical Details***: ReplaceMe는 트랜스포머 모델에서 최소한의 성능 영향을 미치는 레이어를 선택적으로 제거하고, 제거된 레이어의 기여를 보상하기 위해 최적의 선형 변환을 계산합니다. 변환은 선형 회귀(Linear Regression)를 통해 추정되며, 이는 기존 모델의 가중치와 통합되어 추가 파라미터를 도입하지 않습니다.
- ***Performance Highlights***: ReplaceMe는 현재의 훈련 요구사항 없이도 25%의 레이어를 프루닝(Pruning)하여 Llama 2 7B 기반 모델에서 약 92.5%의 성능을 유지합니다. 경쟁 모델과 비교시에는 시간, 에너지소비 및 CO2 배출 등의 지표에서 월등한 효율성을 보였습니다.

### [Optimizing Chain-of-Thought Reasoners via Gradient Variance Minimization in Rejection Sampling and RL](https://arxiv.org/abs/2505.02391)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.02391.png)

Vote: 19

Authors: Yifan Hao, Tong Zhang, Jiarui Yao, Nan Jiang, Hanze Dong, Wei Xiong, Hanning Zhang

- ***What's New***: 이 논문에서는 거절 표본 추출(Rejection Sampling)와 강화 학습(RL)에서의 경사 분산 최소화(Gradient Variance Minimization)를 통한 생각의 사슬(Chain-of-Thought; CoT) 추론자의 최적화 방법인 GVM-RAFT를 제안하며, 이는 CoT 훈련의 주요 병목 현상을 해결하고자 합니다.
- ***Technical Details***: GVM-RAFT는 주어진 계산 예산 내에서 확률적 경사도의 분산을 최소화하기 위해 동적 샘플 할당 전략(Dynamic Sample Allocation Strategy)을 도입합니다. 이는 프롬프트 수락 비율과 확률적 경사 규범을 모니터링하여 계산 자원을 동적으로 할당합니다. 이 방법은 이론적 분석을 통해 적절한 조건 하에서 수렴을 가속화하는 것으로 보장됩니다.
- ***Performance Highlights***: 수학적 추론 실험에서 GVM-RAFT는 기본 RAFT 대비 2-4배의 속도 향상 및 상당한 정확도 개선을 달성했습니다. 제안된 동적 샘플링 전략은 일반적이며 GRPO와 같은 다른 RL 알고리즘에서도 유사한 개선을 가져옵니다.

### [A Survey on Inference Engines for Large Language Models: Perspectives on Optimization and Efficiency](https://arxiv.org/abs/2505.01658)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.01658.png)

Vote: 19

Authors: Seokhun Jeon, Byung-Soo Kim, Sungryeol Jeon, Chaelyn Lee, Sihyeong Park, Jemin Lee

- ***What's New***: 본 논문은 대형 언어 모델(LLM)들의 추론 엔진(Inference Engine)을 최적화 및 효율성 측면에서 평가한 최초의 종합적 연구로서, 25개의 오픈 소스 및 상용 추론 엔진들을 심층 분석하였습니다. 주목할 만한 새로운 요소는 대규모 서비스 환경에 최적화를 들어간 여러 추론 엔진이 나타났다는 점입니다.
- ***Technical Details***: 이 논문에서는 각 추론 엔진의 사용자 편의성, 배포 용이성, 범용성 지원, 확장성, 처리량 및 대기 시간 최적화 능력을 평가하였습니다. 대표적인 최적화 기법에는 페이지드 어텐션(PagedAttention), 연속 배칭(Continuous Batching), 스페큘레이티브 디코딩(Speculative Decoding), 그리고 다양한 병렬 처리 기법이 포함됩니다.
- ***Performance Highlights***: 테스트 결과, 상용 엔진들에서 특히나 NVIDIA GPU를 최대한 활용하여 높은 처리량과 낮은 지연 시간을 달성함을 확인했습니다. 주요 엔진들은 각기 다른 하드웨어와 유연하게 결합하여 최적의 성능을 제공하며, 멀티 라인 텍스트 또는 복합 언어 처리를 수월하게 처리할 수 있는 기능을 갖추고 있습니다.

### [R1-Reward: Training Multimodal Reward Model Through Stable Reinforcement Learning](https://arxiv.org/abs/2505.02835)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.02835.png)

Vote: 17

Authors: Xiao Hu, Tianke Zhang, Changyi Liu, Kaiyu Tang, Kaibing Chen, Jiankang Chen, Liang Wang, Haojie Ding, Zhang Zhang, Bin Wen, Yi-Fan Zhang, Tingting Gao, Chaoyou Fu, Kaiyu Jiang, Fan Yang, Xingyu Lu

- ***What's New***: R1-Reward는 강화 학습(Reinforcement Learning; RL)을 통해 멀티모달 보상 모델(Multimodal Reward Models; MRMs)을 훈련하는 새로운 접근 방식을 제안합니다. 기존의 RL 알고리즘의 한계를 극복하기 위해 StableReinforce 알고리즘을 도입하여 훈련의 안정성을 높이고 성능을 강화시킵니다. 이 연구는 MRMs의 보상 모델링 성능을 장기적 추론 능력을 통해 크게 개선합니다.
- ***Technical Details***: StableReinforce 알고리즘은 전통적인 RL 방법의 훈련 손실, 이점(estimation) 전략을 재정비하고, 보상 설계를 개선하여 훈련 안정성을 향상시킵니다. 이 알고리즘은 MLLMs와 200K의 다양한 데이터셋에서 수집된 선호 데이터로 학습된 R1-Reward 보상 모델을 통해 성능 개선을 달성합니다. 보상 기능 설계에서 모델의 추론 과정과 최종 결과의 일관성을 평가하는 MLLM을 심판으로 이용하여 더 정확하고 논리적인 의사 결정을 촉진합니다.
- ***Performance Highlights***: R1-Reward는 VL Reward Bench에서 8.4%, Multimodal Reward Bench에서 14.3%의 성능 향상을 달성하며, 테스트 시간이 증가할수록 성능이 더욱 향상되는 스케일링 가능성을 보입니다. 모두 15개의 샘플로 투표를 실시할 때 MM-RLHF Reward Bench에서 86.47%의 정확도를 기록하며, 이는 기존 모델을 크게 능가하는 성과입니다.

### [Agentic Reasoning and Tool Integration for LLMs via Reinforcement Learning](https://arxiv.org/abs/2505.01441)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.01441.png)

Vote: 17

Authors: Akshay Nambi, Yash Pandya, Joykirat Singh, Raghav Magazine

- ***What's New***: ARTIST는 에이전트 방식의 추론(Agentic Reasoning), 강화 학습(Reinforcement Learning), 그리고 도구 통합(Tool Integration)을 통합한 프레임워크로, LLMs가 자율적으로 도구를 활용하여 복잡한 문제를 해결할 수 있도록 지원합니다. 이를 통해 기존 모델들이 내부 지식에만 의존하는 한계에서 벗어나, 외부의 도구와 환경을 적극적으로 활용할 수 있는 새로운 방식을 제시합니다.
- ***Technical Details***: ARTIST는 결과 기반 강화 학습(Outcome-based RL)을 활용하여 LLMs가 도구를 언제, 어떻게 호출할지를 스스로 결정할 수 있도록 학습합니다. 이 프레임워크는 내부 추론과 도구 호출을 반복하며, 각 단계에서 어떤 도구를 호출할지, 호출 시점을 결정하고, 도구의 출력 결과를 추론 과정에 통합합니다. 또한, Group Relative Policy Optimization(GRPO) 알고리즘을 사용하여 효율적이고 안정적인 결과 기반 강화 학습을 구현하고, 도구와 환경 통합을 통한 에이전트적 상호작용을 캡처합니다.
- ***Performance Highlights***: ARTIST는 수학적 문제 해결과 다중 턴 기능 호출 벤치마크에서 기존 최첨단 모델 대비 최대 22% 이상의 성능 향상을 보여줍니다. 특히, 복잡한 문제일수록 장점이 두드러지며, 상황에 맞는 다단계 추론과 도구 활용이 가능한 점에서 타 접근법을 뛰어넘습니다. Frontier LLMs와 비교할 때, GPT-4o보다 모든 평가 기준에서 높은 성능을 기록하며, 외부 도구와의 통합이 이루어진 오픈소스 모델에 비해서도 두 자릿수의 성능 향상을 달성했습니다.

### [Think on your Feet: Adaptive Thinking via Reinforcement Learning for Social Agents](https://arxiv.org/abs/2505.02156)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.02156.png)

Vote: 16

Authors: Yongbin Li, Haiyang Yu, Nan Xu, Wenji Mao, Haobo Wang, Bingli Wu, Xinghua Zhang, Fei Huang, Minzheng Wang

- ***What's New***: 이 논문은 사회적 에이전트(Social Agents)에 대한 강화 학습(Adaptive Thinking)의 새로운 접근 방식인 Adaptive Mode Learning (AML)을 소개합니다. 이 프레임워크는 네 가지 사고 모드(직관적 반응부터 심층적 숙고까지)를 실시간 상황에 따라 전략적으로 선택할 수 있도록 설계되었습니다.
- ***Technical Details***: AML의 핵심은 Adaptive Mode Policy Optimization (AMPO) 알고리즘으로, 이 방법은 다중-그레뉴어(thinking mode design) 사고 모드 설계, 사회적 상호작용 전반에 걸친 상황 인식 모드 전환, 그리고 깊이 적응형 처리(depth-adaptive processing)를 통한 토큰 효율적인 추론을 포함하고 있습니다. 이 알고리즘은 RL(강화 학습) 기반 적응적 사고 모드 향상을 위해 사고 모드와 샘플 수준 정보를 활용하여 상황에 민감한 사고 모드 전환을 강화합니다.
- ***Performance Highlights***: AML은 최신 기법 대비 과업 수행률이 15.6% 향상되었으며, GRPO와 비교하여 32.8% 더 짧은 추론 체인을 사용하면서 성능이 7.0% 향상되었습니다. 이러한 결과는 AMPO의 컨텍스트 감지 사고 모드 선택이 인간과 같은 적응적 추론을 가능하게 함을 보여줍니다.

### [SkillMimic-V2: Learning Robust and Generalizable Interaction Skills from Sparse and Noisy Demonstrations](https://arxiv.org/abs/2505.02094)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.02094.png)

Vote: 14

Authors: Qifeng Chen, Yinhuai Wang, Ping Tan, Hok Wai Tsui, Runyi Yu, Jingbo Wang, Qihan Zhao

- ***What's New***: SkillMimic-V2는 결함이 있는 데몬스트레이션에서도 로봇이 강력하고 일반화 가능한 상호작용 기술을 학습할 수 있도록 지원하는 최신 프레임워크입니다. 시뮬레이트된 로봇을 통해 희소하고 잡음이 많은 데모로부터 상호작용 기술을 효과적으로 학습할 수 있도록 두 가지 데이터 증가 기술을 결합한 것입니다.
- ***Technical Details***: 이 논문에서 제안하는 두 가지 데이터 증가 기술은 Stitched Trajectory Graph (STG)와 State Transition Field (STF) 입니다. STG는 데모 간의 잠재적 전환을 발견하고, STF는 데모 주변 상태 내에서 고유 연결을 수립합니다. 이를 강화 학습 상호작용 데모(RLID)와 결합하여 기술 학습을 위한 최적의 트레이닝 시스템을 구성합니다. Adaptive Trajectory Sampling (ATS) 전략을 도입해 난이도에 따라 샘플링 확률을 조정하여 어려운 샘플 학습을 균형 있게 합니다.
- ***Performance Highlights***: 다양한 상호작용 작업에서의 폭넓은 실험은 기존 최첨단 방법에 비해 수렴 안정성, 일반화 역량, 복구 강인성 면에서 실질적인 개선을 보여주었습니다. 특히 성공률에서 평균적으로 40-50% 향상, 일반화 성능이 35% 이상 개선된 것을 확인할 수 있었습니다. 이런 성과는 결함이 있는 데모에서도 뛰어난 성능을 발휘하는 데이터 증가 기법의 효율성을 입증합니다.

### [Ming-Lite-Uni: Advancements in Unified Architecture for Natural Multimodal Interaction](https://arxiv.org/abs/2505.02471)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.02471.png)

Vote: 9

Authors: Xinyu Xiao, Jianxin Sun, Jingdong Chen, Kaixiang Ji, Junbo Zhao, Rui Liu, Cheng Zou, Dandan Zheng, Hu Yu, Biao Gong, Libin Wang, Lixiang Ru, Qingpei Guo, Ziyuan Huang, Jun Zhou, Weilong Chai

- ***What's New***: Ming-Lite-Uni는 통합된 비전과 언어를 위한 새로운 오픈 소스 멀티모달 프레임워크로, MetaQueries와 M2-omni 프레임워크를 통합 구현하고 다중 스케일 학습 가능한 토큰과 다중 스케일 표현 정렬 전략을 도입하였습니다. 이를 통해 텍스트 기반 이미지 생성뿐만 아니라 지시 기반 이미지 편집 작업도 수행할 수 있습니다.
- ***Technical Details***: Ming-Lite-Uni는 고정된 다중모달 언어 모델(MLLM)과 학습 가능한 확산 모델을 결합하여 여러 해상도의 이미지 이해 및 생성을 촉진하는 다중 스케일 학습 가능한 쿼리 토큰과 다중 스케일 표현 정렬 전략을 도입하였습니다. 이러한 방법을 통해 오토리그레시브 모델은 텍스트에서 이미지로의 생성 및 지시 기반 이미지 편집에서 강력한 문맥 가이드를 제공합니다.
- ***Performance Highlights***: Ming-Lite-Uni는 다양한 멀티모달 이해와 텍스트-이미지 생성 작업에서 강력한 성능을 보이며, 특히 GenEval 벤치마크에서 0.62의 전체 정확도를 기록하여 다른 유니파이드 이나 생성 전용 방법들보다 우수한 성능을 시연하였습니다.

### [SuperEdit: Rectifying and Facilitating Supervision for Instruction-Based Image Editing](https://arxiv.org/abs/2505.02370)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.02370.png)

Vote: 9

Authors: Xin Gu, Fan Chen, Xiaoying Xing, Chen Chen, Longyin Wen, Sijie Zhu, Ming Li

- ***What's New***: SuperEdit는 주어진 이미지 쌍에 대해 보다 효과적인 편집 지침을 구성함으로써 기존의 이미지 편집 모델의 잡음 많은 지도 신호 문제를 해결합니다. 이 모델은 편집 지침을 원본 편집 이미지 쌍에 더 잘 맞도록 수정하고, 대조적 편집 지침을 사용하여 모델 학습에 트리플렛 손실을 도입하여 지도 효과를 증대시킵니다.
- ***Technical Details***: SuperEdit는 사전 학습된 비전-언어 모델(Vision-Language Models; VLMs)을 이용해 편집 지침을 수정하고, 일관된 지도 신호를 제공합니다. 대조적 지도 신호 구축을 통해 긍정적 및 부정적 편집 지침을 도입하며, 트리플렛 손실을 활용하여 모델 학습을 강화합니다. GPT-4o를 통해 다단계 비교 분석을 수행하고, 수정된 지침은 Python 사전에 저장하여 일관된 형식으로 관리합니다.
- ***Performance Highlights***: SuperEdit는 적은 양의 높은 품질의 편집 데이터를 사용하여 기존 최첨단 방법보다 9.19% 개선된 성능을 보입니다. Real-Edit 벤치마크에서 30배 적은 데이터와 13배 작은 모델 크기로 모든 평가 메트릭에서 가장 높은 점수를 기록했습니다. 실험 결과는 SuperEdit가 효율적이고 정확한 지도를 제공하여 기존 방법을 넘어선 성능을 달성했음을 입증합니다.

### [Low-Precision Training of Large Language Models: Methods, Challenges, and Opportunities](https://arxiv.org/abs/2505.01043)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.01043.png)

Vote: 9

Authors: Yonggang Wen, Guoxia Wang, Yong Luo, Zhiwei Hao, Han Hu, Jianyuan Guo, Dianhai Yu, Li Shen, Dacheng Tao

- **What's New**: 이 논문은 대용량 언어 모델(Large Language Models, LLMs)의 효율성과 확장성을 개선하기 위해 활용되는 저정밀도 훈련(Low-Precision Training)에 대한 포괄적인 리뷰를 제공합니다. 특히, 고정소수점(fixed-point), 부동소수점(floating-point) 및 맞춤형 형식(customized format) 기반의 훈련 기법을 세부적으로 분류하여 연구 현황을 정리하였습니다.
- **Technical Details**: 기술적으로, 본 논문은 저정밀도 훈련 기법을 크게 고정소수점 및 정수 기반 방법(fixed-point and integer-based methods), 부동소수점 기반 방법(floating-point-based methods) 그리고 맞춤형 포맷 기반 방법(customized format-based methods)으로 분류합니다. 각 방법론의 수학적 표현 및 하드웨어 지원까지 상세히 서술하며, 양자화 인식 훈련(Quantization-Aware Training; QAT) 기법, 시스템 레벨에서의 지원 방안도 논의됩니다.
- **Performance Highlights**: 현대 하드웨어는 저정밀도 연산에 최적화되고 있으며, 이를 통해 16비트 및 8비트 연산에서의 상당한 속도 향상을 제공합니다. 예를 들어, NVIDIA Hopper 아키텍처는 FP8 지원을 도입하여 초저정밀도(ultra-low-precision) 훈련을 위한 중요한 진전을 이루었습니다. 이러한 기술은 대규모 모델을 보다 재빠르고 효율적으로 훈련할 수 있도록 합니다.

### [LLaMA-Omni2: LLM-based Real-time Spoken Chatbot with Autoregressive Streaming Speech Synthesis](https://arxiv.org/abs/2505.02625)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.02625.png)

Vote: 8

Authors: Yan Zhou, Shoutao Guo, Qingkai Fang, Shaolei Zhang, Yang Feng

- ***What's New***: LLaMA-Omni 2는 실시간 고품질 음성 상호작용을 가능하게 하기 위해 0.5B에서 14B 파라미터로 구성된 음성 언어 모델(Speech Language Models; SpeechLMs)를 소개합니다. 기존 GLM-4-Voice와 같은 최첨단 모델에 비해 훈련 시간과 데이터 필요량을 대폭 감소시켰음에도 여러 음성 이해 및 지시 수행 벤치마크에서 더욱 우수한 성능을 보여줍니다.
- ***Technical Details***: LLaMA-Omni 2는 Qwen2.5 기반의 LLM을 사용하며, Whisper의 인코더를 음성 인코더로 채택했습니다. 스트리밍 음성 생성을 위해 CosyVoice 2에서 영감을 받아 오토리그레시브 텍스트-음성 언어 모델과 원인별 흐름 매칭 모델을 사용했습니다. 200K 다중 회전의 음성-음성 대화 샘플을 통해 모델을 훈련시켜 텍스트와 음성 질감의 일관성을 유지하며 스트리밍 생성을 성공적으로 구현했습니다.
- ***Performance Highlights***: LLaMA-Omni 2는 음성 질문응답과 음성 지시수행 작업에서 이전의 LLaMA-Omni 및 GLM-4-Voice를 능가했습니다. 특히, LLaMA-Omni2-14B는 실시간 상호작용 요구사항을 충족시키며 응답 지연 시간을 600ms 미만으로 유지합니다. 이러한 성능은 적은 양의 훈련 데이터와 모델 파라미터에서 더욱 두드러집니다.

### [TEMPURA: Temporal Event Masked Prediction and Understanding for Reasoning in Action](https://arxiv.org/abs/2505.01583)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.01583.png)

Vote: 6

Authors: Jenq-Neng Hwang, Hou-I Liu, Cheng-Yen Yang, Yi-Ling Chen, Kuang-Ming Chen, Wenhao Chai, Vibhav Vineet, Jen-Hao Cheng, Qin Cai, Huapeng Zhou, Yi-Hao Peng, Vivian Wang, Huayu Wang, Hsiang-Wei Huang

- ***What's New***: TEMPURA는 영상 내 사건 이해와 추론 능력을 향상시키기 위해 개발된 새로운 두 단계 학습 파이프라인으로, 영상의 시간적 이해를 강화합니다. 또한 50만 개의 비디오와 밀도 높은 사건 캡션으로 구성된 대규모 데이터셋 VER를 새롭게 제안하였습니다.
- ***Technical Details***: TEMPURA는 두 가지 주요 학습 단계를 거칩니다. 첫 번째 단계는 Masked Event Prediction으로, 비디오 LMM이 비디오 맥락 내에서 누락된 사건을 추론하고 인과성을 파악할 수 있도록 합니다. 두 번째 단계는 Video Segmentation and Dense Captioning으로, 비디오를 정확하게 나누고 타임스탬프가 있는 상세한 설명을 제공하여 비디오 LLM의 시간적 이해를 강화합니다.
- ***Performance Highlights***: TEMPURA는 Charades-STA 벤치마크에서 mIoU 39.2로 기존 모델보다 6.3포인트 더 높은 성능을 보였으며, QVHighlights 데이터셋에서 HIT@1 점수 51.7을 기록했습니다. 이는 기존 모델을 크게 능가하는 결과로, TEMPURA의 학습된 시간적 이해 능력이 다양한 비디오 이해 작업에 쉽게 적응할 수 있음을 보여줍니다.

### [MUSAR: Exploring Multi-Subject Customization from Single-Subject Dataset via Attention Routing](https://arxiv.org/abs/2505.02823)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.02823.png)

Vote: 3

Authors: Chong Mou, Songtao Zhao, Zinan Guo, Yanze Wu, Pengze Zhang, Qian He

- ***What's New***: MUSAR는 단일 주제 데이터 셋에서 다중 주제 커스터마이즈를 가능하게 하는 새로운 프레임워크입니다. 이 방법은 주어진 단일 주제 데이터에서 쌍화법(diptych) 학습을 통해 데이터 부족 문제를 해결하며, 동적 주의 라우팅(Dynamic Attention Routing) 메커니즘을 도입해 교차 주제 속성 얽힘을 해결합니다. 이 접근 방식은 단순한 데이터만으로 다중 주제 커스터마이즈의 확장성을 제공합니다.
- ***Technical Details***: MUSAR는 두 가지 주요 전략을 사용하여 구현됩니다: (1) 정적 주의 라우팅(Static Attention Routing) 및 이중 분기 LoRA(Dual-branch LoRA)를 통해 쌍화법 데이터로 인한 편향을 줄이고, 각 조건에 따라 이미지를 동적으로 매핑하는 기법을 제공합니다. (2) 동적 주의 라우팅에서는 각 이미지 영역이 대응하는 주제를 할당받으며, 교차 주제 간섭을 선택적 주의 마스킹으로 제거합니다.
- ***Performance Highlights***: MUSAR는 단일 주제 데이터로만 훈련되었음에도 불구하고, 기존의 복수 주제 데이터 셋을 이용한 방법들보다 이미지 품질, 주제 일관성 및 상호작용 자연스러움에서 뛰어난 성능을 나타냅니다. 실험결과는 다양한 시나리오에 대한 주제 식별 및 속성 보존에서 탁월한 능력을 보여주었습니다.

### [WorldGenBench: A World-Knowledge-Integrated Benchmark for Reasoning-Driven Text-to-Image Generation](https://arxiv.org/abs/2505.01490)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.01490.png)

Vote: 3

Authors: Yutian Lu, Ruoshi Xu, Zijian Jin, Shengda Luo, Che Jiang, Liang Yong, Jianguo Zhang, Biaoxiang Chen, Jiebo Luo, Daoan Zhang

- ***What's New***: WorldGenBench는 텍스트에서 이미지 생성 모델(Text-to-Image Generation)을 위한 새로운 벤치마크로, 텍스트-이미지 생성 과정에서 필요한 세계적 지식(World Knowledge)과 암묵적 추론(Implicit Reasoning)에 초점을 맞추고 있습니다. 이 벤치마크는 인문학과 자연학 과제를 포함하여, 모델들이 얼마나 이러한 지식을 활용하며 정확한 이미지를 생성할 수 있는지를 평가합니다.
- ***Technical Details***: WorldGenBench는 GPT-4o와 같은 최첨단 비전-언어 모델을 활용하여 생성된 이미지가 체크리스트(Checklist) 항목을 얼마나 충족하는지를 측정함으로써 모델을 평가합니다. 체크리스트는 각 텍스트-이미지 프롬프트에서 요구되는 특정 속성을 나타내며, 만족된 항목의 비율을 기반으로 모델의 전반적인 세계 지식 및 암묵적 추론 기술을 평가합니다. Humanities와 Nature 두 가지 관점에서 각각 732개와 340개의 프롬프트가 사용되었습니다.
- ***Performance Highlights***: 22개의 최첨단 T2I 모델이 평가되었습니다. 오픈 소스 모델 중 SD-v3.5-Large가 최고의 성과를 보였으며, GPT-4o와 같은 독점 모델은 매우 높은 점수를 기록하여 광범위한 세계 지식과 추론 능력에서 탁월함을 보여주었습니다. 상용 시스템은 오픈 소스 대안보다 훨씬 뛰어난 성능을 발휘했으며, 이는 깊이 있는 이해와 추론이 다음 세대 T2I 시스템에서 중요하다는 점을 강조합니다.

### [Learning Heterogeneous Mixture of Scene Experts for Large-scale Neural Radiance Fields](https://arxiv.org/abs/2505.02005)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.02005.png)

Vote: 3

Authors: Xue Xiao, Dan Xu, Ping Yin, Zhenxing Mi

- ***What's New***: Switch-NeRF++는 대규모 Neural Radiance Fields(NeRF)에 대해 이질적인 해시 전문가(Heterogeneous Mixture of Hash Experts; HMoHE)를 활용하여 이전의 문제들을 해결하는 새로운 프레임워크입니다. 기존의 수작업 장치법에 의존하지 않고 장면 분해와 Radiance Fields를 학습 가능한 방식으로 통합합니다.
- ***Technical Details***: Switch-NeRF++는 해시 기반 게이팅 네트워크와 다양한 해상도 범위의 이질적인 해시 전문가들로 구성됩니다. 이 해시 기반 게이팅 네트워크는 대규모 장면의 분해를 효율적으로 학습하며, 각 분해된 장면 파트는 서로 다른 해시 전문가에 의해 처리됩니다. 이를 통해 학습적으로 장면 분해를 자동화하여 대규모 복잡한 장면을 효율적으로 재현할 수 있습니다.
- ***Performance Highlights***: Switch-NeRF++는 현존하는 최고의 방법과 비교하여 학습 속도가 8배, 렌더링 속도가 16배 빠릅니다. UrbanBIS와 같이 매우 큰 규모의 장면 (> 6.5km2)에서도 최첨단의 성능을 보이며, INGP와 비교했을 때 짧은 학습 시간 내에 더 높은 품질의 이미지를 생성할 수 있음을 보여주었습니다.

### [Unlearning Sensitive Information in Multimodal LLMs: Benchmark and Attack-Defense Evaluation](https://arxiv.org/abs/2505.01456)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.01456.png)

Vote: 2

Authors: Peter Hase, Vaidehi Patil, Tianlong Chen, Mohit Bansal, Jie Peng, Yi-Lin Sung

- ***What's New***: UnLOK-VQA는 특정 멀티모달 정보 삭제의 효과를 평가하기 위한 새로운 벤치마크입니다. 이 연구는 멀티모달 LLMs(Multimodal Large Language Models)에서의 민감한 정보 삭제를 위한 벤치마크와 '공격-방어' 평가 체계를 새롭게 제안합니다.
- ***Technical Details***: UnLOK-VQA 벤치마크는 고품질의 이미지-텍스트 쌍을 생성하는 자동화 파이프라인을 사용하여 생성되며, 수동 필터링을 통해 높은 데이터 품질을 유지합니다. 이 데이터셋은 OK-VQA를 확장하여 삭제 방법의 일반화 능력 및 구체성을 평가할 수 있도록 설계되었습니다. 공격-방어 프레임워크는 네 개의 화이트박스(Whitebox) 공격과 세 개의 블랙박스(Blackbox) 공격을 포함하여 모형의 취약성을 평가합니다.
- ***Performance Highlights***: 멀티모달 정보 삭제의 공격 성공률은 45.5%로 이미지 또는 텍스트 단독 공격보다 높았습니다. 가장 효율적인 방어 메커니즘으로는 모형 내부의 숨겨진 상태에서 답변 정보를 제거하는 접근 방법이 있었으며, 이를 통해 멀티모달 공격 성공률을 15.7%로 감소시켰습니다. 더 큰 모델은 정보 삭제 후 더 높은 신뢰성을 보이며 공격에 대한 저항력이 개선될 수 있음을 시사했습니다.

### [Rethinking RGB-Event Semantic Segmentation with a Novel Bidirectional Motion-enhanced Event Representation](https://arxiv.org/abs/2505.01548)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.01548.png)

Vote: 1

Authors: Mooi Choo Chuah, Xiaowen Ying, Zhen Yao

- ***What's New***: 이 논문은 RGB-이벤트 융합의 시맨틱 세그멘테이션을 재구성하며 '양방향 운동 강화 이벤트 텐서(Motion-enhanced Event Tensor; MET)'라는 새로운 이벤트 표현을 제안했습니다. 이를 통해 기존의 시공간 및 모달 불일치를 해결하는 혁신적인 방법을 제시합니다.
- ***Technical Details***: MET는 기존의 그리드 기반 표현이 간과한 시공간의 상관관계를 포착하고, 드문 이벤트 데이터를 밀도 높은 흐름 맵으로 변환합니다. 또한, 빈도 인식 양방향 흐름 집계 모듈(Frequency-aware Bidirectional Flow Aggregation Module; BFAM)과 시간 융합 모듈(Temporal Fusion Module; TFM)을 도입하여, 이 모듈들이 시공간 불일치를 해결합니다.
- ***Performance Highlights***: 제안된 프레임워크는 DSEC 및 DDD17 데이터셋에서 기존의 최첨단 RGB-이벤트 시맨틱 세그멘테이션 접근법들을 능가하는 성능을 보여주었습니다. 특히, BRENet 모델은 이러한 데이터셋에서 우수한 mIoU 성능을 기록하면서도 효율성을 유지하여 모델 크기 대비 성능이 뛰어남을 입증했습니다.

### [Attention Mechanisms Perspective: Exploring LLM Processing of Graph-Structured Data](https://arxiv.org/abs/2505.02130)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2505.02130.png)

Vote: 1

Authors: Hongke Zhao, Zhong Guan, Likang Wu, Ming He, Jianpin Fan

- ***What's New***: 이 논문에서는 주목 메커니즘(Attention Mechanisms)이 그래프 구조 데이터를 어떻게 처리하는지 연구하였습니다. 대형 언어 모델(LLM)이 그래프 데이터를 처리하는 방식에 대한 새로운 통찰을 제공하며, LLM이 그래프 구조에서 주목을 배치하는 독특한 현상을 발견했습니다.
- ***Technical Details***: LLM은 그래프 데이터의 노드 간 관계를 모델링하는데 어려움을 겪으며, 주목 분포가 이상적인 구조 패턴과 일치하지 않는 것으로 나타났습니다. 연구는 LLM을 위한 최적의 연결 관점을 찾기 위해 전역 연결 지평(Global Linkage Horizon; GLH) 지표를 도입하였습니다. 부분적으로 연결된 주목 창이 가장 높은 성능을 보여주었습니다.
- ***Performance Highlights***: 실험 결과, 완전 연결된 상태의 주목 창을 사용한 LLM은 최적의 성능을 나타내지 못하였으며, 특정 연결 정보를 포함한 중간 상태의 주목 창이 훈련 성능을 향상시켰습니다. 이는 실제 시나리오에서 모델 배포의 실용적인 난제를 해결하면서 성능을 향상시킵니다.

