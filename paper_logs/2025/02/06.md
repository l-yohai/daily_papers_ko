## Daily Papers (2025-02-06)

### [SmolLM2: When Smol Goes Big -- Data-Centric Training of a Small Language Model](https://arxiv.org/abs/2502.02737)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.02737.png)

Vote: 81

Authors: Haojun Zhao, Vaibhav Srivastav, Ben Burtenshaw, Thomas Wolf, Andrés Marafioti, Clémentine Fourrier, Colin Raffel, Xuan-Son Nguyen, Lewis Tunstall, Agustín Piqueres Lajarín, Anton Lozhkov, Mathieu Morlon, Elie Bakouch, Guilherme Penedo, Caleb Fahlgren, Joshua Lochner, Hugo Larcher, Loubna Ben Allal, Hynek Kydlíček, Leandro von Werra, Cyril Zakka, Gabriel Martín Blázquez

- ***What's New***: SmolLM2는 1.7억 개의 매개변수를 갖는 소형 언어 모델(Small Language Model; SLM)의 개발을 문서화 하는 연구입니다. SmolLM2는 최신의 '작은' 언어 모델로, 약 11조 토큰의 데이터를 사용하여 여러 단계의 훈련 프로세스를 통해 고성능을 달성합니다. 이러한 데이터는 웹 텍스트뿐만 아니라, 수학, 코드 및 명령-따르기 데이터로 구성됩니다.
- ***Technical Details***: SmolLM2의 훈련은 웹, 코드, 수학 및 명령-따르기 데이터세트를 혼합하여 다단계 수동 리밸런싱 방식을 사용하여 수행됩니다. 각 훈련 단계는 데이터세트의 혼합 비율을 조정하여 이전 단계의 성능을 기반으로 합니다. 새로운 특화 데이터세트는 FineMath, Stack-Edu 및 SmolTalk으로, 기존 데이터세트가 너무 작거나 품질이 낮은 것이 문제인 경우 생성되었습니다.
- ***Performance Highlights***: SmolLM2는 Qwen2.5-1.5B와 Llama3.2-1B 같은 최근의 소형 언어 모델보다 뛰어난 성능을 보였습니다. 헬라스웨그(HellaSwag), 아크(ARC) 등의 벤치마크에서 두드러진 성과를 보였으며, 8k 컨텍스트 길이의 이슈 없음과 HELMET 및 니들 인 더 헤이스택(NIAH) 결과에서 강력한 성능을 나타냈습니다. SmolLM2의 코드 생성 및 수학적 비교에서는 경쟁 모델보다 우수한 성능을 보여 주는 것으로 평가되었습니다.

### [TwinMarket: A Scalable Behavioral and Social Simulation for Financial Markets](https://arxiv.org/abs/2502.01506)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.01506.png)

Vote: 26

Authors: Kaidi Zhang, Minghao Wu, Honghai Yu, Benyou Wang, Yunmiao Zhang, Yuzhe Yang, Yan Hu, Yifei Zhang

- ***What's New***: TwinMarket는 대형 언어 모델 (Large Language Models; LLMs)을 활용해 금융 시장 내 투자자 행동을 시뮬레이션하기 위한 새로운 다중 에이전트 프레임워크입니다. 특히, 개인 행동이 상호작용 및 피드백 메커니즘을 통해 집단 역학과 발생 현상을 어떻게 유발하는지를 탐구합니다.
- ***Technical Details***: TwinMarket의 핵심 혁신 중 하나는 에이전트의 인지 과정을 구조화하고 시각화하기 위해 신념-욕망-의도 (Belief-Desire-Intention; BDI) 프레임워크를 사용하는 것입니다. 사용자마다 고유한 개인정보를 가진 사회적 네트워크에서 실시간으로 상호작용하며, 주식 포럼을 통해 정보를 교환하고 결정에 영향을 미칩니다. 
- ***Performance Highlights***: TwinMarket은 기존의 규칙 기반 접근방식과 달리, LLM 기반 에이전트를 통해 재무 시장의 매크로 수준 역학을 효율적으로 표현하며, 실험 결과를 통해 시장 탁월함과 일치함을 확인했습니다. 1000명 에이전트로 확장된 연구에서는 실제 시장 지수와의 강력한 상관 관계와 시간적 지연이 없는 거래 반응을 보였습니다.

### [Demystifying Long Chain-of-Thought Reasoning in LLMs](https://arxiv.org/abs/2502.03373)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.03373.png)

Vote: 21

Authors: Morry Niu, Xiang Yue, Yuxuan Tong, Edward Yeo, Graham Neubig

- ***What's New***: 이 논문은 대형 언어 모델(LLMs)의 긴 사고 사슬(Chain-of-Thought; CoT) 추론 능력을 보다 명확히 이해하고 탐구합니다. 이 과정에서 강화 학습(RL)이 이러한 능력 개발에 중요하지만, 긴 CoT가 등장하는 구체적인 조건은 명확하지 않음을 지적합니다.
- ***Technical Details***: 연구를 통해 다양한 조건하에 긴 CoT를 생성하는 방법을 체계적으로 조사하였습니다. 주로 감독된 세부 조정(SFT)과 RL 실험을 통해 긴 CoT 궤적을 생성하는 주요 요소를 식별하였으며, 학습 컴퓨트가 증가함에 따라 추론 능력이 향상되지만 이는 보장되지 않으며 보상 구조 조정이 CoT 길이 증가를 안정화하는데 중요함을 발견했습니다.
- ***Performance Highlights***: 실험 결과, 긴 CoT 데이터로 이루어진 SFT는 코트 성과를 크게 향상시키며, RL로 추가적인 성능 향상을 쉽게 유도할 수 있음을 보여주었습니다. 데이터 출처 및 보상 설계의 중요성이 강조되었으며, 노후 데이터에서도 준수한 성능 향상을 달성하며, 다양한 데이터 세트를 결합한 SFT가 편균적인 성능 향상에 기여함을 확인했습니다.

### [LIMO: Less is More for Reasoning](https://arxiv.org/abs/2502.03387)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.03387.png)

Vote: 18

Authors: Shijie Xia, Zhen Huang, Yang Xiao, Yixin Ye, Pengfei Liu, Ethan Chern

- ***What's New***: LIMO(less is more for reasoning)는 대규모 언어 모델(LLM)에서 복잡한 수리적 추론 능력이 소수의 예제로도 효과적으로 유도될 수 있음을 입증한 혁신적인 결과를 제시합니다. 수십만 개의 훈련 예제 대신 단 817개의 샘플로 AIME 벤치마크에서 57.1%, MATH에서 94.8%의 정확도를 달성하며, 데이터 효율성에 대한 새로운 패러다임을 제안합니다.
- ***Technical Details***: LIMO는 두 가지 핵심 요소로 설명됩니다: (1) 모델의 사전 훈련에서 이미 존재하는 도메인 지식의 완전성, (2) 사후 훈련 예제의 효과성으로, 이는 모델이 자체 지식 기반을 활용해 복잡한 문제 해결을 이끌어내는 '인지 템플릿'으로 작용합니다. 이를 통해 적은 수의 고품질 예제로 강력한 추론 능력을 개발할 수 있음을 보여줍니다.
- ***Performance Highlights***: LIMO는 기존 SFT 기반 모델을 능가하며, 동일 데이터 대비 40.5% 개선된 성능을 보여줍니다. 특히 AIME에서 57.1%, MATH에서 94.8%의 정확도를 기록하며, 100배 많은 데이터를 사용한 모델보다 더 뛰어난 일반화 성과를 나타냅니다.

### [Boosting Multimodal Reasoning with MCTS-Automated Structured Thinking](https://arxiv.org/abs/2502.02339)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.02339.png)

Vote: 9

Authors: Feihu Che, Zengqi Wen, Ruihan Jin, Mingkuan Feng, Jianhua Tao, Jinyang Wu, Shuai Zhang

- ***What's New***: 이 연구는 몬테카를로 트리 탐색(Monte Carlo Tree Search; MCTS)을 활용하여 멀티모달 추론을 강화하는 자동화된 구조적 사고 패러다임을 제안합니다. 이를 통해 제한된 데이터를 사용하여 고차원 인지 추론 패턴을 자동으로 생성하고, 이러한 패턴을 활용해 모델의 내부 추론 능력과 외부 추론 가이드라인을 통합하는 통합 추론 프레임워크를 제공합니다.
- ***Technical Details***: AStar는 MCTS 기반의 계층 구조를 활용하여 제한된 데이터에서 고차원의 인지 추론 패턴을 도출합니다. 여섯 가지 추론 동작을 정의하여 인간과 유사한 인지 행동을 시뮬레이션하고, MCTS를 사용하여 참조 추론 경로를 구성합니다. 그리고 목적 복잡성과 일치하는 최적의 추론 경로를 선택하여 시각적 추론을 수행하며, 자기 일관성 검사 또는 결과 보상 모델을 통해 최종 솔루션을 검증합니다.
- ***Performance Highlights***: AStar는 MathVerse 벤치마크에서 7B 백본을 사용하여 54.0%의 정확도로 GPT-4o(50.2%)를 능가하는 성능을 보였습니다. 또한, 데이터 및 계산 효율성이 뛰어나 기존 트리 기반 방법 대비 추론 오버헤드를 6.4배 줄이고 훈련 기반 방법 대비 520배 적은 데이터를 필요로 합니다.

### [Text-to-CAD Generation Through Infusing Visual Feedback in Large Language Models](https://arxiv.org/abs/2501.19054)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.19054.png)

Vote: 6

Authors: Shizhao Sun, Jiang Bian, Ruiyu Wang, Yu Yuan

- ***What's New***: 이 연구는 CADFusion이라는 새로운 프레임워크를 제안하여 텍스트 설명을 CAD 파라메트릭 시퀀스로 변환하는 Text-to-CAD 생성 프로세스를 개선합니다. 기존 방법들이 주로 시퀀스 신호에만 초점을 맞췄던 것과 달리, CADFusion은 시각적 피드백(Visual Feedback) 신호를 활용하여 향상된 성능을 제공합니다.
- ***Technical Details***: CADFusion은 대형 언어 모델(Large Language Models; LLMs)을 백본으로 사용하며, 시퀀스 학습(SL) 단계와 시각적 피드백(VF) 단계를 번갈아가며 훈련합니다. 시퀀스 학습 단계에서는 실제 CAD 파라메트릭 시퀀스를 사용하여 논리적으로 일관된 시퀀스를 생성하도록 LLM을 훈련합니다. 시각적 피드백 단계에서는 렌더링된 시각 객체들이 선호되는 시각 형태로 표현될 때 보상하고 그렇지 않을 경우 페널티를 줌으로써 학습합니다.
- ***Performance Highlights***: CADFusion은 기존의 GPT-4o와 Text2CAD와 같은 기법들에 비해 모든 성능 지표에서 우수한 결과를 보여줍니다. 특히 시각적 품질을 평가하는 LVM 점수와 사용자가 선호하는 출력에 대한 평균 순위에서 뛰어난 성능을 발휘하며, CAD 모델의 시각적 품질을 크게 향상시킵니다.

### [LayerTracer: Cognitive-Aligned Layered SVG Synthesis via Diffusion Transformer](https://arxiv.org/abs/2502.01105)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.01105.png)

Vote: 6

Authors: Yiren Song, Mike Zheng Shou, Danze Chen

- ***What's New***: LayerTracer는 설계자의 레이어별 생성 로직을 학습하여 계층적 SVG(SVGs; Scalable Vector Graphics)를 생성하는 최초의 프레임워크입니다. 이 시스템은 Diffusion Transformer(DiT)를 기반으로 하며, 텍스트 프롬프트에서 SVG를 생성하거나 이미지를 레이어별로 변환할 수 있습니다.
- ***Technical Details***: LayerTracer는 두 가지 주요 단계로 구성됩니다. 첫째, 텍스트 조건에 맞춰 DiT를 사용해 사람의 디자인 워크플로우를 시뮬레이트하는 다단계 래스터화된 빌드 시퀀스를 생성합니다. 둘째, 레이어별 벡터화 및 경로 중복 제거를 통해 깔끔하고 편집 가능한 SVG를 만듭니다. 이미지 벡터화에는 참조 이미지를 잠재 토큰으로 인코딩하여 계층적 재구성을 유도하는 조건부 확산 메커니즘이 포함됩니다.
- ***Performance Highlights***: LayerTracer는 생성품질과 편집 가능성에서 최상의 성능을 보여주며, 기존 최적화 기반 및 신경망 기반 방법에 비해 우수한 성과를 냅니다. 특히 테스트된 기준에서 더 낮은 평균 경로 수와 더 빠른 실행 시간을 기록했으며, 생성된 SVG의 계층적 구조가 명확하고 편집 가능성을 갖추고 있습니다.

### [A Probabilistic Inference Approach to Inference-Time Scaling of LLMs using Particle-Based Monte Carlo Methods](https://arxiv.org/abs/2502.01618)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.01618.png)

Vote: 5

Authors: Guangxuan Xu, Akash Srivastava, Isha Puri, Kai Xu, Shivchander Sudalairaj

- ***What's New***: 이 논문에서는 대형 언어 모델(LLMs)의 추론 시간 확장을 확률적 추론 문제로 프레임하고, Particle-Based Monte Carlo Methods를 사용하여 모델 성능을 향상시키는 새로운 방법론을 제안합니다. 이는 기존의 보상 모델을 기반으로 한 검색 기반 접근 방식의 한계를 극복하기 위해 설계되었습니다.
- ***Technical Details***: 추론 시간 확장을 위해 상태 공간 모델(SSM)에서 확률 추론을 수행하며, 파티클 필터링(Particle Filtering)을 주요 알고리즘으로 채택하고 있습니다. 이 방법은 다양한 후보군을 유지하며, 관찰된 증거에 따라 후보의 가중치를 갱신하여 보상 모델의 불완전성을 보완합니다. 또한, 모델 기반 집계를 통해 부분적 해답에 대한 보상을 보다 효과적으로 계산하는 방법을 제안합니다.
- ***Performance Highlights***: 실험 결과에 따르면, 제안된 방법은 다른 최적화 기반 접근 방식에 비해 4-16배 빠르게 스케일링 성능을 보였습니다. Qwen2.5-Math-1.5B-Instruct가 4번의 롤아웃 만에 GPT-4o의 정확도를 능가했으며, Qwen2.5-Math-7B-Instruct는 32번의 롤아웃 내에서 o1 수준의 정확도를 달성했습니다. 이는 Qwen2.5-Math-7B 모델이 MATH500 데이터셋에서 o1-preview와 동일한 성능을 달성할 수 있음을 보여줍니다.

### [On Teacher Hacking in Language Model Distillation](https://arxiv.org/abs/2502.02671)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.02671.png)

Vote: 5

Authors: Daniele Calandriello, Nino Vieillard, Alexandre Ramé, Johan Ferret, Mathieu Blondel, Daniil Tiapkin, Sarah Perrin

- ***What's New***: 이 논문은 언어 모델 증류(Language Model Distillation)에서 발생할 수 있는 새로운 현상인 '티처 해킹(Teacher Hacking)'을 소개하고 있습니다. 이는 학생 모델이 실제 데이터 분포를 더 잘 근사화하는 대신 불완전한 티처 모델의 결함을 이용하여 학습하는 현상입니다.
- ***Technical Details***: 실험은 오라클 모델(Oracle Model)을 사용하여 티처 모델을 학습시키고, 이 티처로부터 학생 모델(Student Model)을 증류하는 방법을 통해 진행됩니다. 실험 환경은 컨트롤된 셋업에서 이루어지며, 오프라인 데이터세트와 온라인 데이터 생성 기법을 활용하여 교사 해킹 현상을 탐구합니다. 주된 분석 방법은 KL divergence와 Jensen-Shannon divergence와 같은 거리 측정을 통해 이루어집니다.
- ***Performance Highlights***: 실험 결과는 오프라인 데이터세트에서 티처 해킹이 발생할 수 있음을 보여줍니다. 특히 고정된 오프라인 데이터세트를 사용할 때 'golden metric'은 악화되며, 이는 온라인 데이터 생성 기법의 사용이나 데이터 다양성을 늘리는 전략을 통해 완화될 수 있음을 제시합니다.

### [Token Assorted: Mixing Latent and Text Tokens for Improved Language Model Reasoning](https://arxiv.org/abs/2502.03275)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.03275.png)

Vote: 3

Authors: Jiantao Jiao, Yingchen Xu, DiJia Su, Yuandong Tian, Qinqing Zheng, Hanlin Zhu

- ***What's New***: 이 연구는 대형 언어 모델(LLMs)의 추론 성능을 향상시키기 위해 잠재(Discrete Latent)와 텍스트 토큰을 혼합하여 사용하는 방법을 제안합니다. VQ-VAE를 사용해 초기 추론 단계의 부분적인 압축을 통해 모델의 입력 길이를 줄이고 계산 비용을 절감합니다.
- ***Technical Details***: VQ-VAE(Vector-quantized Variational Autoencoder)를 활용해 추론 단계의 텍스트 토큰을 잠재 토큰으로 대체하고, 한 샘플 내에서 임의의 텍스트 토큰 수를 잠재 토큰으로 대체하는 방식으로 학습합니다. 이 방식은 새로운 잠재 토큰에 대한 빠른 적응을 가능하게 합니다. 제안된 방법은 ProntoQA, Math, GSM8K 등의 다양한 벤치마크에서 검증되었습니다.
- ***Performance Highlights***: 제안된 모델은 다양한 벤치마크에서 평균적으로 17%의 추론 트레이스 길이 절감을 달성하면서도, 기존 Complete CoT 기반 모델보다 높은 성능을 보였습니다. Llama-3.2-1B 모델에서는 Math 벤치마크에서 4.2%의 성능 향상을, GSM8K에서 4.1%의 성능 향상을 달성했습니다. 또한, Fresh-Gaokao-Math-2023에서는 13.3%의 성능 개선을 이뤘습니다.

### [Jailbreaking with Universal Multi-Prompts](https://arxiv.org/abs/2502.01154)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.01154.png)

Vote: 3

Authors: Hsuan Su, Shang-Tse Chen, Yu-Ling Hsu

- ***What's New***: 이 논문은 JUMP라는 새로운 프롬프트 기반 방법을 소개하며, 대형 언어 모델(Large Language Models; LLMs)을 감시 모드로 유도하는 유니버설 멀티 프롬프트(Universal Multi-Prompts)를 최적화하는 방법을 제안합니다. 또한 이 방법을 방어 용도로 사용할 수 있도록 DUMP라는 기법도 도입하였습니다.
- ***Technical Details***: JUMP는 BEAST 방법을 확장하여 새로운 훈련 모델 없이도 일반적인 시나리오에서 최적화된 결과를 제공하는 방법입니다. 초기 버전 JUMP*는 perplexity 제어 없이 기본 메서드를 능가합니다. 실험 결과 잘 선택된 초기 시드 집합은 ASR과 perplexity 사이의 절충 문제를 완화할 수 있음을 보였습니다. 최종 버전 JUMP는 제한 단계를 통합하여 최적화를 진행합니다.
- ***Performance Highlights***: JUMP는 Llama 모델과 같은 어려운 모델에서도 높은 성능을 보여줍니다. JUMP++는 perplexity와 공격 성공률(ASR) 사이의 절충을 완화하여 개선된 결과를 보였습니다. 또한 AutoDAN, GPTFuzzer와 같은 기존 방법보다 뛰어난 성과를 기록했습니다.

### [Large Language Model Guided Self-Debugging Code Generation](https://arxiv.org/abs/2502.02928)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.02928.png)

Vote: 2

Authors: Carlos C. N. Kuhn, Zhiwei Xu, Muntasir Adnan

- ***What's New***: 이 논문은 PyCapsule이라는 새로운 프레임워크를 제안하며, 이는 Python 코드 생성을 위한 매우 효율적인 자기 디버깅(Self-Debugging) 모듈을 포함한 두 에이전트 구조를 가지고 있습니다. 이는 기존의 복잡한 다중 에이전트 시스템을 대체하며, 높은 세대 안정성, 안전성, 정확성을 보장합니다.
- ***Technical Details***: PyCapsule은 프로그래머 에이전트와 실행기(Executor) 에이전트를 사용하여 코드 생성 및 디버깅을 수행합니다. 프로그래머 에이전트는 Ollama와 GPT 인프라스트럭쳐를 활용하여 코드 생성 및 자기 디버깅 과정을 거치며, 실행기 에이전트는 코드의 실행 및 유효성 검사, 케이스 테스트를 담당합니다. 이 구조에는 세 가지 특화된 모듈이 포함되어 있습니다: 오류 처리기(Error Handler), 예제 호출 검출기(Example Call Detector), 함수 시그니처 컨버터(Function Signature Converter).
- ***Performance Highlights***: PyCapsule은 HumanEval에서 5.7%, HumanEval-ET에서 10.3%, BigCodeBench에서 24.4%의 성공률 향상을 보여주며, 높은 성능을 발휘합니다. 이는 더 적은 API 호출 수로도 높은 성능을 유지하면서도 기존의 다중 에이전트 시스템에서 소비되는 자원을 절감합니다.

### [Riddle Me This! Stealthy Membership Inference for Retrieval-Augmented Generation](https://arxiv.org/abs/2502.00306)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.00306.png)

Vote: 1

Authors: Alina Oprea, Harsh Chaudhari, Anshuman Suri, Ali Naseh, Yuefeng Peng, Amir Houmansadr

- ***What's New***: 이 논문은 Retrieval-Augmented Generation (RAG) 시스템의 데이터스토어에서 문서의 존재 여부를 감지하는 새로운 스텔스적 멤버십 추론 기법인 Interrogation Attack (IA)을 제안하고 있습니다. 이 방법은 자연어로 작성된 쿼리를 사용하여 기존의 탐지 시스템에 걸리지 않으면서 해당 문서의 존재를 확인할 수 있도록 설계되었습니다.
- ***Technical Details***: IA는 크게 쿼리 생성, 정답 생성, 멤버십 추론의 세 단계로 이루어집니다. 자연어 데이터에서 문서의 주요 내용을 추출하여 질의문을 만들고, LLM을 통해 정답을 생성한 후, 모델의 응답과 비교하여 멤버십을 추론합니다. 이 과정에서 사용하는 쿼리는 자연스럽고 기존 탐지 시스템에서 걸러지지 않도록 설계했습니다.
- ***Performance Highlights***: IA는 다른 기존 공격과 비교하여 탐지율이 매우 낮으며 응답 정확도는 높게 유지됩니다. 다양한 데이터 세트에 대해 실험한 결과, 높은 AUC와 낮은 FPR에서 우수한 성능을 보여주며, 특히 0.02달러 이하의 비용으로 문서 추론이 가능해 경제적입니다.

### [Activation-Informed Merging of Large Language Models](https://arxiv.org/abs/2502.02421)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.02421.png)

Vote: 1

Authors: Amin Heyrani Nobari, Ali ArjomandBigdeli, Navid Azizan, Akash Srivastava, Faez Ahmed, Kaveh Alimohammadi

- ***What's New***: 이 논문에서는 대형 언어 모델(LLMs)의 병합 성능을 개선하기 위한 Activation-Informed Merging (AIM) 방법을 소개합니다. AIM은 기존의 모델 병합 방법에 유연하게 결합할 수 있으며, 모델의 활성화 공간(activation space) 정보를 통합하여 성능을 향상시킵니다. 이는 지속적 학습(continual learning)과 모델 압축(model compression)에서 가져온 원리를 사용하여, 기본 모델의 중요한 가중치를 우선시합니다.
- ***Technical Details***: AIM은 작업에 중립적인 보정 세트를 사용하여 모델의 활성화 공간을 분석하고 중요한 가중치를 결정합니다. 이렇게 선택된 중요한 가중치는 병합 단계에서 최소한의 변경을 가하며, 이는 지속적 학습에서의 가중치 규제(weight regularization)와 유사합니다. AIM은 다양한 병합 방법에 적용될 수 있는 보완적 솔루션이며, 활성화 공간에서 도출된 정보를 사용하여 대형 언어 모델을 더 효과적으로 병합합니다.
- ***Performance Highlights***: AIM은 다양한 벤치마크에서 병합된 모델의 성능을 최대 40%까지 향상시킬 수 있음을 실험적으로 증명했습니다. 이 결과는 AIM이 모델 병합 전략에서 활성화 공간 정보가 얼마나 중요한지를 강조하며, 특히 수학적 문제 해결과 코드 생성, 명령어 따르기 등의 작업에서 AIM이 강력한 성능 개선을 가져오는 것을 보여줍니다.

### [HackerRank-ASTRA: Evaluating Correctness & Consistency of Large Language Models on cross-domain multi-file project problems](https://arxiv.org/abs/2502.00226)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.00226.png)

Vote: 0

Authors: Rafik Matta, Mayur Bhatia, Jun Xing, Darshan Suresh, Sahil Phulwani

- ***What's New***: HackerRank-ASTRA는 다중 파일 기반의 실제 프로젝트 문제를 다루는 새로운 벤치마크로, 대규모 언어 모델(LLMs)의 정확성과 일관성을 평가합니다. 이 벤치마크는 프론트엔드 개발에 중점을 두며, Node.js, React.js, Django 등을 포함한 프레임워크를 활용합니다.
- ***Technical Details***: ASTRA 벤치마크는 평균 12개의 소스 코드와 구성 파일을 포함하는 65개의 프로젝트 기반 코딩 문제로 구성되어 있습니다. 모델은 32번의 실행(k = 32)에서 일관된 성능을 평가하며, mean pass@1와 median standard deviation을 통해 모델의 정확성과 일관성을 평가합니다.
- ***Performance Highlights***: 실험 결과, o1, o1-preview, Claude-3.5-Sonnet-1022 모델은 평균 75%의 점수를 기록하였으며, Claude-3.5-Sonnet-1022는 가장 낮은 변동성 (SD = 0.0497)을 보였습니다. 이는 실제 소프트웨어 개발 작업에서 높은 신뢰성을 나타냅니다.

