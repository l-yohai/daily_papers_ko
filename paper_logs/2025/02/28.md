## Daily Papers (2025-02-28)

### [Self-rewarding correction for mathematical reasoning](https://arxiv.org/abs/2502.19613)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.19613.png)

Vote: 49

Authors: Wei Xiong, Hanning Zhang, Nan Jiang, Tong Zhang, Lichang Chen, Chenlu Ye

- ***What's New***: 이 연구는 대형 언어 모델(LLMs)이 수학적 추론을 자율적으로 수행하고, 자기 생성의 오류를 스스로 감지하고 수정할 수 있는 '자기 보상적 추론' 프레임워크를 제안합니다. 이 프레임워크는 모델이 외부 피드백 없이 자급적 사고 과정과 평가를 통합하여 추론을 수행할 수 있게 합니다.
- ***Technical Details***: 자기 보상적 추론 모델을 구축하기 위한 이중 단계 알고리즘 프레임워크가 소개되었습니다. 첫 번째 단계에서는 순차적 '거절 샘플링'을 사용하여 자체 보상 및 수정 메커니즘을 포함하는 장기간의 사고 궤적을 합성합니다. 그런 다음 이 데이터로 모델을 미세 조정하여 패턴을 학습합니다. 두 번째 단계에서는 규칙 기반 신호를 사용하여 강화 학습을 통해 응답 정확성을 평가하고 출력을 개선합니다.
- ***Performance Highlights***: Llama-3 및 Qwen-2.5 모델을 사용한 실험에서 제안된 접근 방식은 내적 자가 수정을 능가하며, 외부 보상 모델에 의존하는 시스템과 비슷한 성능을 달성했습니다. 특히, 자기 보상적 수정은 기본적인 자가 수정 능력을 뛰어넘고 설계된 프레임워크의 학습 역학을 조사하는 과정에서도 그 효과성을 확인했습니다.

### [MedVLM-R1: Incentivizing Medical Reasoning Capability of Vision-Language Models (VLMs) via Reinforcement Learning](https://arxiv.org/abs/2502.19634)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.19634.png)

Vote: 42

Authors: Fenglin Liu, Jiayuan Zhu, Hongwei Bran Li, Jiazhen Pan, Che Liu, Junde Wu, Chen Chen, Daniel Rueckert, Cheng Ouyang

- ***What's New***: MedVLM-R1은 의료 비전-언어 모델(Vision-Language Models; VLMs)의 의료 추론 능력을 강화하기 위해 강화 학습(Reinforcement Learning)을 적용한 최초의 의료 VLM입니다. 이 모델은 명시적인 자연어 추론을 생성하여 의료 진단의 투명성과 신뢰성을 높입니다.
- ***Technical Details***: MedVLM-R1은 GRPO(Group Relative Policy Optimization)를 활용하여 방사선 영상 질의응답(VQA) 문제에서 자연어 추론을 통해 최종 답변을 제공합니다. 기본 베이스 모델은 Qwen2-VL-2B이며, GRPO를 통해 명시적인 추론을 유도하고 형식적 및 정확도 보상 함수에 기반하여 모델을 최적화합니다.
- ***Performance Highlights***: MedVLM-R1은 600개의 MRI 시각 질문 응답 샘플로만 학습 되었음에도, MRI, CT, X-ray 벤치마크에서 정확도가 55.11%에서 78.22%로 향상되었습니다. SFT(Supervised Fine-Tuning)과 비교하여 뛰어난 일반화 성능을 보였으며, 수백만 개의 샘플로 훈련된 대규모 모델보다도 우수한 성능을 발휘했습니다.

### [R2-T2: Re-Routing in Test-Time for Multimodal Mixture-of-Experts](https://arxiv.org/abs/2502.20395)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.20395.png)

Vote: 32

Authors: Zhongyang Li, Ziyue Li, Tianyi Zhou

- ***What's New***: 이 논문은 대형 멀티모달 모델(Large Multimodal Models; LMMs)의 하위 최적 라우팅 문제를 해결하기 위한 새로운 테스트-타임 리라우팅 방법인 R2-T2를 제안합니다. 이는 라우팅 가중치를 동적으로 조정하여 멀티모달 모델의 일반화를 개선하고 모델의 성능 격차를 해소합니다.
- ***Technical Details***: R2-T2는 k-최근접 이웃(k-Nearest Neighbors; kNN) 방법론을 사용하여 레퍼런스 세트의 성공적인 샘플을 기반으로 시험 샘플에 대한 라우팅 가중치를 최적화합니다. 이 방법에는 네 가지 핵심 전략이 있으며, 각각 새로운 최적화 목표를 가지고 다양한 이웃 탐색 공간을 기반으로 솔루션을 제공합니다. 이 논문에서는 경사하강법(Gradient Descent), 커널 회귀(Kernel Regression), 모드 찾기(Mode Finding) 등 세 가지 주요 전략을 제안하고 있습니다.
- ***Performance Highlights***: R2-T2는 기본 모형 및 오라클 기반 최적화 방법과 비교하여 여러 멀티모달 벤치마크에서의 성능이 뛰어남을 보여줍니다. R2-T2는 사전 학습된 MoVA-7B 및 MoAI-7B 모델 모두에서 사용되었으며, 원래 모델보다 상당한 성능 개선을 제공하고, 더 큰 모델을 능가하는 결과를 나타냈습니다. 이러한 결과는 더 작은 모델의 잠재력을 발휘하여 대형 비전 언어 모델(Vision Language Models; VLMs)과 비슷하거나 그보다 뛰어난 성능을 구현할 수 있음을 시사합니다.

### [LongRoPE2: Near-Lossless LLM Context Window Scaling](https://arxiv.org/abs/2502.20082)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.20082.png)

Vote: 21

Authors: Mao Yang, Li Lyna Zhang, Weizhu Chen, Siyuan Wang, Gilsinia Lopez, Ning Shang, Fan Yang, Gaokai Zhang

- ***What's New***: 이 연구는 긴 컨텍스트 윈도우를 효과적으로 확장하면서 기존 짧은 컨텍스트 성능을 유지하는 새로운 방법인 LongRoPE2를 제안합니다. 기존 방법들이 처리하지 못한, RoPE의 고차원에서의 학습 부족 문제를 해결하여 128K 컨텍스트 길이를 달성했습니다.
- ***Technical Details***: LongRoPE2는 세 가지 주요 기여를 통해 RoPE의 학습 부족 문제를 해결합니다: RoPE 고차원에서 발생하는 OOD 문제에 대한 가설 수립, 'needle-driven' perplexity를 통한 효과적인 RoPE 재스케일 알고리즘, 그리고 혼합 컨텍스트 윈도우 학습 방법 도입으로 긴 컨텍스트 이해력을 높이고 짧은 컨텍스트 성능을 유지합니다. LongRoPE2는 LLaMA3-8B 및 Phi3-mini-3.8B 모델에서 128K 유효 컨텍스트 길이를 달성했습니다.
- ***Performance Highlights***: LongRoPE2는 10B 토큰만을 사용하여, Meta의 800B 토큰 접근법보다 훨씬 적은 비용으로 LLaMA3-8B 모델의 긴 컨텍스트 성능을 향상시키면서 짧은 컨텍스트에서의 성능도 98.5% 이상 유지했습니다. 다양한 벤치마크 테스트에서 다른 RoPE 재스케일링 방법의 성능을 능가하며, 특히 긴 문맥 모델링에서 강력한 성능을 발휘합니다.

### [FINEREASON: Evaluating and Improving LLMs' Deliberate Reasoning through Reflective Puzzle Solving](https://arxiv.org/abs/2502.20238)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.20238.png)

Vote: 18

Authors: Yu Rong, Deli Zhao, Hou Pong Chan, Guizhen Chen, Hao Zhang, Lidong Bing, Chaoqun Liu, Weiwen Xu, Anh Tuan Luu

- ***What's New***: FINEREASON은 논리 퍼즐을 통해 LLMs의 추론 능력을 보다 세밀하게 평가하는 새로운 벤치마크로, 중간 단계 평가를 통해 모델의 반성(reflection) 및 수정(correction) 능력을 살펴볼 수 있습니다.
- ***Technical Details***: FINEREASON 벤치마크는 Sudoku, Graph Coloring, Game of 24, Grid Puzzles로 구성되며, 각 퍼즐은 연속 단계로 분해되어 상태 점검(state checking)과 상태 전환(state transition) 두 가지 주요 작업을 통해 모델의 추론 과정을 평가합니다. 각 단계는 원자적 단계로 분해되어 중간 상태의 올바름을 철저히 검증할 수 있습니다.
- ***Performance Highlights***: OpenAI의 o1 모델은 Gemini-FT 모델보다 모든 퍼즐에서 19.7%의 큰 차이로 우월한 성능을 보여주었고, 일반적인 모델은 깊이 있는 추론에서 고전했습니다. 예를 들어, DeepSeek-R1-Distill-Qwen-7B 모델은 FINEREASON의 상태 점검 및 전환 데이터를 학습하여 GSM8K에 대한 수학적 추론 정확도를 82.3%에서 87.4%로 향상시켰습니다.

### [CODESYNC: Synchronizing Large Language Models with Dynamic Code Evolution at Scale](https://arxiv.org/abs/2502.16645)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.16645.png)

Vote: 15

Authors: Zhaoyang Chu, Dongping Chen, Kaiyue Qiu, Chenlong Wang, Zhou Zhao, Zhengxiang Cheng, Xuanhua Shi, Yao Wan, Xuyi Yang

- ***What's New***: CODESYNC는 대형 언어 모델(LLMs)이 동적인 코드 진화와 동기화할 수 있도록 지원하기 위해 설계된 데이터 엔진입니다. 이 툴은 Python 서드파티 라이브러리의 실시간 코드 지식 업데이트를 수집하고, CODESYNCBENCH라는 포괄적인 벤치마크를 통해 LLMs의 코드 진화 동기화 능력을 평가합니다.
- ***Technical Details***: CODESYNC는 Python의 여러 서드파티 라이브러리에서 API 서명을 추적해 업데이트를 식별하고, GitHub 코드 검색을 통한 API 호출 사례를 수집합니다. DeepSeek-V3를 이용하여 레거시 및 업데이트된 API 버전에 대한 대조적인 호출을 합성합니다. CODESYNCBENCH는 6개의 Python 라이브러리에서 220개의 API와 관련된 3,300개의 테스트 케이스를 제공하며, 코드 완성 작업(CCT), 오류 수정 작업(ECT), 다중 선택 질문(MCQ)이라는 세 가지 평가 작업을 포함합니다.
- ***Performance Highlights***: 14개의 최신 LLMs에 대한 광범위한 실험 결과, 고도화된 지식 업데이트 방법(DPO, ORPO, SimPO)을 지원하더라도 LLM이 동적 코드 진화에 적응하는 데 어려움을 겪고 있는 것으로 나타났습니다. 이를 통해 API 업데이트 시 실제 모델의 지식 업데이트를 반영하는 것이 중요한 과제임을 확인하였습니다.

### [UniTok: A Unified Tokenizer for Visual Generation and Understanding](https://arxiv.org/abs/2502.20321)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.20321.png)

Vote: 13

Authors: Chuofan Ma, Yi Jiang, Bingyue Peng, Xin Yu, Xiaojuan Qi, Jihan Yang, Zehuan Yuan, Junfeng Wu

- ***What's New***: UniTok은 시각적 생성과 이해를 위한 통합된 화소화기(Tokeniser)로, 고유한 디스크리트 비주얼 토크나이저(Discrete Visual Tokeniser)를 소개합니다. UniTok은 생성 시 미세한 디테일을 인코딩하면서도, 이해를 위한 고차원 의미론을 포착하여 두 가지 목표를 모두 충족시키는 최초의 접근법입니다.
- ***Technical Details***: UniTok은 멀티-코드북 양자화(Multi-codebook Quantization)를 도입하여 잠재 피처 공간을 확장합니다. 이는 코드북을 여러 독립적인 서브-코드북으로 나누어 과도한 코드북 사이즈로 인한 훈련 불안정을 피하며 잠재 코드 공간을 확장합니다. 이러한 수단으로서는 다중 헤드 주의 메커니즘(Multi-head Attention Mechanism)와 유사합니다. UniTok은 통합된 슈퍼비전을 사용하여 재구성 손실(VQVAE)과 이미지-텍스트 대비 손실(CLIP)을 동시에 통합하기 위해 훈련됩니다.
- ***Performance Highlights***: UniTok은 ImageNet에서 256 × 256 해상도로 0.38의 뛴 rFID와 함께 놀라운 성과를 보여주며, zero-shot 정확도 78.6%를 기록했습니다. 이는 도메인-특정 연속형 토크나이저를 능가하는 성과입니다. 또한, 다양한 멀티모달 이해 및 생성 벤치마크에서 새로운 최첨단 성과를 기록하며, 통합된 자동 회귀 MLLM에서 뛰어난 성능을 발휘합니다.

### [NeoBERT: A Next-Generation BERT](https://arxiv.org/abs/2502.19587)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.19587.png)

Vote: 10

Authors: Mariam El Mezouar, Lola Le Breton, Sarath Chandar, Quentin Fournier

- ***What's New***: NeoBERT는 최신 건축 및 훈련 전략을 통합한 차세대 인코더로, BERT 및 RoBERTa 같은 기존 모델을 대체할 수 있도록 설계되었습니다. 이 모델은 심층 및 폭 비율을 최적화하여 4,096 토큰 길이의 문맥을 처리할 수 있으며, GLUE 및 MTEB 벤치마크에서 최첨단 성과를 보여줍니다.
- ***Technical Details***: NeoBERT는 BERT와 RoBERTa에서 벗어나 RoPE(Rotary Position Embeddings) 및 Pre-Layer Normalization을 통합하여 성능을 개선했습니다. 또한, RefinedWeb과 같은 최신 데이터를 활용하여 대규모 토큰(2.1T)으로 훈련되었습니다. 이 모델은 AdamW 옵티마이저와 cosine decay 학습률 스케줄러를 사용하여 2단계 훈련 절차를 통해 범위와 정확도를 극대화합니다.
- ***Performance Highlights***: NeoBERT는 MTEB에서 다른 대형 프리트레인드 모델들보다 4.5% 높은 상대적인 성능을 보여주며, GLUE 벤치마크에서 기존의 인코더 모델들을 뛰어넘습니다. 중간 사이즈 모델임에도 불구하고, NeoBERT는 2.1T 토큰으로 훈련되어 확장된 문맥 길이와 효율적인 추론 속도를 유지합니다.

### [Multimodal Representation Alignment for Image Generation: Text-Image Interleaved Control Is Easier Than You Think](https://arxiv.org/abs/2502.20172)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.20172.png)

Vote: 9

Authors: Liang Chen, Baobao Chang, Leon Vinci, Shuai Bai, Weichu Xie, Junyang Lin, Wenhao Chai, Haozhe Zhao

- ***What's New***: DREAM ENGINE는 복잡한 텍스트-이미지 혼합 제어를 위한 효율적이고 통합된 프레임워크로, 대형 멀티모달 모델(Large Multimodal Models; LMMs)을 활용하여 독창적이고 맞춤화된 이미지 생성에 탁월한 성능을 발휘합니다. 이는 기존 텍스트 기반 인코더를 대체할 수 있도록 설계되었습니다.
- ***Technical Details***: DREAM ENGINE은 공개 소스 텍스트-이미지 생성 모델인 Stable Diffusion v3.5를 기반으로 LMM과 경량화된 프로젝터를 통합하여 텍스트와 이미지의 혼합 신호를 개념적으로 정렬 가능한 대표 공간으로 변환합니다. 두 단계의 교육 패러다임을 통해 다양한 백본 모델 간 표현 공간을 효율적으로 정렬하며 텍스트와 이미지가 혼합된 조건에 따라 이미지를 생성합니다.
- ***Performance Highlights***: DREAM ENGINE은 GenEval 벤치마크에서 0.69의 종합 점수를 기록하여, state-of-the-art 텍스트-이미지 모델인 SDv3.5 (0.71)에 근접한 성능을 보여주었습니다. 이는 텍스트 인코더 없이도 강력한 멀티모달 제어를 가능하게 함을 보여주며, 여러 입력 이미지와 합성 지침을 처리할 수 있는 역량을 입증합니다.

### [Lean and Mean: Decoupled Value Policy Optimization with Global Value Guidance](https://arxiv.org/abs/2502.16944)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.16944.png)

Vote: 9

Authors: Saravan Rajmohan, Chenghua Huang, Fangkai Yang, Dongmei Zhang, Qi Zhang, Zhixu Li, Pu Zhao, Lu Wang, Qingwei Lin

- ***What's New***: 이 논문에서는 기존의 프록시말 폴리시 최적화(Proximal Policy Optimization; PPO) 기반의 '인간 피드백을 통한 강화 학습(Reinforcement Learning from Human Feedback; RLHF)'에서 발생하는 연산 복잡성과 불안정성을 해결하기 위해 '분리된 가치 정책 최적화(Decoupled Value Policy Optimization; DVPO)'를 제안합니다. 이 새로운 프레임워크는 전통적인 보상 모델을 미리 학습된 글로벌 가치 모델(Global Value Model; GVM)로 대체하여, 배우-비평가(Actor-Critic) 간의 상호 의존성을 제거합니다.
- ***Technical Details***: DVPO는 정책 경로에 조건화된 GVM을 사용하여 토큰 수준의 예상 복귀 값을 예측하며, 배우-비평가 간의 상호 의존성을 제거합니다. 이 방법은 GPU 메모리 사용량을 40%, 훈련 시간을 35% 줄입니다. GVM은 정책 궤적에 따라 사전 학습되며, 고정된 형태로 정책 최적화에 대한 안내자 역할을 합니다. 또한, RLHF 데이터 외의 추가 정보 없이, 표준 RL 목표를 사용하여 GVM 기반 정책 최적화를 진행합니다.
- ***Performance Highlights***: 다양한 벤치마크에서 DVPO는 기존의 효율 높은 RLHF 방법들보다 우수하며, 상태-of-the-art 수준의 PPO와 유사한 성능을 보여줍니다. 특히 훈련 시간과 GPU 사용량을 기존 방법 대비 각각 35% 이상 줄이는 데 성공했습니다. 이는 대규모 언어 모델 미세 튜닝에서 DVPO의 확장성과 안정성을 강조합니다.

### [FlexiDiT: Your Diffusion Transformer Can Easily Generate High-Quality Samples with Less Compute](https://arxiv.org/abs/2502.20126)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.20126.png)

Vote: 9

Authors: Markos Georgopoulos, Yuming Du, Yeongmin Kim, Albert Pumarola, Artsiom Sanakoyeu, Gregor Bachmann, Ali Thabet, Jonas Kohler, Sotiris Anagnostidis, Edgar Schönfeld

- ***What's New***: FlexiDiT는 기존의 정적인 컴퓨팅 예산을 동적 전략으로 전환하여 사전 학습된 Diffusion Transformer(DiT) 모델을 유연하게 변환하여 다양한 컴퓨팅 예산에서 이미지를 생성할 수 있는 프레임워크를 제안합니다. 이 방법은 정적 모델에 비해 40% 이상의 FLOPs를 절감하면서도 이미지 품질 저하 없이 클래스 조건부 및 텍스트 조건부 이미지 생성이 가능합니다.
- ***Technical Details***: FlexiDiT는 DiT 모델을 적절한 패치 크기(patch size)를 조정하여 다양한 길이의 시퀀스를 처리할 수 있도록 합니다. 각 디노이징 스텝에서 적절한 이미지 특성을 활용하여 특정 스텝에 적은 컴퓨팅을 할당함으로써 계산 절감 효과를 얻습니다. 이 방법은 단일 유연한 모델에 의해 처리되며, 클래스 조건부 및 텍스트 조건부 이미지 생성 모두에서 성공적으로 적용되었습니다. 또한 비디오 생성에도 확장하여 최고 75%의 계산 절감을 달성할 수 있습니다.
- ***Performance Highlights***: FlexiDiT는 기존의 고정된 계산 모델과 비교하여 상당한 계산 절감을 이루며, 최소한의 성능 손실로 동일한 수준의 이미지 품질을 유지합니다. 예를 들어, 이미지 생성에서 가장 효율적인 설정은 58%의 계산 비용으로 동일한 품질을 달성하는 것입니다. 고해상도 이미지 생성 실험에서, 현재 전통적인 접근법보다 상당한 계산 절감 효과를 보여주며, 이는 고해상도 비디오 생성에서도 마찬가지 입니다.

### [Guardians of the Agentic System: Preventing Many Shots Jailbreak with Agentic System](https://arxiv.org/abs/2502.16750)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.16750.png)

Vote: 7

Authors: Shehnaz Khaled, Md Jafor Sadek, Saikat Barua, Rafiul Islam, Mostafizur Rahman, Ahmedul Kabir

- ***What's New***: 이 연구는 Large Language Model(LLM) 기반의 에이전트 시스템의 보안을 강화하기 위해 Reverse Turing Test, 다중 에이전트 시뮬레이션, 그리고 다양한 방법을 결합하여 대형 멀티 에이전트 시스템의 탈옥 시도를 막는 방법론을 제안합니다.
- ***Technical Details***: 연구는 게임 체인(Turing Test)을 반대로 적용하여 악성 행위자를 탐지하는 에이전트를 설계하고, 에이전트 시스템의 정렬을 평가하며, 다중 프로프트 탈옥 공격에 대해 방어 시스템의 성능을 측정하는 실험적 방법론을 활용했습니다. 이는 GamoraAI를 통해 네트워크 환경을 스캔하고 위협을 탐지하며 해지하는 과정을 통해 진행됩니다. 또한, 다중 에이전트 환경 내에서 에이전트 간의 상호작용과 정렬을 잡아내고 위협을 탐지하는 기술을 사용합니다.
- ***Performance Highlights***: GEMINI 1.5 pro 모델은 다양한 실험에서 높은 정확도를 기록하며 우수한 성능을 보여주었습니다. Reverse Turing Test에서는 94%의 정확도를 달성했으며, 여러 에이전트 설정에서도 높은 검출 능력을 보여줬습니다. 그러나 일부 모델은 공격에 노출된 상태에서 상당한 약점을 드러냅니다. 특히, 많은 프로프트 길이에 대한 공격 시 성공률이 높아지는 경향을 나타내며 이는 시스템의 안전성에 큰 위협이 됩니다.

### [SoRFT: Issue Resolving with Subtask-oriented Reinforced Fine-Tuning](https://arxiv.org/abs/2502.20127)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.20127.png)

Vote: 7

Authors: Pengfei Gao, Zexiong Ma, Yanzhen Zou, Xiangxin Meng, Chao Peng, Bing Xie

- ***What's New***: SoRFT는 대형 언어 모델(LLMs)의 문제 해결 능력을 강화하기 위해 서브테스크 지향 강화 미세 조정(Subtask-oriented Reinforced Fine-Tuning)을 제안합니다. 주요 기술로는 문제가 파일, 함수, 라인 등 여러 서브테스크로 나뉘며, 각각의 서브테스크를 위한 규칙 기반 강화 학습을 포함합니다.
- ***Technical Details***: SoRFT는 두 가지 훈련 단계로 구성됩니다: (1) 타당성 검사가 이루어진 코트(Chain-of-Thought; CoT) 데이터를 사용한 거절 샘플링 지도 학습(Rejection-sampled Supervised Fine-Tuning; SFT)과 (2) Proximal Policy Optimization(PPO)을 사용한 규칙 기반 강화 학습입니다. 각 서브테스크별로 정확한 답을 기준으로 보상 규칙을 정의하여 모델 성능을 최적화합니다.
- ***Performance Highlights***: SoRFT로 훈련된 모델은 SWE-Bench Verified에서 SoRFT-Qwen-7B가 21.4%의 문제 해결율을 보여 동급 오픈 소스 모델들 중 최고 성능을 기록하였고, SoRFT-Qwen-32B는 더 큰 파라미터를 가진 모델들보다 더 나은 성과를 보여줍니다. 이는 SoRFT가 비용 효율적인 대안이 될 수 있음을 시사합니다.

### [Mobius: Text to Seamless Looping Video Generation via Latent Shift](https://arxiv.org/abs/2502.20307)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.20307.png)

Vote: 7

Authors: Jianfei Yuan, Xiaodong Cun, Bin Xiao, Xiuli Bi, Chi-Man Pun, Bo Liu, Yong Zhang

- ***What's New***: Mobius는 사용자의 주석 없이도 텍스트 설명만으로 직관적으로 무한 반복 동영상을 생성할 수 있는 혁신적인 방법을 제안합니다. 기존의 텍스트-to-Video 확산 모델(pre-trained Text-to-Video latent diffusion model)을 사용하여 트레이닝 없이 무한 루핑 영상을 생성합니다. 이 방법은 시네마그래프(Cinemagraph)와 달리 이미지로 나타내지 않아 더욱 다이나믹한 움직임과 자연스러운 시각적 효과를 제공합니다.
- ***Technical Details***: 제안된 Mobius 방법은 비디오 확산 모델(Video Diffusion Model)의 멀티프레임 라텐트 디노이징(multi-frame latent denoising)을 활용하여 각 프레임이 동등하게 고려되는 루핑 비디오를 생성합니다. 라텐트 시프트 전략(Latent Shift)을 사용하여 접속된 라텐트 사이클을 구성하고, 시퀀스 내에서 프레임 위치를 이동시켜 일관된 동영상 시각 효과를 유지합니다. 또한, 프레임-불변 라텐트 디코딩(frame-invariant latent decoding)과 RoPE-보간법(RoPE-interpolation)을 사용하여 더욱 높은 품질의 비디오를 생성합니다.
- ***Performance Highlights***: 수치적 비교에서 Mobius는 기존의 방법들에 비해 더 나은 시각적 품질과 텍스트-비디오 정렬을 보여주었습니다. 동영상의 동적 및 부드러움 측면에서도 높은 점수를 기록하였고, 최종적인 프레임과 초기 프레임 간의 차이가 적어, 루핑 비디오 생성에 탁월한 성능을 입증했습니다. 사용자 연구 결과 또한 Mobius의 시각적 품질, 시간적 일관성, 그리고 비주얼 다이나믹 면에서 우수함을 나타냈습니다.

### [Building Interactable Replicas of Complex Articulated Objects via Gaussian Splatting](https://arxiv.org/abs/2502.19459)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.19459.png)

Vote: 6

Authors: Yu Liu, Junfeng Ni, Song-Chun Zhu, Ruijie Lu, Siyuan Huang, Baoxiong Jia

- ***What's New***: ArtGS는 복잡한 다부분 관절 객체의 상호작용 가능한 복제본을 구축하는 혁신적인 방법으로 3D 가우시안(3D Gaussians)을 활용하여 최고 수준의 성능을 달성합니다. 이는 다양한 객체 상태에서의 정합성을 개선하고 파트-메시 재구성과 관절 학습을 적절히 다루도록 설계되었습니다.
- ***Technical Details***: ArtGS는 대체적으로 두 국가의 설정에서 학습된 관절 객체들에 대한 3D Gaussians를 사용하여 공간 정보를 명시적으로 유지하면서 효율적이고 높은 재구성 품질을 제공합니다. 초기화와 업데이트는 사이조정 정보 프레임워크를 통해 실행되며, 모션 프라이어를 사용한 센터 기반 클러스터링 모듈을 도입하여 각 상태 간의 객체 파트를 최적 정렬시킵니다. 이러한 설계는 대체 말단의 두 개의 입력 관절 상태를 서로 연결하여 메시 재구성을 상호 개선할 수 있게 합니다.
- ***Performance Highlights***: ArtGS는 다양한 합성 및 실제 데이터셋에서 획기적인 성능을 보여줍니다. 복잡한 다부분 객체 재구성 벤치마크에 대한 실험에서 가장 높은 정밀도의 관절 파라미터 추정 및 파트 메시 재구성을 달성하며, 축 모델링 및 전체 효율성에서 의미 있는 개선을 나타냅니다.

### [R1-T1: Fully Incentivizing Translation Capability in LLMs via Reasoning Learning](https://arxiv.org/abs/2502.19735)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.19735.png)

Vote: 6

Authors: Osamu Yoshie, Shimin Tao, Chang Su, Minggui He, Hongxia Ma, Yilun Liu, Hao Yang, Daimeng Wei, Hongyong Zeng, Li Zhang, Weibin Meng, Yuanchang Luo, Boxing Chen

- ***What's New***: R1-T1은 대형 언어 모델(LLMs)에 새로운 추론 학습(Reinforcement Learning)을 통합하여 인센티브 기반 번역을 가능하게 하는 프레임워크입니다. 논문은 다양한 번역 과제에 걸친 인간 정렬(CoTs) 체인을 사용하여 자동 추론 기능을 극대화합니다. 특히, 여섯 가지 공통적인 패턴을 포함한 인간-정렬 CoTs를 통해 일반 번역 문제에 적용합니다.
- ***Technical Details***: R1-T1은 인간 전문가의 번역 패턴을 반영하는 여섯 개의 CoT 템플릿을 통한 작업을 진행합니다. 여기에는 문맥 인식 패러프레이징 및 역번역(back translation) 등이 포함됩니다. 강화 학습의 객체로 사용되는 KL-제약 보상을 활용하여 LLM이 자동으로 새로운 CoT를 발견하고, 역베이스 데이터 없이도 번역 적응을 가능합니다.
- ***Performance Highlights***: R1-T1은 Flores-101 테스트 세트에서 21개의 언어와 80개의 번역 방향에 대한 성능 향상을 보였습니다. 특히, 학습에 포함되지 않았던 15개의 새로운 언어에서도 그 멀티링구얼 능력을 유지했습니다. 이는 기존의 SFT 전략과의 비교를 통해, 일반 번역 문제에의 적응력을 고려할 때 향상된 결과를 나타냅니다.
- ***Methodology***: R1-T1은 Parallel Corpus에 기반한 시드 데이터 세트를 준비하고, 이를 통해 여섯 종류의 CoT 템플릿을 통합하여 번역 추론용 데이터 세트를 구축합니다. 그리고 이를 기반으로 SFT 및 강화 학습을 통해 자가 발전(self-evolution)하는 번역 코스를 형성합니다.

### [Beyond Next-Token: Next-X Prediction for Autoregressive Visual Generation](https://arxiv.org/abs/2502.20388)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.20388.png)

Vote: 5

Authors: Qihang Yu, Sucheng Ren, Alan Yuille, Liang-Chieh Chen, Xiaohui Shen, Ju He

- ***What's New***: 이 논문에서는 기존의 자가회귀(Autoregressive; AR) 모델이 사용하는 '다음 토큰 예측'(Next-Token Prediction) 방식을 확장하여 '다음-X 예측'(Next-X Prediction) 프레임워크를 제안합니다. 여기서 X는 이미지 패치, 셀, 서브샘플, 스케일, 전체 이미지와 같은 다양한 예측 단위를 의미합니다. 또한 소음 기반의 학습 방법으로 교사 강요(Teacher Forcing)에 의한 노출 편향(Exposure Bias)을 경감시킵니다.
- ***Technical Details***: xAR 프레임워크는 불연속 토큰 분류(discrete token classification)를 연속적 엔터티 회귀(continuous entity regression) 문제로 재구성합니다. 토큰 대신 패치, 셀, 또는 전체 이미지를 예측 단위로 사용할 수 있습니다. 또한, 훈련 시에는 '노이즈 컨텍스트 학습(Noisy Context Learning)'을 도입하여, 모델이 깨끗한 원본 토큰이 아닌 노이즈가 섞인 엔터티에 기초해 예측할 수 있게 합니다. 이는 예측 에러가 누적되지 않도록 하며 모델의 강화 학습을 지원합니다.
- ***Performance Highlights***: ImageNet-256 생성 벤치마크에서, 제안된 xAR-B 모델(172M)은 DiT-XL(675M)보다 20배 더 빠르게 추론하면서도 더 나은 성능을 보였고, xAR-H(1.1B)는 1.24의 FID로 새로운 최첨단 상태를 달성했습니다. 이 모델들은 Vision 기반 모듈(DINOv2)이나 추가 안내 간격 샘플링 없이도 성능을 극대화했습니다.

### [On Relation-Specific Neurons in Large Language Models](https://arxiv.org/abs/2502.17355)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.17355.png)

Vote: 4

Authors: Lea Hirlimann, Sascha Rothe, Runsheng Chen, Amir Hossein Kargaran, Hinrich Schütze, Mingyang Wang, Ahmad Dawar Hakimi, Yihong Liu, François Yvon

- ***What's New***: 본 연구는 대형 언어 모델(Large Language Models, LLMs) 내에서 특정 관계에 집중하는 뉴런들의 존재를 탐구하였습니다. 이를 통해 관계에 특정화된 뉴런이 존재함을 이론적으로 제시하고, 그 역할을 실험적으로 검증하였습니다.
- ***Technical Details***: 이 연구는 Llama-2 모델 군을 대상으로 12개의 관계 유형에 대해 신경망의 관계 특정 뉴런을 식별하였습니다. Cuadros et al.(2022)의 방법을 기반으로 뉴런을 식별해, 관계 자체에 의해 활성화되는 뉴런을 통계적으로 분석했습니다. 실험은 사실 기반 질의응답을 통해 새로운 프롬프트로 진행되었으며, 관계 특정 뉴런의 비활성화가 모델의 성능에 미치는 영향을 관찰하였습니다.
- ***Performance Highlights***: 모델의 관계 특정 뉴런을 3,000개 비활성화할 경우, 관련된 사실에 대해 상당한 정확도 감소가 나타났습니다. 이는 뉴런 누적성(neuron cumulativity)을 시사하며, 뉴런 상호작용은 여러 관계에 걸쳐 발생할 수 있음을 보여줍니다. 또한, 비활성화한 뉴런이 관계 간 성능에 미치는 복합 효과 또한 관찰되었습니다.

### [Training Consistency Models with Variational Noise Coupling](https://arxiv.org/abs/2502.18197)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.18197.png)

Vote: 3

Authors: Chieh-Hsin Lai, Yuki Mitsufuji, Luca Ambrogioni, Gianluigi Silvestri, Yuhta Takida

- ***What's New***: 이 논문에서는 'Variational Noise Coupling'을 사용한 새로운 일관성 훈련 방법을 제안합니다. 이 방법은 VAE(Variational Autoencoders) 구조에 영감을 받아 데이터 의존적 노이즈 방출 모델을 사용하여 노이즈-데이터 매핑의 기하학적 측면을 간접적으로 학습합니다.
- ***Technical Details***: 이 연구는 'Flow Matching' 프레임워크를 기반으로하며, 노이즈와 데이터 사이의 조건적 결합 함수(coupling function)를 학습하여 일관성 모델을 향상시킵니다. 훈련 중 데이터-노이즈 결합을 학습하기 위해 추가적인 Kullback-Leibler 발산 손실로 규제된 데이터 의존적 확률 분포를 사용하는 엔코더 구조가 사용됩니다.
- ***Performance Highlights***: 다양한 이미지 데이터셋에서의 실험 결과, 제안된 모델은 비증류 일관성 훈련에서 기존 기준점을 능가했으며, CIFAR-10과 ImageNet 64x64 해상도에서 최첨단(FID) 성과를 달성했습니다.

### [MMKE-Bench: A Multimodal Editing Benchmark for Diverse Visual Knowledge](https://arxiv.org/abs/2502.19870)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.19870.png)

Vote: 3

Authors: Chenrui Shi, Siyuan Qi, Zhi Gao, Zilong Zheng, Qing Li, Kailin Jiang, Yuntao Du

- ***What's New***: MMKE-Bench는 현실 세계의 다양한 시각적 지식을 편집할 수 있는 능력을 평가하기 위해 설계된 포괄적인 멀티모달 지식 편집 벤치마크입니다. 세 가지 편집 작업, 즉 시각적 엔티티 편집, 시각적 의미 편집, 사용자 특화 편집을 포함하여 다양한 편집 작업을 포함하고 있습니다.
- ***Technical Details***: MMKE-Bench는 33개의 광범위한 카테고리에서 2,940개의 지식 조각과 8,363개 이미지를 포함하고 있으며, 평가 질문은 자동으로 생성되고 사람이 검증합니다. 이 벤치마크는 자유 형식의 자연어를 통해 지식을 표현하고 편집하여 보다 유연하고 효과적인 포맷을 제공합니다.
- ***Performance Highlights***: 세 가지 대표적인 멀티모달 모델(BLIP-2, MiniGPT-4, LLaVA-1.5)과 다섯 가지 첨단 지식 편집 방법(FT-LLM, FT-Alignment, IKE, SERAC, MEND)에 대한 평가 결과, 어떤 방법도 모든 기준을 완벽히 충족하지 못했습니다. 특히 시각적 및 사용자 특화 편집은 가장 어려운 것으로 나타났습니다. MMKE-Bench는 멀티모달 지식 편집 기술의 견고성을 평가하기 위한 새로운 표준을 설정하며 이 분야의 발전을 이끌고 있습니다.

### [Adapting Automatic Speech Recognition for Accented Air Traffic Control Communications](https://arxiv.org/abs/2502.20311)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.20311.png)

Vote: 3

Authors: Justin Juin Hng Wong, Marcus Yu Zhe Wee, Aloysius Keng Siew Han, Yong Zhi Lim, Lynus Lim, Joe Yu Wei Tan, En Hao Tew, Prannaya Gupta, Dillion Lim

- ***What's New***: 이 연구는 동남아시아 억양(SEA-accented)의 ATC(항공 교통 관제) 의사소통을 위한 자동 음성 인식(Automatic Speech Recognition; ASR) 모델을 특정 억양에 맞게 개선하여, SEA-억양 ATC 스피치의 WER(Word Error Rate)를 9.82%까지 낮추는 데 성공했습니다. 이는 억양 중심의 훈련과 지역별 데이터셋의 중요성을 강조하며, 자원 제약 하에 있는 군사 작전에서 ASR 시스템을 효과적으로 배치할 수 있는 경로를 제공합니다.
- ***Technical Details***: 이 연구에서는 새로운 SEA-억양 ATC 데이터셋을 구축하고, Whisper 모델을 억양에 맞게 미세 조정(Fine-Tuning)하였습니다. 데이터셋은 Spectral Gating 방식을 사용하여 노이즈를 제거한 후, 데이터는 훈련, 테스트, 검증 세 부분으로 나누어 사용됩니다. Whisper 모델 중 Small, Large v3 Turbo 모델이 선택되어 30회의 에포크 동안 미세 조정을 진행하였으며, 특히 동남아시아 억양에 최적화된 모델 성능을 확보하였습니다.
- ***Performance Highlights***: 실험 결과, fine-tuned Whisper Small 모델은 SEA-억양 데이터셋에서 0.0982 WER를 기록하며, ATCO2 및 ATCOSIM 데이터셋과 다른 억양을 가진 데이터셋과의 비교에서 각각의 성능을 보여줍니다. 본 연구의 성과는 현재의 일반 목적 ASR 모델들이 익숙한 억양에서 잘 작동하는 반면, SEA-억양 같은 특정 억양에서는 한계를 보일 수 있음을 시사합니다.

### [Efficient Gaussian Splatting for Monocular Dynamic Scene Rendering via Sparse Time-Variant Attribute Modeling](https://arxiv.org/abs/2502.20378)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.20378.png)

Vote: 1

Authors: Xingyi Yang, Hanyang Kong, Xinchao Wang

- ***What's New***: Efficient Dynamic Gaussian Splatting (EDGS)는 단조로운 시간-변화 속성 모델링(Sparse Time-Variant Attribute Modeling)을 통해 역동적인 장면을 효율적으로 표현하는 새로운 방식으로, 단안 비디오(Monocular Video)에서 역동적인 장면을 고속으로 렌더링하는데 중점을 둔 최신 기술입니다.
- ***Technical Details***: EDGS는 동적 장면을 희소 앵커-그리드 표현(Sparse Anchor-Grid Representation)으로 형성하며, 고전적 커널 표현(Kernel Representation)을 이용하여 밀집된 Gaussian의 움직임 흐름을 계산합니다. 또한, 비감독 학습(Unsupervised Learning)을 활용하여 정적 영역에 해당하는 앵커를 효율적으로 필터링하여 변형 가능한 객체에만 MLP을 통해 시간-변화 속성을 질의합니다.
- ***Performance Highlights***: HyperNeRF 및 NeRF-DS와 같은 실제 데이터셋 실험에서 EDGS는 평균 PSNR (Peak Signal-to-Noise Ratio) 점수를 개선하며 기존의 최첨단 기법보다 더 빠른 렌더링 속도(FPS)를 달성했습니다. 이는 적은 Gaussian 수로도 높은 품질의 렌더링을 유지함을 의미합니다.

### [PlanGEN: A Multi-Agent Framework for Generating Planning and Reasoning Trajectories for Complex Problem Solving](https://arxiv.org/abs/2502.16111)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.16111.png)

Vote: 1

Authors: Zifeng Wang, Hamid Palangi, Swaroop Mishra, Yanfei Chen, Hossein Mobahi, Chen-Yu Lee, Palash Goyal, Hootan Nakhost, Xin Liu, Jindong Gu, Tomas Pfister, Chitta Baral, Long Le, Mihir Parmar

- ***What's New***: PlanGEN은 복잡한 문제 해결을 위한 계획 및 추론 경로를 생성하는 모델-애그노스틱(m-agnostic)이며, 쉽게 확장 가능한 멀티-에이전트 프레임워크입니다. 이 프레임워크는 제약 에이전트, 검증 에이전트, 선택 에이전트의 세 가지 주요 구성 요소를 포함하며, 이를 통해 자연어 계획과 복잡한 요구에 대한 적응성을 향상시킵니다.
- ***Technical Details***: PlanGEN은 제약, 검증, 선택의 세 가지 에이전트로 구성되어 있으며, 각 에이전트는 특정한 작업에 맞춘 프롬프트가 장착된 오프-더-쉘프 LLM을 사용합니다. 계획 질을 검증하고 피드백을 생성하며, 수정된 UCB(Upper Confidence Bound)를 사용하여 사례 복잡성에 따라 최적의 알고리즘을 선택합니다. 널리 사용되는 Best of N, Tree-of-Thought (ToT), REBASE 알고리즘을 활용하여 알고리즘을 동적으로 선택합니다.
- ***Performance Highlights***: PlanGEN은 다양한 벤치마크에서 강력한 성능을 보여줍니다. NATURAL PLAN에서는 평균 약 8% 향상, OlympiadBench에서는 MATH 카테고리에서 ∼5% 향상, DocFinQA에서는 ∼7% 향상을 이루었으며, GPQA에서도 최고 성과를 보였습니다. 이는 PlanGEN의 제약 기반 검증 및 적응형 선택 방법이 복잡한 계획 및 추론 문제 해결에 효과적임을 강조합니다.

