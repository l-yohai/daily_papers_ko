## Daily Papers (2025-02-20)

### [Qwen2.5-VL Technical Report](https://arxiv.org/abs/2502.13923)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.13923.png)

Vote: 87

Authors: Zheren Fu, Haiyang Xu, Zhibo Yang, Junyang Lin, Sibo Song, Yuanzhi Zhu, Yiheng Xu, Keqin Chen, Wei Ding, Pengfei Wang, Xuejing Liu, Tianbao Xie, Wenbin Ge, Shuai Bai, Peng Wang, Humen Zhong, Mingkun Yang, Xi Zhang, Zhaohai Li, Shijie Wang, Jun Tang, Jialin Wang, Hang Zhang, Jianqiang Wan, Kai Dang, Jiabo Ye, Zesen Cheng

- ***What's New***: Qwen2.5-VL 모델이 출시되었습니다. 이 모델은 시각 언어 이해 분야에서 중요한 발전을 이루었으며, 시각인식과 객체 로컬라이제이션, 문서 파싱 및 장시간 비디오 이해 능력에서 획기적인 진전을 보였습니다. 특히 Qwen2.5-VL은 절대 좌표나 JSON 형식을 사용한 객체 정확한 위치 파악이 가능한 점이 주목할 만합니다. 다양한 크기의 이미지를 다이나믹한 해상도로 처리하고, 장시간(최대 몇 시간)에 걸친 비디오의 사건을 초 단위로 로컬라이징하는 것이 가능합니다.
- ***Technical Details***: 모델의 아키텍처는 대규모 언어 모델(LLM)과 비전 인코더로 구성되어 있으며, Window Attention을 사용하여 계산 오버헤드를 줄입니다. Vision Transformer (ViT) 아키텍처를 새롭게 디자인하여 2D-RoPE와 window attention을 통합하였고, 입출력 이미지는 본래 해상도대로 처리되며, 4개의 계층만이 self-attention을 사용합니다. 또한 MRoPE를 통해 시간적 순서를 절대 시간에 맞춰 정렬하여 더 세련된 시간 순서 학습을 가능하게 합니다.
- ***Performance Highlights***: Qwen2.5-VL-72B 모델은 GPT-4o, Claude 3.5 Sonnet과 같은 최첨단 모델들과 동등하거나 더 나은 성능을 보였으며, 특히 문서 및 다이어그램 이해에서 두각을 나타냅니다. 소규모 모델들(Qwen2.5-VL-7B 및 Qwen2.5-VL-3B)도 자원 제약 환경에서 탁월한 성능을 발휘하여 경쟁 모델들을 능가했습니다. 실험 결과, Qwen2.5-VL 시리즈는 일반적인 VQA(Visual Question Answering)에서 뛰어난 유연성과 적응력을 보여주었으며, 각종 평가 벤치마크에서 우수한 성능을 입증했습니다.

### [RAD: Training an End-to-End Driving Policy via Large-Scale 3DGS-based Reinforcement Learning](https://arxiv.org/abs/2502.13144)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.13144.png)

Vote: 31

Authors: Xiaoyang Guo, Hao Gao, Shaoyu Chen, Qian Zhang, Xinbang Zhang, Wenyu Liu, Bo Jiang, Haoran Yin, Xinggang Wang, Ying Zhang, Yuechuan Pu, Yiang Shi, Bencheng Liao, Xiangyu Li

- ***What's New***: RAD는 대규모 3DGS 기반 강화 학습(Reinforcement Learning; RL)을 통해 에지-투-에지 자율주행(End-to-End Autonomous Driving; AD) 정책을 훈련하는 프레임워크를 제안합니다. 이는 기존의 모방 학습(Imitation Learning; IL) 기반 방법론이 가진 인과 혼란과 개방형 루프 갭 문제를 해결하며, 현실 세계의 인과관계를 모델링하고 안전도 높은 주행을 위한 보상을 설계함으로써 보다 효율적인 학습을 가능하게 합니다.
- ***Technical Details***: RAD는 3D Gaussian Splatting(3DGS)을 활용하여 현실 세계의 디지털 복제본을 생성하는 3단계 학습 파라다임을 도입합니다. 이를 통해 AD 정책은 대규모 상태 공간 탐색과 파생분포 상황을 처리하는 학습이 가능합니다. RL 학습 과정에서 IL은 정규화 항으로 통합되어 인간 운전자 행동과의 유사성을 유지합니다. 평가를 위해 RAD는 다양한 미지의 3DGS 환경을 포함한 폐쇄 루프 평가 벤치마크를 활용합니다.
- ***Performance Highlights***: RAD는 폐쇄 루프 평가에서 기존의 IL 기반 방법과 비교하여 충돌률에서 3배 낮은 성능을 보이며, 특히 안전과 궤적 일관성 측면에서 우수한 성능을 보입니다. 이러한 결과는 RL이 AD 정책이 일반적인 충돌 회피 능력을 학습하는 데 도움이 된다는 것을 나타냅니다.

### [SongGen: A Single Stage Auto-regressive Transformer for Text-to-Song Generation](https://arxiv.org/abs/2502.13128)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.13128.png)

Vote: 26

Authors: Xiaoyi Dong, Jiaqi Wang, Zhixiong Zhang, Yuhang Zang, Shuangrui Ding, Dahua Lin, Yuhang Cao, Zihan Liu, Pan Zhang

- ***What's New***: SongGen은 텍스트를 기반으로 한 노래 생성(Task-to-Song Generation)을 위한 단일 단계 자동 회귀 트랜스포머(Single Stage Auto-regressive Transformer) 모델로서, 기존의 복잡한 여러 단계 절차를 단순화하여 학습과 추론 파이프라인을 간편하게 만듭니다. 이 모델은 다양한 음악 속성을 개별적으로 제어할 수 있으며, 보컬 클로닝을 지원하여 유저가 정의한 세부사항에 맞춘 노래 생성을 가능하게 합니다.
- ***Technical Details***: SongGen은 단일 단계 자동 회귀 모델로, 혼합 모드(Mixed Mode)와 이중 트랙 모드(Dual-track Mode)를 지원합니다. 혼합 모드는 보컬과 반주가 동시에 혼합된 출력을 생성하며, 이중 트랙 모드는 보컬과 반주를 분리된 트랙으로 생성하여 더 많은 전문 후속 편집이 가능하게 합니다. 데이터 부족을 해결하기 위해 피쳐 선별을 통한 자동화된 데이터 전처리 파이프라인을 설계하였으며, 필요한 데이터를 수집하고 품질을 관리합니다.
- ***Performance Highlights***: SongGen은 MusicCaps 데이터셋 테스트에서 우수한 성능을 보였으며, 객관적 평가와 주관적 평가 모두에서 기존 모델을 능가했습니다. 특히 보컬의 명료성과 자연스러운 발음 기술에 있어서도 높은 평가를 받으며, 전문가들 조차도 음악성과 보컬-반주 조화 측면에서 상당히 경쟁력 있는 성능을 보여줍니다.

### [MoM: Linear Sequence Modeling with Mixture-of-Memories](https://arxiv.org/abs/2502.13685)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.13685.png)

Vote: 21

Authors: Yu Cheng, Disen Lan, Weigao Sun, Jiaxi Hu, Jusen Du

- ***What's New***: MoM(Mixture-of-Memories)은 새로운 아키텍처로, 다양한 독립적인 메모리 상태를 사용하여 기존 선형 시퀀스 모델링 기술보다 뛰어난 성능을 발휘합니다. 이를 통해 메모리 용량을 확장하고 메모리 간섭을 최소화하여 기억 집중도가 높은 작업에서 탁월한 성과를 달성합니다.
- ***Technical Details***: MoM은 심리학적 인사이트에서 영감을 받아 개발된 아키텍처로, 입력 토큰을 특정 메모리 상태로 라우팅하는 네트워크를 활용합니다. 이러한 방식은 독립적인 메모리 상태를 유지하면서도 각 메모리 상태의 계산 복잡도가 선형적으로 유지되므로 훈련과 추론에서의 효율성을 보장합니다.
- ***Performance Highlights***: MoM은 리콜 집중도가 높은 다운스트림 언어 작업에서 현재의 선형 시퀀스 모델들을 능가하는 성능을 보였으며, 특히 Transformer 모델과 견줄 수 있는 성과를 이룬 것이 특기할 만합니다. 회상 작업에서 이전보다 높은 효율성과 성능을 자랑합니다.

### [Is That Your Final Answer? Test-Time Scaling Improves Selective Question Answering](https://arxiv.org/abs/2502.13962)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.13962.png)

Vote: 21

Authors: Jeffrey Cheng, William Jurayj, Benjamin Van Durme

- ***What's New***: 이 논문은 테스트 시간 컴퓨팅(Test-Time Compute)를 스케일링하여 선택적 질문 응답(Selective Question Answering; QA)을 개선하는 새로운 평가 방식을 제공합니다. 모델이 모든 질문에 답변할 필요가 없는 상황에서 다양한 수준의 응답 위험(Non-Zero Response Risk)을 고려하며, 모델이 자신감이 있는 답변만 제공하도록 하는 방법론을 제시합니다.
- ***Technical Details***: 테스트 시간 컴퓨팅 스케일링은 긴 논리 체인(Chains of Thought)을 활용하여 수학적 문제에 대한 성능을 향상시키는 기술로, 사용된 컴퓨팅 예산(Compute Budget)과 자신감 임계값(Confidence Threshold)을 통해 모델의 응답 여부를 결정하는 선택 함수(Selection Function)가 도입되었습니다. 예산과 임계값은 테스트 시간 결정(Test-Time Decision)으로서, 컴퓨팅 버짓은 추론시 사용된 토큰 수로, 자신감은 답변 토큰의 로그 확률의 합으로 평가됩니다.
- ***Performance Highlights***: 테스트에서 DeepSeek-R1-32B와 s1 모델은 선택적인 QA 환경에서 서로 다른 컴퓨팅 예산과 자신감 임계값 하에 평가되었으며, Jeopardy Odds 설정에서 R1-32B는 컴퓨팅 예산이 큰 경우 우수한 성능을 보였습니다. 이 실험은 선택적 질문 응답에서 모델이 제시하지 않은 답변의 위험 수준을 어떻게 다룰 수 있는지를 보여주며, 모델의 선택적 분류 성능을 개선하는 데 기여할 수 있습니다.

### [Craw4LLM: Efficient Web Crawling for LLM Pretraining](https://arxiv.org/abs/2502.13347)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.13347.png)

Vote: 19

Authors: Zhiyuan Liu, Shi Yu, Chenyan Xiong

- ***What's New***: CRAW4LLM은 LLM(Large Language Model) 사전 학습을 위한 웹 크롤링 효율을 개선한 방법을 제안합니다. 기존의 그래프 연결성 기반의 우선순위 대신 웹 페이지의 사전 학습에 미치는 영향을 우선 순위 점수로 사용하여 고품질 사전 학습 데이터를 획득하는 새로운 접근법입니다.
- ***Technical Details***: CRAW4LLM은 웹 그래프를 탐색할 때, 새로운 문서들이 발견될 때마다 사전 학습 영향 점수(pretraining influence score)를 계산하여 해당 웹 페이지를 크롤링 우선순위에 반영합니다. 이 점수는 사전 학습 데이터 필터링 파이프라인에서 유래하며, 문서가 사전 학습에 얼마나 중요한지를 평가합니다. 이렇게 함으로써 연결성 기반 크롤링과는 다른 방식으로 웹 그래프를 탐색하여 사전 학습에 유용한 문서들을 발견합니다.
- ***Performance Highlights***: CRAW4LLM을 통해 크롤링된 데이터 기반으로 사전 학습한 LLM은 기존의 사전 크롤링-후-선택(crawl-then-select) 방식보다 뛰어난 성능을 보였습니다. 크롤링 데이터의 21%만으로도 95%의 성능을 달성하였으며, 이는 전통적인 그래프 연결성 기반 크롤러가 동일 성능을 얻기 위해 처리해야 하는 문서의 약 4.8배를 필요로 하는 것과 대조적입니다.

### [LongPO: Long Context Self-Evolution of Large Language Models through Short-to-Long Preference Optimization](https://arxiv.org/abs/2502.13922)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.13922.png)

Vote: 18

Authors: Guanzheng Chen, Xin Li, Lidong Bing, Michael Qizhe Shieh

- ***What's New***: LongPO는 대형 언어 모델(Large Language Models; LLMs)의 긴 문맥에서의 성능 저하 문제를 해결하기 위한 새로운 방법론으로, 짧은 문맥의 능력을 긴 문맥으로 자기진화(Self-Evolution)하여 이전하는 기술을 제안합니다. 이 방법은 짧은 문맥에서 학습된 능력을 내부적으로 긴 문맥으로 전이시키고, 외부의 긴 문맥 주석 데이터에 의존하지 않고도 긴 문맥 과제를 수행할 수 있도록 합니다.
- ***Technical Details***: LongPO는 짧은 문맥에서부터 긴 문맥까지 설정된 선호도 데이터(Preference Data)를 사용하여 모델을 최적화하는 방식입니다. 여기에는 동일한 명령어에 대해 긴 문서와 그 축약된 짧은 문맥의 입력으로 만들어진 응답 쌍이 포함됩니다. 이 선호도는 짧은 문맥 정렬에서 길러진 능력과 잠재력을 보여주며, 긴 문맥 정렬 시 감소될 수 있습니다. LongPO는 또한 KL 발산(KL Divergence)을 사용하여 짧은 문맥 성능의 감소를 완화하는 짧은-긴 제약을 포함합니다.
- ***Performance Highlights***: LongPO로 훈련된 모델은 긴 문맥 평가에서 GPT-4-128K와 같은 상위 모델과 비교할 수 있는 성능을 보여주며, 짧은 문맥에서의 성능도 완전히 유지합니다. 특히, Mistral-7B-LongPO-128K 모델은 InfiniteBench에서 39.27점을 기록하여 GPT-4-128K의 34.81점을 초과하는 결과를 얻었습니다. 이는 긴 문맥 주석 데이터를 대규모로 포함한 모델들과도 경쟁하거나 그 이상임을 시사하며, LongPO의 효율성을 입증합니다.

### [Small Models Struggle to Learn from Strong Reasoners](https://arxiv.org/abs/2502.12143)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.12143.png)

Vote: 17

Authors: Zhangchen Xu, Yuetai Li, Bhaskar Ramasubramanian, Bill Yuchen Lin, Luyao Niu, Radha Poovendran, Xiang Yue, Fengqing Jiang

- ***What's New***: 이 논문은 작은 모델들이 강력한 사상가(Mentors)의 복잡한 추론 역량을 지속적으로 이익으로 얻지 못한다는 흥미로운 현상을 공개했습니다. 대신, 작은 모델들은 그들의 고유 학습 능력에 더 잘 맞는 짧고 단순한 추론 체인에서 더 나은 성능을 발휘합니다. 이를 해결하기 위해, 저자들은 Mix Distillation이라는 전략을 제안했습니다.
- ***Technical Details***: Mix Distillation은 긴 Chain-of-Thought (CoT)와 짧은 CoT 예제를 결합하거나 큰 모델과 작은 모델의 응답을 혼합하는 두 가지 구성 요소로 이루어져 있습니다. 이 방법은 작은 모델들이 그들의 능력에 더 적합한 추론 체인을 학습할 수 있도록 돕습니다. 실험에서는 다양한 크기의 Qwen 및 Llama 모델들이 사용되었습니다.
- ***Performance Highlights***: 실험 결과, Mix Distillation은 표준 증류보다 작은 모델의 추론 성능을 현저히 개선했습니다. 예를 들어, Qwen2.5-3B-Instruct는 Mix-Long을 사용하여 MATH와 AMC에서 8점 이상 향상되었으며, Mix-Large를 사용할 경우 MATH, AIME 및 AMC에서 7점 이상 향상되었습니다.

### [Autellix: An Efficient Serving Engine for LLM Agents as General Programs](https://arxiv.org/abs/2502.13965)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.13965.png)

Vote: 14

Authors: Zhifeng Chen, Michael Luo, Xiaoxiang Shi, Yichuan Wang, Ion Stoica, Joseph E. Gonzalez, Tianjun Zhang, Yanping Huang, Justin Wong, Chi Wang, Colin Cai

- ***What's New***: Autellix는 LLM(대형 언어 모델) 에이전트를 일반 프로그램으로 제공하기 위한 효율적인 서빙 엔진으로, 프로그램들 간의 종속성을 고려하여 최적화하는 최초의 시스템입니다. 기존 시스템의 대기 시간을 줄이고 프로그램 중심의 스케줄링을 통해 전체 성능을 4-15배 개선합니다.
- ***Technical Details***: Autellix는 프로그램을 일급 시민으로 대우하여, 프로그램 수준의 컨텍스트를 활용하여 LLM 호출을 최적화하는 스케줄링 알고리즘을 도입합니다. PLAS(Program-Level Attained Service)와 ATLAS(Adaptive Thread-Level Attained Service)로 싱글 및 멀티 스레드 프로그램을 처리하며, 대기 시간을 줄이고 엔진의 처리량을 향상시킵니다. 특히, Autellix는 GPU 메모리 활용을 개선하기 위해 보다 효율적인 메모리 스왑 커널을 사용합니다.
- ***Performance Highlights***: Autellix는 최신 시스템(vLLM)과 비교하여 평균적으로 프로그램 처리량을 4-15배 향상시킵니다. 실험 결과, Autellix는 vLLM의 한계를 뛰어넘어 더 낮은 지연 시간과 더 높은 처리량을 제공하며, 특히 혼합 워크로드에서 프로그램 및 호출 수준의 블로킹을 관리하여 성능을 극대화할 수 있음을 입증했습니다.

### [SearchRAG: Can Search Engines Be Helpful for LLM-based Medical Question Answering?](https://arxiv.org/abs/2502.13233)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.13233.png)

Vote: 9

Authors: Tianming Liu, Quanzheng Li, Xiang Li, Yucheng Shi, Canyu Chen, Tianze Yang, Ninghao Liu

- ***What's New***: SearchRAG는 실시간 검색 엔진(Real-time Search Engines)을 활용하여 의학 질문에 대한 정답 정확도를 개선하기 위한 새로운 프레임워크입니다. 이러한 최적화된 시스템은 복잡한 의학 질문을 검색에 적합한 쿼리로 변환하고 불확실성 기반의 지식 선택(Uncertainty-Based Knowledge Selection)을 통해 LLM에 가장 관련 있는 의학 지식을 제공하게 설계되었습니다.
- ***Technical Details***: SearchRAG 프레임워크는 합성 쿼리 생성(Synthetic Query Generation)을 통해 원래의 복잡한 의학 질문을 LLM를 이용하여 다양한 검색 쿼리로 변환합니다. 쿼리 샘플링 시 고온 기준을 사용하여 쿼리 다양성을 보장하며, 생성된 쿼리들 사이에서는 가장 정보 가치가 큰 후보를 선별하기 위해 불확실성 감소를 평가하는 불확실성 기반의 선택 메커니즘을 도입합니다. 검색 엔진을 통해 검색된 정보를 사용하여 증강된 입력을 기반으로 LLM의 응답 생성 시 모델의 불확실성을 줄이도록 설계되었습니다.
- ***Performance Highlights***: 의학 QA 벤치마크에서 SearchRAG는 기존의 RAG 방법들에 비해 평균적으로 응답 정확도를 12.61% 향상시켰습니다. 특히, LLaMA 8B 모델을 기준으로 MedMCQA에서 16.16%, MMLU_Med에서 13.59%, MedQA에서 8.09%의 절대적 정확도 향상을 기록했습니다. 이는 모델의 불확실성을 줄여 학습에 도움을 주는 검색 최적화 쿼리 생성과 고도로 맞춤화된 지식 필터링 과정에서 비롯된 것입니다.

### [Presumed Cultural Identity: How Names Shape LLM Responses](https://arxiv.org/abs/2502.11995)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.11995.png)

Vote: 8

Authors: Siddhesh Pawar, Arnav Arora, Lucie-Aimée Kaffee, Isabelle Augenstein

- ***What's New***: 이 논문은 대형 언어 모델(LLM; Large Language Models)이 이름을 통해 개인화를 수행할 때 발생하는 문화적 편견을 연구하는 최초의 작업 중 하나입니다. 저자들은 30개의 문화에서 900명의 이름을 이용하여 LLM이 이름을 통해 문화적 추정치를 가지는지를 분석합니다.
- ***Technical Details***: 연구진은 Facebook의 데이터셋에서 1위부터 30위의 가장 인기 있는 이름을 선택하고, CANDLE(Knowledge Graph)을 사용하여 문화적 상식 데이터를 수집했습니다. 이 데이터들은 음식, 의복, 전통 및 의식의 5가지 문화적 측면에서 분석되었습니다. 모델로는 Aya, DeepSeek, Llama, Mistral-Nemo, GPT-4o-mini를 이용해 각각의 이름이 포함된 프롬프트와 포함되지 않은 프롬프트로 나누어 반응의 문화적 편견을 측정했습니다.
- ***Performance Highlights***: 연구 결과, LLM 응답은 기본적으로 특정 문화에 편향되는 경향이 있으며, 이는 일본과 인도와 같은 동남아시아 문화에서 더욱 두드러졌습니다. 한국, 러시아 이름이 포함된 프롬프트의 경우 Llama 모델에서 특히 높은 문화적 추정치를 보였습니다. 반면 아일랜드, 브라질, 필리핀의 이름에서는 문화적 편견이 약하거나 무작위적 제안이 많았습니다.

### [Why Safeguarded Ships Run Aground? Aligned Large Language Models' Safety Mechanisms Tend to Be Anchored in The Template Region](https://arxiv.org/abs/2502.13946)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.13946.png)

Vote: 8

Authors: Jian Wang, Qingyu Yin, Wenjie Li, Chak Tou Leong

- ***What's New***: 이 연구는 대형 언어 모델(Large Language Models; LLMs)의 안전성 정렬(safety alignment)에 있어 '템플릿 고정 안전 정렬(Template-Anchored Safety Alignment; TASA)' 현상이 널리 퍼져있음을 확인하고, 이로 인해 발생하는 취약성을 조사하였습니다. 본 논문은 TASA가 어떻게 모델의 초기 행동을 안전하지 않게 만들 수 있는지에 대한 메커니즘을 분석하고, 이 문제를 완화하기 위한 초기 전략을 제안합니다.
- ***Technical Details***: 연구는 다양한 안전 정렬된 LLM들을 대상으로 TASA의 존재를 실험적으로 검증하고, 이러한 안전 메커니즘이 템플릿 영역에 과도하게 의존한다는 것을 밝혔다. 또한, 템플릿 영역에서 안전 메커니즘을 분리하게 되면, 잠재적으로 자일브레이크(jailbreak) 공격에 대한 취약성을 줄이는 데 유망한 것으로 나타났습니다.
- ***Performance Highlights***: 템플릿 영역에서 정보를 간섭(temppatching)하는 단순한 방법이 기존의 특정 자일브레이크 공격보다 효과적인 공격 성공률을 높였다는 점을 보였으며, 서로 다른 LLM 모델에서도 유사한 경향이 관찰되었습니다.

### [Thinking Preference Optimization](https://arxiv.org/abs/2502.13173)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.13173.png)

Vote: 8

Authors: Xiaotian Han, Jingfeng Yang, Vipin Chaudhary, Wang Yang, Hongye Jin

- ***What's New***: Thinking Preference Optimization (ThinkPO)는 새로운 장문의 연쇄추론(SFT) 데이터 없이 장문 연쇄추론(CoT) 성능을 개선하는 방법을 제안합니다. 이 방식은 짧은 CoT 응답을 거부된 답변으로, 긴 CoT 응답을 선택된 답변으로 사용하여 모델이 긴 응답을 선호하도록 직접적인 우선순위 최적화를 적용합니다.
- ***Technical Details***: ThinkPO는 짧은 CoT 응답을 거부된 사례로, 이미 존재하는 긴 CoT 응답을 선택된 사례로 사용하여 모델을 훈련시킵니다. 각 질문마다 거부된 짧은 응답과 선택된 긴 응답 쌍을 형성하고, Direct Preference Optimization을 통해 롱폼의 구조화된 추론 프로세스를 장려합니다. 대규모 학습 모델처럼 복잡한 알고리즘이 아닌, 손쉽게 얻을 수 있는 짧은 CoT 응답을 활용해 모델의 성능을 지속적으로 향상시킵니다.
- ***Performance Highlights***: ThinkPO는 SFT-ed 모델의 수학적 추론 정확도를 8.6% 증가시키고 출력 길이를 25.9% 증가시켰습니다. 특히, DeepSeek-R1-Distill-Qwen-7B의 MATH500 데이터셋에서 성능을 87.4%에서 91.2%로 끌어올렸습니다. 이 결과는 추가적인 고품질 데이터가 없이도 ThinkPO가 모델의 추론 능력을 상당히 향상시킬 수 있음을 보여줍니다.

### [AdaptiveStep: Automatically Dividing Reasoning Step through Model Confidence](https://arxiv.org/abs/2502.13943)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.13943.png)

Vote: 6

Authors: Zhaoling Chen, Yunhui Xia, Li Zhao, Yuliang Liu, Jiang Bian, Wei Shen, Chaofeng Qu, Zhouhan Lin, Zefan Cai, Chonghan Liu, Jason Klein Liu, Junjie Lu, Chuheng Zhang

- ***What's New***: AdaptiveStep는 모델의 자신감(Model Confidence)을 통해 추론 단계를 자동으로 나누는 방법을 제안합니다. 이는 사전 정의된 기호나 고정된 크기의 토큰을 사용하는 규칙 기반 방법의 한계를 극복하고, 모델의 각 단계에서 의사결정 정보의 경제성을 높입니다.
- ***Technical Details***: AdaptiveStep은 W-PRM(AdaptiveStep Process Reward Model)이라는 새로운 PRM을 훈련하여 사전에 나누어진 추론 단계별로 보상을 예측합니다. 모델은 토큰 샘플링으로 모델의 자신감을 측정하고, 기준 임계값을 통해 결정적인 분기점을 자동으로 식별합니다. 이를 통해 분할된 데이터로 PRM을 훈련하고, Token-level Value-guided Decoding(TVD)를 통해 더 나은 모델 응답을 얻을 수 있습니다.
- ***Performance Highlights***: 실험 결과, ASPRM은 GSM8k와 MATH500 데이터셋에서 TVD를 통해 각각 3.15%와 14.4%의 성능 향상을 보였으며, 기존의 오픈 소스 PRM 대비 70% 이하의 데이터 구축 비용을 보입니다. 코드 생성 과제에서도 기존의 ORM(Outcome Reward Model)보다 우수한 성능을 나타내며, TVD 평가에서는 Greedy Decoding 대비 6.54%와 3.70%의 성능 향상을 보였습니다.

### [MMTEB: Massive Multilingual Text Embedding Benchmark](https://arxiv.org/abs/2502.13595)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.13595.png)

Vote: 5

Authors: Tom Aarsen, Dominik Krzemiński, Malte Ostendorff, Maria Tikhonova, Marion Schaeffer, Björn Plüster, Manuel Faysse, Alessia Borghini, David Stap, Zheng Liu, Alena Fenogenova, Lester James Miranda, Martin Bernstorff, Loïc Magne, Vaibhav Adlakha, Wen-Ding Li, Marek Šuppa, John Yang, Shitao Xiao, Daniel Auras, Simon Clematide, Jan Kostkan, Xing Han Lù, Michael Günther, Hippolyte Gisserot-Boukhlef, Taemin Lee, Sara Hooker, Ruqiya Bin Safi, Henil Panchal, Andrianos Michail, Isabelle Mohr, Orion Weller, Márton Kardos, Guangyu Song, Aleksei Vatolin, Lasse Hansen, Gabriel Sequeira, Simone Tedeschi, Mengzhou Xia, Gayatri Krishnakumar, Niklas Muennighoff, Shreeya Dhakal, Dipam Vasani, Aleksandr Abramov, Kenneth Enevoldsen, Jordan Clive, Mathieu Ciancone, Artem Snegirev, Federico Cassano, Isaac Chung, Jonathan Rystrøm, Konrad Wojtasik, Roberta Rocca, Shawon Ashraf, Akash Kundu, Wissam Siblini, Nandan Thakur, Mohammed Hamdy, Rafał Poświata, Bhavish Pahwa, Chenghao Xiao, Anna Maksimova, Mariya Hendriksen, Crystina Zhang, Dawei Zhu, Pranjal Chitale, Howard Yen, Saba Sturua, Kranthi Kiran GV, Genta Indra Winata, Hongjin Su, Saiteja Utpala, Siva Reddy, Jan Philipp Harries, Ömer Çağatan, Jimmy Lin, Roman Solomatin, Akshita Sukhlecha, Silvan Wehrli, Manan Dey, Jay Gala, Weijia Shi, Diganta Misra, Nguyen Tai, Ashwin Mathur, Imene Kerboua

- ***What's New***: MMTEB는 대규모 멀티랭귀지 텍스트 임베딩(Multilingual Text Embedding) 벤치마크로, 250개 이상의 언어와 500개의 평가 작업을 포함합니다. 이는 언어 및 작업 다양성의 제약점을 해결하고 포괄적 평가를 제공하기 위한 것입니다.
- ***Technical Details***: MMTEB는 MTEB의 확장판으로, 500개의 평가 작업은 Code Retrieval, Long-Document Retrieval, Instruction Following 등 새로운 작업을 포함합니다. 데이터 유출 방지를 위해 각 작업은 고품질의 벤치마크가 포함되어 있으며, LLMs와 같은 대형 언어 모델을 평가합니다.
- ***Performance Highlights***: 상업적으로 이용 가능한 대형 언어 모델(LLMs)은 특정 언어에서 최고 성능을 보여주지만, 560M 파라미터를 가진 e5-large-instruct 모델이 다중언어에서 가장 강력한 퍼포먼스를 보입니다. 새로운 다운샘플링 방법과 하드 네거티브 샘플링 전략을 통해 계산 비용을 크게 줄일 수 있습니다. 예를 들어, 새로운 zero-shot English benchmark는 전체 문서의 2%만으로도 유사한 순위 순서를 유지합니다.

### [The Hidden Risks of Large Reasoning Models: A Safety Assessment of R1](https://arxiv.org/abs/2502.12659)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.12659.png)

Vote: 4

Authors: Xuandong Zhao, Dawn Song, Chengzhi Liu, Kaiwen Zhou, Shreedhar Jangam, Jayanth Srinivasa, Xin Eric Wang, Gaowen Liu

- ***What's New***: 이 논문은 대규모 추론 모델(Large Reasoning Models)의 안전성에 대한 포괄적인 평가를 제공하며, 특히 오픈 소스 모델인 DeepSeek-R1(R1)의 잠재적인 오용 가능성과 관련된 안전 문제에 초점을 맞춥니다. 이 연구는 R1 모델과 독점 모델인 o3-mini 간의 안전성 격차를 강조하며, R1 모델의 안전성 향상이 필요하다는 결론을 내립니다.
- ***Technical Details***: 연구에서는 다양한 안전 벤치마크와 역공격(adversarial attacks)을 통해 추론 모델의 안전성을 평가했습니다. 예를 들어, 잠금 해제(jailbreaking) 및 프롬프트 삽입(prompt injection)과 같은 공격에 대한 취약성을 분석했습니다. 또한, DeepSeek-R1 모델의 사고 프로세스가 최종 응답보다 더 큰 안전 우려를 야기할 수 있음을 발견했습니다.
- ***Performance Highlights***: 실험 결과, 오픈 소스 추론 모델은 독점 모델인 o3-mini에 비해 상당한 안전성 격차가 있으며, R1-70b와 같은 증류된 추론 모델은 원래의 안전 정렬된 베이스 모델보다 안전 성능이 저하되었습니다. 특히 R1 모델의 사고 과정에서 더 많은 안전 문제가 식별되었습니다.

### [REFIND: Retrieval-Augmented Factuality Hallucination Detection in Large Language Models](https://arxiv.org/abs/2502.13622)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.13622.png)

Vote: 3

Authors: DongGeon Lee, Hwanjo Yu

- ***What's New***: REFIND는 대형 언어 모델(LLM) 출력 내에서 허위 문장을 감지하기 위해 검색 문서를 직접 활용하는 새로운 프레임워크입니다. 이는 Context Sensitivity Ratio (CSR)라는 새로운 메트릭을 제안하여 검색된 증거에 대한 LLM 출력의 민감도를 정량화함으로써 효과적으로 환각을 감지할 수 있게 합니다.
- ***Technical Details***: REFIND는 질문과 관련된 문서를 검색해오는 리트리버(Retriever)와 얼어있는(frozen) 언어 모델을 통해 LLM 출력의 각 토큰에 대한 확률을 계산합니다. 그런 다음, CSR(Context Sensitivity Ratio)을 사용하여 각 토큰이 외부 정보에 얼마나 의존하는지를 판단합니다. CSR이 특정 임계값을 초과하면 허위로 분류합니다.
- ***Performance Highlights***: REFIND는 9개의 다양한 언어에서 기존 모델보다 뛰어난 성능을 보여주었으며, 특히 저자원 언어들에서도 안정적인 IoU 점수를 달성했습니다. 이는 외부 검색 정보를 통합하여 다양한 언어 환경에서 환각 감지의 신뢰성과 확장성을 입증했습니다.

### [From Tools to Teammates: Evaluating LLMs in Multi-Session Coding Interactions](https://arxiv.org/abs/2502.13791)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.13791.png)

Vote: 3

Authors: Alberto Testoni, Sandro Pezzelle, Jon Ander Campos, Marco Del Tredici, Mohammed Hamdy, Lucas Weber, Marzieh Fadaee, Nathanaël Carraz Rakotonirina

- ***What's New***: 이 논문은 MEMORYCODE라는 새로운 벤치마크를 소개합니다. 이 벤치마크는 다중 세션 코딩 상호작용 내에서 긴 대화 기록에서 간단한 코딩 명령을 추적하고 실행하는 LLMs의 능력을 평가하는 데 중점을 두고 있습니다. 이것은 현실적인 작업 환경을 시뮬레이션하면서 관련없는 정보 중에 간단한 코딩 명령을 다루도록 설계되었습니다.
- ***Technical Details***: MEMORYCODE 데이터셋은 멘토와 멘티 간의 대화로 이루어지며, 다양한 코딩 지침과 규칙이 전달됩니다. 대화 세션들은 지침이 업데이트될 수 있는 여러 세션으로 나뉘며, 관련 없는 정보가 많이 섞여 있어 모델이 이를 마치 실제 업무에서 코딩 명령을 따르는 인간 팀원처럼 행동하는지 평가합니다. LLMs는 여기서 추출한 지침을 실질적인 작업에 응용해야 합니다.
- ***Performance Highlights***: 다양한 최신 모델들이 MEMORYCODE에서 테스트되었으며, 개별 세션에서 단일 코딩 명령을 수행하는 데에는 상대적으로 좋은 성능을 보였으나, 긴 세션 수로 인해 관련 정보를 추출하고 업데이트된 정보를 조합하는 데에는 어려움을 나타냈습니다. 특히, GPT-4o는 단일 명령 수행에서의 정확도에 비해 100 세션에 가까워질 경우 정확도가 67% 정도 하락하는 문제를 보였습니다. 이는 현재 LLMs가 긴 세션 내에서 정보를 추출하고 추론하는 데 한계를 가지고 있음을 시사합니다.

### [Train Small, Infer Large: Memory-Efficient LoRA Training for Large Language Models](https://arxiv.org/abs/2502.13533)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.13533.png)

Vote: 3

Authors: Huan Li, Guiming Xie, Jun Zhang, Lidan Shou, Xuejian Gong, Ke Chen, Yang You, Jue Wang, Kunlong Zhou

- ***What's New***: LORAM은 대형 언어 모델(LLMs)의 메모리 효율적인 학습 방법으로, Low-Rank Adaption(LoRA)의 메모리 사용 문제를 해결하기 위해 제안되었습니다. 기존 모델을 축소한 상태에서 저차원 행렬을 얻어낸 후, 이를 원래의 큰 모델에 통합하여 추론하는 독특한 접근 방식을 취하고 있습니다.
- ***Technical Details***: LORAM은 과매개변수화된 LLM들에서 많은 신경들이 훈련 중 낮은 유용성을 가지지만, 추론에는 필수적이라는 직관에 기반하여 설계되었습니다. 훈련 과정에서는 잘린(작은) 모델에서 훈련을 진행하고, 원래(큰) 모델에 회복된 저차원 행렬을 이용하여 추론을 수행합니다. 이러한 회복 과정은 잘린 행렬을 원래 모델에 통합 가능하도록 재구성하여, 부풀리지 않은 가중치를 사용하는 동안 잘린 가중치를 이용하여 추론 성능을 향상시킵니다.
- ***Performance Highlights***: 70B 파라미터 모델에서 LORAM은 20G HBM GPU만으로도 훈련을 가능하게 하며, A100-80G GPU와 전체 미세 조정에 필요한 15 GPU를 대체합니다. QLORAM은 구조화된 가지치기와 4비트 양자화를 결합하여, LLaMA-3.1-70B 모델의 저차원 행렬 훈련 시 메모리 사용을 15.81배 또는 16.95배 절감하면서도 뛰어난 성능 향상을 얻습니다.

### [NExT-Mol: 3D Diffusion Meets 1D Language Modeling for 3D Molecule Generation](https://arxiv.org/abs/2502.12638)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.12638.png)

Vote: 3

Authors: Zhiyuan Liu, Xiang Wang, Sihang Li, Yanchen Luo, Han Huang, Junfeng Fang, Tat-Seng Chua, Kenji Kawaguchi, Enzhi Zhang, Yaorui Shi

- ***What's New***: NExT-Mol은 3D 분자 생성(3D Molecule Generation) 분야에서 3D 확산 모델(3D Diffusion Model)과 1D SELFIES 기반 언어 모델(1D SELFIES-based Language Models; LMs)의 장점을 결합하여 시뮬레이션을 개선하는 새로운 접근법입니다. 이 모델은 고유하게 사전 훈련된 SELFIES 기반의 1D 분자 생성 언어 모델을 활용하고 3D 확산 모델과의 1D에서 3D로의 전이 학습(1D to 3D Transfer Learning)을 통해 3D 분자 구조 예측의 정확성을 높였습니다.
- ***Technical Details***: NExT-Mol은 1.8억 SELFIES 시퀀스 데이터를 기반으로 Molecule Language Model을 사전 훈련한 후, 이 모델을 통해 3D 분자 생성 작업을 수행합니다. 3D Diffusion Model은 Relational Multi-Head Self-Attention와 Adaptive LayerNormalization을 사용하여 분자 내 원자와 페어의 특징을 학습하도록 설계되었습니다. 1D에서 3D 전이 학습은 MoLlama의 사전 훈련된 1D 표현을 3D 합성 예측에 활용하여 이루어집니다.
- ***Performance Highlights***: NExT-Mol은 GEOM-DRUGS 데이터셋의 de novo 3D 생성 Task에서 3D FCD 지표에 대해 26%의 상대적 성능 개선을 달성했습니다. 또한, QM9-2014 데이터셋에서 조건부 3D 생성 Task는 13%의 평균 상대적 이득을 보였습니다. 이러한 성능 향상은 1D LMs의 강력한 1D/2D 분자 패턴 학습과 3D conformer 예측의 결합력에 기반한 것입니다.

### [MVL-SIB: A Massively Multilingual Vision-Language Benchmark for Cross-Modal Topical Matching](https://arxiv.org/abs/2502.12852)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.12852.png)

Vote: 3

Authors: Chris Biemann, Florian Schneider, Goran Glavaš, Fabian David Schmidt

- ***What's New***: MVL-SIB는 대규모 멀티모달 비전-랭귀지(Vision-Language) 모델을 평가하기 위해 205개 언어로 구성된 대규모 멀티링구얼 벤치마크를 소개합니다. 이 벤치마크는 특히 저자원 언어(Low-resource Languages)에 대한 지원을 강화하여 기존보다 100개 이상의 언어를 추가적으로 포함하고 있습니다.
- ***Technical Details***: 멀티모달 및 텍스트 전용 주제 매칭을 테스트하기 위해 다양한 Open-weights LVLM(대규모 비전-랭귀지 모델) 및 GPT-4o와 함께 브렌치마크 테스트를 수행했습니다. 이 벤치마크는 SIB-200에서 다수의 토픽 레이블을 확장하였으며, 각 토픽은 10개 이상의 엄선된 이미지를 통해 매칭됩니다.
- ***Performance Highlights***: LVLM은 저자원 언어에서 특히 어려움을 겪었으며, 일부 언어에서는 성능이 거의 무작위에 가까웠습니다. 반면, 텍스트 전용 작업에서 이러한 모델은 상대적으로 더 나은 성능을 나타내며, 이미지를 통한 표현이 추가적인 이점을 제공하지 못했습니다. GPT-4o-mini는 많은 경우에서 가장 우수한 성능을 보였으나, 최저 자원 언어에서는 여전히 한계를 드러냈습니다.

### [AIDE: AI-Driven Exploration in the Space of Code](https://arxiv.org/abs/2502.13138)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.13138.png)

Vote: 2

Authors: Dixing Xu, Yuxiang Wu, Zhengyao Jiang, Dhruv Srikanth, Ian Kaplan, Deniss Jacenko, Dominik Schmidt

- ***What's New***: AIDE는 코드 공간에서의 최적화를 통해 머신러닝 엔지니어링을 자동화하는 AI 주도 탐색(AI-Driven Exploration) 시스템입니다. AIDE는 대규모 언어 모델(LLMs)을 활용하여 머신러닝 모델 개발의 시행착오 과정을 트리 검색(Tree Search) 문제로 재구성하여 작업을 자동화합니다.
- ***Technical Details***: AIDE는 기본 솔루션을 기반으로 새로운 코드를 제안하는 코딩 연산자와, 기록된 모든 과거 솔루션을 트리 구조로 정리하여 향상된 성능을 제공합니다. 이 시스템은 개선 제안을 위한 전략적인 트리 검색 알고리즘을 사용하며, 각 솔루션이 독립적인 평가함수를 통해 평가되고 비교됩니다.
- ***Performance Highlights***: AIDE는 Kaggle과 OpenAI의 MLE-Bench 등에서 최첨단 성과를 달성하며, 특히 GPT-4o 모델과 결합할 때 메달 획득율이 16.9%로 경쟁 에이전트보다 높은 성과를 기록했습니다. 여러 태스크에서 AIDE는 인간 전문가를 뛰어넘는 성능을 보였습니다.

### [Judging the Judges: A Collection of LLM-Generated Relevance Judgements](https://arxiv.org/abs/2502.13908)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.13908.png)

Vote: 2

Authors: Mohammad Aliannejadi, Nick Craswell, Guglielmo Faggioli, Paul Thomas, Bhaskar Mitra, Charles L. A. Clarke, Clemencia Siro, Hossein A. Rahmani, Emine Yilmaz

- ***What's New***: 이 논문은 대규모 언어 모델(Large Language Models; LLMs)을 활용해 정보 검색(Information Retrieval; IR)에서의 관련성 판단 문제를 자동화하려는 시도를 다루고 있으며, SIGIR 2024에서 LLMJudge 챌린지를 통해 이를 평가하였습니다. 이 연구는 새로운 주제로 학습되지 않은 최신 콘텐츠에 대해서도 효율적인 판단을 제공할 수 있으며, 적은 수의 자원을 요구하는 환경에서도 평가 시스템을 구축할 수 있는 가능성을 열어줍니다.
- ***Technical Details***: LLMJudge 챌린지는 8개의 국제 팀이 참여해 TREC 2023 딥러닝 트랙의 관련성 판단을 자동 생성한 42개의 레이블을 벤치마킹하였습니다. 이는 다양한 모델과 프롬프트의 영향을 탐색하고 평가합니다. 각 팀은 다양한 프롬프트 기법과 모델 적응을 활용했으며, 다단계 평가나 앙상블 모델의 유효성을 실험하였습니다.
- ***Performance Highlights***: 몇 가지 제출물에서 인상적인 성능을 보였는데, 예를 들어 h2oloo-fewself는 Krippendorff's Alpha에서 0.4958, 유사도의 Kendall's Tau에서 0.9085라는 높은 점수를 기록했습니다. 이와 달리 TREMA-nuggets와 TREMA-rubric0는 상대적으로 낮은 일치도를 보여 개선의 여지가 있음을 시사합니다.

### [TESS 2: A Large-Scale Generalist Diffusion Language Model](https://arxiv.org/abs/2502.13917)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.13917.png)

Vote: 2

Authors: Jaesung Tae, Sachin Kumar, Hamish Ivison, Arman Cohan

- ***What's New***: TESS 2는 기존의 텍스트 확산 모델과 비교하여 성능이 우수하며, 때때로 강력한 자동회귀(autoregressive; AR) 모델을 능가하는 범용 지시 따른 확산 언어 모델(diffusion language model)입니다. 이 모델은 기존 AR 모델을 기반으로 확산 손실로 교차 엔트로피를 사용하여 지속적인 사전 훈련을 수행한 후 추가적인 지시 조정을 통해 훈련되었습니다. 또한, 보상 안내(reward guidance)라는 새로운 추론 시 가이드 절차를 제안하여 기본 모델을 추가로 훈련하지 않고도 모델 출력을 정렬할 수 있습니다.
- ***Technical Details***: TESS 2는 TESS 및 SSD-LM 같은 모델 구조를 따라 확산 단계에서의 자기 조건부(self-conditioning)와 심플렉스 확산을 사용합니다. 모든 확산 단계에서 모델은 가상의 역방향 과정으로 예측된 보상(reward)의 그래디언트를 사용하여 모델 출력을 조정합니다. 또한, TESS 2는 UL2 마스킹을 통해 AR 모델을 적응하고 완전 양방향 주의(attention) 사용, 레이블 시프트와 같은 여러 구성 요소를 사용하여 기존 AR LM을 확산 모델로 변환하는 레시피를 제안합니다.
- ***Performance Highlights***: TESS 2는 AlpacaEval, SQuAD, TriviaQA와 같은 다양한 테스트에서 AR 모델과 유사하거나 더 나은 성능을 보입니다. 그러나 BBH 및 GSM8k와 같은 추론 중심의 작업에서는 상대적으로 부족한 성능을 보입니다. 다만, 더욱 많은 도메인 특화 데이터를 사용하면 TESS 2는 AR 모델을 능가하는 결과를 나타낼 수 있습니다. 예를 들어, GSM8k 상징 데이터셋 학습 후에는 TESS 2가 Mistral AR 모델보다 높은 성능을 보였습니다.

### [ActionPiece: Contextually Tokenizing Action Sequences for Generative Recommendation](https://arxiv.org/abs/2502.13581)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.13581.png)

Vote: 2

Authors: Jianmo Ni, Wang-Cheng Kang, Zhankui He, Noveen Sachdeva, Ed H. Chi, Derek Zhiyuan Cheng, Julian McAuley, Yupeng Hou

- ***What's New***: ActionPiece는 생성적 추천(Generative Recommendation; GR)에서 사용자 액션 시퀀스(Action Sequences)를 컨텍스트를 고려하여 토큰화하는 혁신적인 방법을 제안합니다. 기존 GR 모델이 각각의 액션을 독립적으로 토큰화 하는 것과 달리, ActionPiece는 액션 시퀀스 내의 컨텍스트를 명시적으로 포함하도록 설계되었습니다.
- ***Technical Details***: ActionPiece에서는 아이템의 특징(feature set)을 초기 토큰으로 사용하여 각 액션을 표현합니다. 그런 다음, 액션 시퀀스 데이터셋을 바탕으로 공출현 빈도를 기반으로 특징 패턴을 합쳐 새로운 토큰을 생성하여 어휘를 구성합니다. 이 과정에서 특징 세트의 비정렬성을 고려하여 '세트 순열 정규화(set permutation regularization)'를 도입하며, 동일한 의미를 보존하면서 다양한 분할을 생성하여 모델 학습을 이롭게 합니다.
- ***Performance Highlights***: ActionPiece는 공개된 데이터셋 실험에서 기존의 액션 토큰화 방법들을 꾸준히 능가하며 NDCG@10에서 6.00%에서 12.82%까지 향상시켰습니다. 이는 추천 성능을 개선하는데 있어 컨텍스트 인지 액션 시퀀스 토큰화의 효과를 입증합니다.

### [REALTALK: A 21-Day Real-World Dataset for Long-Term Conversation](https://arxiv.org/abs/2502.13270)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.13270.png)

Vote: 2

Authors: Dong-Ho Lee, Francesco Barbieri, Xiang Ren, Jay Pujara, Adyasha Maharana

- ***What's New***: REALTALK는 21일간의 실세계 메신저 대화 데이터셋으로, 장기적인 대화를 평가하기 위한 최초의 데이터셋입니다. 이는 인간의 실제 상호작용과의 직접적인 비교를 가능하게 하여, LLM 생성 대화와의 차이점을 조명합니다.
- ***Technical Details***: REALTALK 데이터셋은 10명의 참가자가 21일 동안 두 명씩 짝을 이루어 서로 다른 파트너와 두 번의 대화를 나눈 기록으로 구성되어 있으며, 각각 약 21세션으로 구성됩니다. 또한, 참가자 외 별도의 주석자가 표시된 각 대화에 대하여 메모리 탐색 질문과 주요 이벤트를 주석하였습니다.
- ***Performance Highlights***: 실험 결과, 모델들이 대화사를 기록하여 사용자 스타일을 시뮬레이션하는 데 어려움을 겪고 있으며, 특정 사용자의 대화 내용을 미세 조정함으로써 퍼포먼스가 개선되었습니다. 하지만 장기적인 컨텍스트를 활용하여 효과적으로 기억을 호출하는 데 여전히 큰 도전을 받고 있습니다.

### [InfiR : Crafting Effective Small Language Models and Multimodal Small Language Models in Reasoning](https://arxiv.org/abs/2502.11573)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.11573.png)

Vote: 2

Authors: Zhen Li, Congkai Xie, Xiaotian Han, Pengxiang Li, Yang Yu, Shuo Cai, Su Lu, Shengyu Zhang, Baoyi He, Fei Wu, Hongxia Yang, Qi Zhou, Kejing Yang, Zeyu Liu, Jianbo Yuan, Yuhang Liu, Guanghao Zhu, Yiming Zhang, Wenjun Wang, Zhijie Sang

- ***What's New***: InfiR는 효율적인 작고 다중모달 언어 모델(Small Multimodal Language Models; MSLMs)을 개발하여 추론 능력을 유지하는 것을 목표로 하는 혁신적인 훈련 파이프라인을 소개합니다. 이는 특히 엣지 디바이스에서의 배치를 용이하게 하여 개발 비용을 최소화하고 데이터 프라이버시 문제를 해결합니다.
- ***Technical Details***: 이 연구에서는 작고 강력한 언어 모델을 개발하기 위해 새로운 사전 및 후훈련 파이프라인을 제안합니다. 이 파이프라인은 약 5760 GPU 시간 내에 학습을 완료할 수 있으며, 이는 평균적으로 동일한 크기의 기존 모델에 비해 2.26배의 향상된 추론 관련 성능을 제공합니다. 데이터 수집은 주로 고품질의 수학 및 소스 코드 데이터를 포함하여 논리적 추론을 강조하는 텍스트를 사용하며, 고도로 정제된 전처리 과정을 통해 중복 제거 및 품질 평가를 수행합니다.
- ***Performance Highlights***: InfiR-1B-Base와 InfiR-1B-Instruct 모델은 각각 Llama-3.2-1B와 유사하고, Qwen2.5-1.5B 모델에 근접한 성능을 나타냅니다. InfiR-VL-1.6B는 '안드로이드 월드' 시나리오에서 기존의 소형 모델 중 최고 SOTA 대비 정확도가 28% 증가한 성과를 보였습니다. 이는 컴퓨팅 자원을 줄이면서도 실질적인 AI 시스템을 위한 추론 과제에서 효과적인 성능을 입증합니다.

### [GIMMICK -- Globally Inclusive Multimodal Multitask Cultural Knowledge Benchmarking](https://arxiv.org/abs/2502.13766)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.13766.png)

Vote: 2

Authors: Chris Biemann, Carolin Holtermann, Anne Lauscher, Florian Schneider

- ***What's New***: GIMMICK는 전 세계 144개국과 여섯 개의 글로벌 매크로 지역을 대표하여 728개의 고유한 문화 이벤트 또는 면(CEFs)을 대상으로 새로운 데이터셋을 포함한 6개의 과제를 통해 주요 이미지-언어 모델(LVLMs)과 대형 언어 모델(LLMs)의 문화적 지식을 평가하기 위한 다양한 멀티모달 벤치마크입니다.
- ***Technical Details***: GIMMICK 벤치마크는 고유한 데이터셋 위에서 구축된 6개의 과제를 포함합니다. 이러한 과제는 문화적 지식의 고급 수준과 미세 조정을 목표로 하는 멀티모달 및 유니모달 작업을 포함합니다. 모든 과제는 UNESCO 비물질 문화유산(ICH)의 고품질 개방형 데이터세트에 기반하고 있으며, 영상과 텍스트, 영상 두 가지 입력 모드를 모두 지원합니다.
- ***Performance Highlights***: 다양한 모델 크기가 성능에 미치는 영향을 분석한 결과, 모델 크기가 복잡한 과제에서 성능을 크게 향상시켰으며, 지역적 편향은 여전히 존재하지만 상위 모델에서는 줄어들었습니다. 주어진 외부 문화적 힌트나 멀티모달 입력이 주어지면 대부분의 모델이 성능 향상이 있었으며, 특히 문화적 근원이 요구되는 경우 유리한 결과를 보였습니다. 그러나 여전히 세밀한 문화적 이해에서는 기존 모델들이 어려움을 겪고 있다는 점이 드러났습니다.

### [Reducing Hallucinations in Language Model-based SPARQL Query Generation Using Post-Generation Memory Retrieval](https://arxiv.org/abs/2502.13369)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.13369.png)

Vote: 1

Authors: Christopher J. Pal, Amal Zouaq, Aditya Sharma, Luis Lara

- ***What's New***: PGMR(Post-Generation Memory Retrieval)는 LLMs가 생성하는 SPARQL 쿼리의 환각(Hallucination) 문제를 해결하기 위한 새로운 모듈형 아키텍처입니다. 이 프레임워크는 LLM을 사용하여 중간 쿼리를 생성한 뒤, 비파라메트릭 메모리 모듈을 통해 정확한 KG 요소를 검색하여 최종 SPARQL 쿼리를 구성합니다.
- ***Technical Details***: PGMR는 LLM이 자연어 엔티티와 관계가 특수 토큰(starturi, enduri)으로 둘러싸인 중간 SPARQL 쿼리를 생성하도록 변환합니다. 생성된 중간 쿼리는 메모리 검색을 통해 URI와 매칭되어 최종 SPARQL 쿼리가 형성됩니다. 이를 통해 환각 문제를 억제하고 LLM의 SPARQL 쿼리 생성 정확성을 높입니다.
- ***Performance Highlights***: 기존의 SPARQL 쿼리 생성 접근법에 비해 PGMR는 URI 환각을 거의 완전히 제거하며, 모든 실험에서 강력한 성능을 보였습니다. 이러한 성과는 다양한 데이터 집합, 데이터 분포 및 LLMs에서 일관되게 나타났습니다.

### [High-Fidelity Novel View Synthesis via Splatting-Guided Diffusion](https://arxiv.org/abs/2502.12752)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.12752.png)

Vote: 1

Authors: Xiang Zhang, Christopher Schroers, Markus Gross, Yang Zhang, Lukas Mehl

- ***What's New***: 이 논문에서는 새로운 관점 생성(Novel View Synthesis; NVS)을 위한 SplatDiff라는 픽셀 스플래팅 기반 비디오 확산 모델을 소개합니다. SplatDiff는 픽셀 스플래팅과 확산 모델의 강점을 결합하여 일관된 기하학과 높은 충실도의 텍스처를 갖춘 새로운 장면을 단일 이미지로부터 생성합니다.
- ***Technical Details***: SplatDiff는 픽셀 스플래팅(Pixel Splatting)을 통해 입력 이미지의 깊이 정보를 추정하고, 카메라 포즈에 따라 스플래팅된 뷰를 생성하여 확산 조건으로 사용합니다. 확산 모델은 비디오 데이터셋에서 학습된 시각 요소의 깊이 있는 이해를 활용하여 변환 지도의 부정확성으로 발생하는 스플래팅 오류를 수정하고 일관된 기하학적 콘텐츠와 충실도 높은 세부사항을 생성합니다. 핵심 구성 요소에는 정렬된 합성을 위한 트레이닝 페어 정렬(Training Pair Alignment; TPA)과 텍스처 브리지(Texture Bridge) 모듈이 포함되며, TPA는 생성된 뷰와 스플래팅된 뷰 간의 기하학 및 밝기 일관성을 보장합니다.
- ***Performance Highlights***: SplatDiff는 기존의 확산 기반 및 스플래팅 기반 방법에 비해 뛰어난 성능을 발휘하며, 단일 시나리오 학습만으로 다양한 과제에서 우수한 제로샷 성능을 보여줍니다. 특히 단일 뷰 NVS, 희소 뷰 NVS 및 스테레오 비디오 변환에서 높은 수준의 세부 정보와 일관된 기하학을 유지하며 최첨단 성능을 입증하였습니다.

### [Scaling Autonomous Agents via Automatic Reward Modeling And Planning](https://arxiv.org/abs/2502.12130)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.12130.png)

Vote: 1

Authors: Zhenfang Chen, Rui Sun, Wenjun Liu, Delin Chen, Chuang Gan

- ***What's New***: ARMAP 프레임워크는 인간의 주석 없이 환경에서 보상 모델(Reward Model)을 자동으로 학습하여 LLM 기반 에이전트의 작업 계획 성능을 향상시키는 혁신적인 접근 방식입니다. 이 프레임워크는 다양한 에이전트 벤치마크를 통해 LLM 에이전트의 의사결정 능력을 크게 향상시킵니다.
- ***Technical Details***: LLM 기반 에이전트가 환경을 무작위로 탐색하며 다양한 행동 궤적을 생성하는 데 활용됩니다. 그 후 별도의 LLM이 각 궤적에 대해 태스크 의도를 정하고 긍정 및 부정 응답을 생성합니다. 이 트리플렛 데이터로 보상 모델을 최적화하여 맡은 의도를 달성했는지를 평가할 수 있습니다. 보상 모델은 LLM 기반 에이전트와 몬테카를로 트리 탐색(Monte Carlo Tree Search) 알고리즘과 같이 통합되어 작업 해결 성능을 높입니다.
- ***Performance Highlights***: 과학World, 웹상점(Webshop) 및 수학게임(Game of 24) 등의 다양한 에이전트 벤치마크에서 ARMAP 프레임워크는 기존 샘플링 및 그리디 방법에 비해 일관되게 높은 성능을 보였으며, 특히 약한 모델에서 더 큰 성능 향상을 제공했습니다. MCTS 알고리즘이 평균적으로 가장 우수한 성능을 보였으며 보상 모델은 더 나은 궤적을 찾는 데 결정적인 역할을 합니다.

### [Noise May Contain Transferable Knowledge: Understanding Semi-supervised Heterogeneous Domain Adaptation from an Empirical Perspective](https://arxiv.org/abs/2502.13573)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.13573.png)

Vote: 0

Authors: Jian Jin, Yuan Yao, Yu Zhang, Xiaopu Zhang, Qiang Yang

- ***What's New***: 이 논문은 반감독 이질 도메인 적응(Semi-supervised Heterogeneous Domain Adaptation; SHDA)의 전이에 대해 경험적 관점에서 깊이 탐구했습니다. 기존 SHDA 방법들이 출처와 대상 간 전이되는 지식의 본질을 명확히 설명하지 못한 가운데, 저자들은 약 330개의 SHDA 과제를 통해 여러 실험을 수행하고, 놀랍게도 출처 샘플의 카테고리나 특징 정보가 대상 도메인의 성능에 큰 영향을 미치지 않는다는 결과를 발견했습니다. 이러한 통찰을 바탕으로 단순 분포에서 추출한 노이즈가 전이 가능한 지식을 포함할 수 있다고 제안합니다.
- ***Technical Details***: 저자들은 SHDA의 전이 가능한 지식의 본질을 더 잘 이해하기 위해 통합된 지식 전이 프레임워크(Knowledge Transfer Framework; KTF)를 설계했습니다. 이 KTF는 출처 도메인의 전달력과 변별성을 고려하여 연구하여 SHDA 작업에서 출처 샘플의 기원이 이미지든, 텍스트든, 노이즈든 간에 상관없이 이 속성을 보장하는 것이 중요하다고 결론지었습니다.
- ***Performance Highlights***: 저자들은 약 330개의 SHDA 과제를 통해 실험을 수행했으며, 단순 분포에서 발생한 노이즈를 출처 샘플로 사용했을 때도 대상 도메인의 성능이 유지됨을 발견했습니다. 이는 노이즈가 전이 가능한 지식을 포함할 수 있음을 암시하며, 기존 SHDA 방법에 비해 노이즈 기반 접근법이 비슷한 성능을 달성할 수 있음을 보여줍니다. 이러한 결과는 SHDA 연구에 있어 새로운 가능성을 제시합니다.

