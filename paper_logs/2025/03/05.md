## Daily Papers (2025-03-05)

### [MPO: Boosting LLM Agents with Meta Plan Optimization](https://arxiv.org/abs/2503.02682)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.02682.png)

Vote: 15

Authors: Qingxiu Dong, Yifan Song, Weimin Xiong, Xun Wang, Sujian Li, Feifan Song, Bingchan Zhao

- ***What's New***: Meta Plan Optimization(MPO) 프레임워크는 명시적인 지침을 직접적으로 에이전트 계획에 포함하여 대형 언어 모델(LLM) 기반 에이전트의 성능을 향상시킵니다. 메타 플랜(meta plans)을 통한 높은 수준의 일반적인 지침을 활용하여 에이전트 계획을 돕고, 에이전트의 작업 실행 피드백을 바탕으로 메타 플랜을 지속적으로 최적화합니다.
- ***Technical Details***: MPO의 메타 플래너(meta planner)는 전문가 경로에서 메타 플랜을 수집하여 감독된 미세 조정을 통해 초기화됩니다. 그 후, 몬테카를로(Monte Carlo; MC) 샘플링을 사용하여 메타 플랜 품질을 평가하고, 대비적 메타 플랜 쌍을 식별하여 DPO(Direct Preference Optimization)로 메타 플래너를 최적화합니다. 최종적으로, MPO 프레임워크에서 분리된 메타 플래너는 새로운 에이전트에 대한 고품질 메타 플랜을 생성할 수 있는 플러그 앤 플레이(plug-and-play) 구성 요소로 기능할 수 있습니다.
- ***Performance Highlights***: MPO는 ALFWorld와 ScienceWorld 두 벤치마크에서 에이전트의 성능을 크게 개선하였으며, 평균적으로 최대 100%의 성능 향상을 이루었습니다. 또한, MPO는 다양한 기존 에이전트 프레임워크와 호환되어 더 큰 성능 향상을 누적적으로 제공합니다. 특히, MPO는 에이전트의 평균 동작 보상을 크게 증가시켜 작업 완료 효율성을 향상시킵니다.

### [Mask-DPO: Generalizable Fine-grained Factuality Alignment of LLMs](https://arxiv.org/abs/2503.02846)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.02846.png)

Vote: 14

Authors: Kai Chen, Chengqi Lyu, Yuzhe Gu, Dahua Lin, Wenwei Zhang

- ***What's New***: Mask-DPO는 대형 언어 모델(Large Language Models; LLMs)의 세밀한 사실성 정렬 방법을 제시한 새로운 접근법입니다. 문장 수준의 사실 정보를 신호(mask signals)로 사용하여 선호 샘플에서는 사실적으로 올바른 문장만 학습하고, 비선호 샘플에서는 사실적인 콘텐츠에 대한 페널티를 방지하여 학습의 모호함을 해결합니다.
- ***Technical Details***: Mask-DPO는 Direct Preference Optimization(DPO) 기반의 정렬 프레임워크를 사용합니다. 세밀한 환상(hallucination) 주석기를 이용해 각 문장의 사실성을 평가하고, 이를 통해 선호 샘플과 비선호 샘플을 선택하여 학습합니다. 최적화 과정에서는 올바르지 않은 문장은 무시하고, 올바른 문장은 강화하여 모델의 사실성 정렬 효과를 극대화합니다.
- ***Performance Highlights***: Mask-DPO는 ANAH 테스트 세트에서 77.53%의 향상된 성과를 보여 Llama3.1-70B-Instruct의 53.44%를 능가합니다. 또한, Biography 데이터셋에서도 FactScore가 30.29%에서 39.39%로 증가하여, 다양한 도메인에 걸친 사실성 정렬에 대한 높은 일반화를 입증합니다.

### [Wikipedia in the Era of LLMs: Evolution and Risks](https://arxiv.org/abs/2503.02879)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.02879.png)

Vote: 13

Authors: Yuliang Xu, Siming Huang, Dongping Chen, Mingmeng Geng, Yao Wan

- ***What's New***: 이 논문에서는 대형 언어 모델(LLM)이 Wikipedia에 미치는 영향을 분석하고 Wikipedia의 진화와 잠재적 위험을 모의 실험을 통해 탐구하고 있습니다. 연구에 따르면 Wikipedia의 특정 범주에 LLM의 영향이 약 1%에서 2%에 이를 수 있으며, LLM이 생성한 콘텐츠로 지식 기반이 '오염'될 경우 검색보강생성(RAG)의 효과가 감소할 수 있습니다.
- ***Technical Details***: 연구의 처음 목표는 LLM이 Wikipedia에 미친 직접적인 영향을 평가하는 것이며, 페이지 조회수, 단어 사용 빈도, 언어 스타일 변화에 중점을 둡니다. 그 후, Wikipedia 콘텐츠가 포함된 기계 번역 벤치마크와 RAG에 대한 간접적인 영향을 평가합니다. LLM에 의해 번역된 문장은 번역 평가 결과에 큰 영향을 미칠 수 있으며, LLM이 수정한 위키피디아 페이지는 RAG 작업에서 성능 저하를 일으킬 수 있습니다.
- ***Performance Highlights***: RAG 실험에서는 외부 지식이 주어졌을 때 LLM의 정답률이 80% 이상으로 높아지는 것으로 나타났습니다. 그러나 LLM이 수정된 페이지를 사용할 경우 그 정확도가 하락하는 경향을 보이며, 특히 Gemini 모델로 수정된 경우가 그러했습니다. 이는 LLM으로 생성된 콘텐츠가 사람의 콘텐츠보다 RAG 시스템에서 덜 효과적일 수 있음을 시사합니다.

### [MultiAgentBench: Evaluating the Collaboration and Competition of LLM agents](https://arxiv.org/abs/2503.01935)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.01935.png)

Vote: 11

Authors: Shuyi Guo, Xiaocheng Yang, Zhenhailong Wang, Heng Ji, Zhaochen Hong, Xiangru Tang, Zhe Wang, Hongyi Du, Cheng Qian, Jiaxuan You, Kunlun Zhu

- ***What's New***: MultiAgentBench는 다양한 상호작용 시나리오에서 대형 언어 모델(LLM) 기반 멀티 에이전트 시스템을 평가하기 위해 설계된 포괄적인 벤치마크입니다. 이 새로운 벤치마크는 협력과 경쟁의 질을 평가할 수 있는 혁신적인 마일스톤 기반 성능 지표를 포함하고 있어, 멀티 에이전트 환경의 독특한 도전과제를 잘 나타냅니다.
- ***Technical Details***: MultiAgentBench는 LLM 기반 멀티 에이전트 시스템의 효율성을 극대화하기 위해 MARBLE(Multi-agent cooRdination Backbone with LLM Engine) 프레임워크를 사용합니다. 이 프레임워크는 스타, 체인, 트리, 그래프와 같은 다양한 커뮤니케이션 토폴로지를 지원하며, 그룹 토론 및 인지 계획과 같은 혁신적인 전략을 실험합니다. 각 에이전트는 독립적이고 협력적인 작업을 위한 다양한 도구 모음을 사용하여 환경과 상호작용합니다.
- ***Performance Highlights***: 실험 결과, gpt-4o-mini는 가장 높은 평균 작업 점수를 기록하였으며, 연구 시나리오에서 그래프 구조를 사용한 경우가 가장 좋은 성과를 보였습니다. 인지 계획은 마일스톤 달성률을 3% 향상시키는 것으로 나타났습니다. 이 결과는 멀티 에이전트 시스템이 더 복잡한 환경에서 협력과 경쟁을 더 효과적으로 수행할 가능성을 시사합니다.

### [LADDER: Self-Improving LLMs Through Recursive Problem Decomposition](https://arxiv.org/abs/2503.00735)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.00735.png)

Vote: 10

Authors: Akira Yoshiyama, Toby Simonds

- ***What's New***: LADDER는 대형 언어 모델(LLMs)이 문제를 더 단순하게 변형하여 스스로 어려운 문제를 해결할 수 있도록 하며, 인간의 피드백 없이 모델이 자체 성능을 개선할 수 있는 프레임워크를 제안합니다. 이 프레임워크는 Qwen2.5 7B 모델이 MIT Integration Bee 시험에서 73%의 정확도를 달성하도록 도왔으며, 이는 기존의 대형 모델들을 능가하는 성과입니다.
- ***Technical Details***: LADDER는 문제를 재귀적으로 더 간단한 변형으로 분해하여 자연스러운 난이도 기울기를 생성하는 방식으로 설계되었습니다. 또한 TTRL(Test-Time Reinforcement Learning)을 도입하여 모델이 시험 순간에 문제 변형을 생성하고 이를 기반으로 강화를 통해 성능을 개선합니다. 이러한 모든 과정은 숫자 통합을 통해 해결의 검증을 수행하는 메커니즘에 의해 지원됩니다.
- ***Performance Highlights***: LADDER를 통해 Llama 3.2 3B 모델은 대학 수준의 수학적 통합 문제에서 1%에서 82%로 크게 성능이 향상되었습니다. MIT Integration Bee 시험에서 Qwen2.5 7B Deepseek-R1 Distilled 모델은 73%의 정확도를 기록하며, TTRL을 사용하면 90%까지 도달할 수 있었습니다. 이는 기존의 OpenAI의 o1 모델을 능가하는 성과입니다.

### [PipeOffload: Improving Scalability of Pipeline Parallelism with Memory Optimization](https://arxiv.org/abs/2503.01328)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.01328.png)

Vote: 10

Authors: Xinyi Wan, Min Lin, Penghui Qi, Jialin Li, Guangxing Huang

- ***What's New***: 이 논문은 대형 언어 모델(Large Language Models; LLMs)의 훈련에서 파이프라인 병렬성(Pipeline Parallelism; PP)의 확장성을 높이기 위한 새로운 메모리 최적화 전략을 제시합니다. 특히, 메모리 오프로드(memory offload) 전략을 활용하여 활성화 메모리의 소비를 줄이려는 시도를 강조합니다. 이로써 하드웨어 제약에도 불구하고 더 큰 모델을 효과적으로 훈련할 수 있게 됩니다.
- ***Technical Details***: PipeOffload는 메모리 오프로드 전략을 통해 PP에서 활성화 메모리 소비를 줄입니다. 실험을 통해, 대부분의 표준 설정에서 최소 절반 이상의 활성화 메모리를 오프로드할 수 있으며, 전혀 오버헤드가 거의 없음을 발견했습니다. 오프로드가 불가능한 경우, 선택적 오프로드 전략을 도입하여 피크 활성화 메모리를 더 효과적으로 줄이는 방식을 사용했습니다. 이는 PCI-E 대역폭과 GPU 계산 대역폭의 조합을 이용해 오프로드 비용을 극소화하는 방식입니다.
- ***Performance Highlights***: PipeOffload를 통해 각 장치의 활성화 메모리는 PP의 총 단계 수 증가에 따라 효과적으로 감소하며, 공연량 및 메모리 제약을 포함한 여러 요인을 고려합니다. 이 방법은 일반적인 1F1B 스케줄보다 메모리 사용량을 최대 75%까지 감소시키며, 직선보다 더 나은 메모리 절약 효율성을 가집니다. 이로 인해 Tensor Parallelism(TP)보다 PP가 더 나은 대안으로 작용할 수 있으며, 최대 19%의 가속화를 제공합니다.

### [Iterative Value Function Optimization for Guided Decoding](https://arxiv.org/abs/2503.02368)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.02368.png)

Vote: 10

Authors: Ruizhe Chen, Tong Zhu, Yuxian Jiang, Wenliang Chen, Lijun Li, Zhenhua Liu, Jing Shao

- ***What's New***: 기존의 RLHF(Reinforcement Learning from Human Feedback) 접근 방식이 높은 계산 비용과 훈련 불안정성을 겪는 반면, 새로운 Iterative Value Function Optimization(IVO) 프레임워크는 두 가지 주요 구성 요소를 통해 이러한 문제를 해결하여 모델 재훈련 없이도 효율적이고 효과적인 제어를 제공합니다. Monte Carlo Value Estimation은 다양한 경로를 탐색하여 추정 오차를 줄이며, Iterative On-Policy Optimization은 가치 추정의 정확성을 점진적으로 개선합니다.
- ***Technical Details***: IVO는 Monte Carlo Value Estimation과 Iterative On-Policy Optimization을 결합하여 높은 보상 경로 탐색을 개선하고, 가치 함수를 최적화하는 방식으로 작동합니다. 이 접근 방식은 KL-정규화 강화 학습의 이론적 최대 보상을 추구하는 정책을 유도하며, 계산 효율성을 유지하면서도 점진적 정책 향상을 통해 베이스 정책과 최적 정책 간의 격차를 줄입니다.
- ***Performance Highlights***: IVO는 다중 턴 대화(multi-turn dialogue)에서 기존 기법을 능가하며, 300개의 예제에서 기존의 메서드들과 비교하여 GPT-4 기준 77.52%의 승률을 기록했습니다. 이것은 다양한 광범위한 과제들, 특히 텍스트 요약 및 명령 수행에서 일관된 성능 향상을 보여주며, 새로운 가치 함수 최적화를 활용한 혁신적인 접근법의 효율성을 입증합니다.

### [SemViQA: A Semantic Question Answering System for Vietnamese Information Fact-Checking](https://arxiv.org/abs/2503.00955)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.00955.png)

Vote: 7

Authors: Tai V. Duong, Phuc-Lu Le, Thanh T. Tran, Di T. Le, Dien X. Tran, Anh T. Hoang, Nam V. Nguyen

- ***What's New***: SemViQA는 베트남어 정보 검증을 위한 혁신적인 질문 응답 시스템으로, 최근의 정보 왜곡 문제를 해결하기 위한 방법으로 소개되었습니다. 이 시스템은 Semantic-based Evidence Retrieval(SER)과 Two-step Verdict Classification(TVC)을 통합하여 정보 검증의 정확성과 효율성을 크게 향상시켰습니다.
- ***Technical Details***: SemViQA 시스템은 데이터 처리, 의미 기반 증거 검색(SER), 그리고 두 단계의 판정 분류(TVC)로 구성됩니다. 데이터 처리 단계에서는 Transformer 모델의 토큰 한계 문제를 효율적으로 처리합니다. SER은 TF-IDF와 Question Answering Token Classifier(QATC)를 함께 사용하여 키워드 매칭과 의미 기반 증거 선택을 최적화합니다. 마지막으로, TVC는 Focal Loss와 Cross-Entropy Loss를 활용한 계층적 분류 전략을 사용하여 협력, 반박, 정보 부족을 판별합니다.
- ***Performance Highlights***: SemViQA는 ISE-DSC01 데이터셋에서 78.97% 엄격 정확도를, ViWikiFC에서는 80.82%를 기록했습니다. 이는 기존의 베스트 방법들에 비해 월등한 성능으로, 특히 긴 토큰 시퀀스를 처리하는 데 있어서도 뛰어난 효율성을 보여줍니다. 고속 버전인 SemViQA Faster는 정확성을 유지하면서 추론 속도를 7배 개선했습니다.

### [FR-Spec: Accelerating Large-Vocabulary Language Models via Frequency-Ranked Speculative Sampling](https://arxiv.org/abs/2502.14856)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.14856.png)

Vote: 6

Authors: Xu Han, Yuxuan Li, Jianyong Wang, Yuxiang Huang, Weilin Zhao, Maosong Sun, Kaihuo Zhang, Zhiyuan Liu, Ao Sun, Weilun Zhao, Yudi Zhang, Tengyu Pan

- **What's New**: FR-Spec는 큰 어휘집합을 가진 대형 언어 모델(LLM)에서 빈도 기반의 추측적 샘플링(Frequency-Ranked Speculative Sampling)을 통해 초안을 최적화하여, 출력 분포의 등가성을 유지하면서도 LM Head 계산 오버헤드를 대폭 감소시킵니다.
- **Technical Details**: FR-Spec는 자주 사용되는 토큰들이 우선적으로 선택되는 서브셋을 활용하여 초안 검색을 진행함으로써, Llama-3-8B와 같은 대형 어휘집합을 가진 LLM에서 LM Head 연산 부담을 75% 감소시킵니다. 이를 통해 최종 출력 분포의 등가성을 보장하면서도 전체 생성 속도를 증가시킵니다.
- **Performance Highlights**: FR-Spec은 EAGLE-2 대비 평균 1.12배의 속도 향상을 여러 데이터셋에 걸쳐 시연하며, 특히 어휘집합이 클수록 이점이 두드러졌습니다. 추가적으로, 하드웨어와 Model 크기에 상관 없이 LLM의 다른 추측적 샘플링 방법에 편리하게 통합될 수 있습니다.

### [RectifiedHR: Enable Efficient High-Resolution Image Generation via Energy Rectification](https://arxiv.org/abs/2503.02537)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.02537.png)

Vote: 5

Authors: Zhen Yang, Pengfei Wan, Liang Hou, Mushui Liu, Luozhou Wang, Ying-Cong Chen, Guibao Shen, Di Zhang, Xin Tao

- ***What's New***: 이 논문에서는 RectifiedHR이라는 고해상도 이미지 생성의 새롭고 효율적인 방법을 제안합니다. 이 방법은 트레이닝 없이 고해상도 이미지를 생성할 수 있으며, Noise Refresh와 Energy Rectification 전략을 통해 고해상도 이미지 생성의 효율성을 대폭 개선합니다.
- ***Technical Details***: RectifiedHR 방법은 Noise Refresh와 Energy Rectification 두 가지 모듈로 구성됩니다. Noise Refresh는 디퓨전 모델의 예측 x0의 해상도를 특정 샘플링 단계에서 향상시키며, Energy Rectification은 분석하여 이미지가 흐려지는 에너지 감소 현상을 완화하기 위해 Classifier-Free Guidance(CFG) 하이퍼파라미터를 조절하는 전략을 사용합니다. 이 방법은 코드 몇 줄만으로 구현이 가능하며 트레이닝이 필요 없습니다.
- ***Performance Highlights***: RectifiedHR은 다른 최첨단 방법들과의 비교 실험에서 효율성과 효과성 면에서 우수한 성과를 보였습니다. 특히 2048x2048 및 4096x4096 해상도 이미지 생성에서 뛰어난 효율성을 입증하였으며, FID, KID, IS 등의 지표에서 최상의 성능을 보이며, 시간 효율성에서도 전통적인 방법보다 뛰어난 결과를 보였습니다.

### [UFO: A Unified Approach to Fine-grained Visual Perception via Open-ended Language Interface](https://arxiv.org/abs/2503.01342)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.01342.png)

Vote: 5

Authors: Tingyu Weng, Yun Zheng, Pandeng Li, Liwei Wang, Haiyang Wang, Hao Tang, Xiaoyi Bao, Chenwei Xie

- ***What's New***: UFO는 통합된 언어 인터페이스(Open-ended Language Interface)를 통해 세밀한 시각적 인식(Fine-grained Visual Perception) 작업을 하나의 모델로 통합하는 새로운 프레임워크입니다. 물체 수준 감지, 픽셀 수준 분할, 이미지 수준 시각-언어 과제를 통합하며, 복잡한 작업별 디코더 없이 경쟁력 있는 성능을 달성합니다.
- ***Technical Details***: UFO는 모든 감지 목표를 언어 공간으로 변환하여 물체 감지를 개방형 텍스트 시퀀스로 처리합니다. 세분화(Segmentation)는 임베딩 검색 방식으로 재구성되며, <MASK> 토큰의 임베딩과 이미지 특징 간의 유사성을 계산해 마스크를 생성합니다. 이로써 MLLMs의 강력한 시각적 이해 capabilities를 활용합니다.
- ***Performance Highlights***: 다섯 개의 표준 시각적 인식 데이터셋에서의 멀티태스크 학습 후, UFO는 이전의 최첨단 일반주의 모델보다 COCO 객체 인스턴스 분할에서 12.3 mAP, ADE20K 의미론적 분할에서 3.3 mIoU 높은 성능을 보였습니다. 이는 세밀한 인식 capabilities와 MLLMs의 고급 언어 능력을 효과적으로 결합하여 추론 분할(Reasoning Segmentation)과 같은 도전적인 작업도 가능하게 합니다.

### [Language Models can Self-Improve at State-Value Estimation for Better Search](https://arxiv.org/abs/2503.02878)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.02878.png)

Vote: 5

Authors: Ethan Mendes, Alan Ritter

- ***What's New***: 이 논문에서는 State-Value Estimation(상태-가치 추정)을 통해 언어 모델(Language Models)이 스스로 성능을 향상시킬 수 있는 Self-Taught Lookahead(STL)라는 새로운 방법론을 제안합니다. 이는 Value Model이 기반한 언어 모델이 레이블이나 보상 없이도 스스로 개선할 수 있다는 것을 처음으로 입증한 예입니다.
- ***Technical Details***: Self-Taught Lookahead는 State-Transition Dynamics(상태 전이 동역학)를 활용하여 초기 Value Function(가치 함수)을 개선하고, 이를 통해 언어 모델이 제어하는 검색이 더 효율적으로 이루어질 수 있도록 Value Model을 훈련하는 방법입니다. STL 과정은 트리 검색의 단일 Lookahead 단계를 통해 자가 개선 데이터를 생성하고, 이를 기반으로 Value Model을 Fine-Tuning 합니다.
- ***Performance Highlights***: 자체 개발된 LLM(언어 모델) 기반의 Value Model이 STL을 통해 개선됨으로써 MCTS(몬테카를로 트리 서치)와 같은 기존 방식보다 비용 효율적으로 더 나은 퍼포먼스를 보였습니다. 특히, 검색에서 STL Value Model은 20%의 성능 향상을 이루었으며, 비용 면에서 37배의 절감을 이루었습니다. 또한, STL은 성능을 유지하면서 작은 모델 파라미터 범위 내에서도 활용될 수 있음을 보여줍니다.

### [ATLaS: Agent Tuning via Learning Critical Steps](https://arxiv.org/abs/2503.02197)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.02197.png)

Vote: 5

Authors: Zhixun Chen, Meng Fang, Yuxuan Huang, Yali Du, Tianyi Zhou, Ming Li

- ***What's New***: ATLaS는 거대 언어 모델(Large Language Models; LLMs) 에이전트의 튜닝을 기존의 전체 전문가 경로 전체에 대한 감독 학습에서 중요한 단계(Critical Steps)만을 식별하여 튜닝하는 혁신적인 방법을 제시합니다. 이를 통해 전문가 바이어스(expert bias)를 줄이고, 다양한 환경과 작업에서 일반화 능력을 향상합니다.
- ***Technical Details***: ATLaS는 4가지 기준에 기반해 모니터링한 전문가 경로 내에서 계획 수립, 중요한 관찰, 계획 기억, 중대한 행동을 포함한 중요한 단계를 식별합니다. 그런 다음, 이러한 단계에서만 LLM을 미세 조정하여 학습의 초점을 하여 효과적인 에이전트 튜닝을 수행합니다. 이는 전체 경로에 대한 오버피팅을 줄이고, 다양한 상황에서의 일반화를 개선합니다.
- ***Performance Highlights***: ATLaS는 전문가 경로의 약 30%의 중요한 단계를 선택하여 훈련된 LLM이 전체 경로로 튜닝된 LLM과 최신 오픈 소스 LLM 에이전트를 초과하는 성능을 보여줍니다. 특히 여러 작업 학습 시나리오에서 이는 전문가 바이어스와 과제 간의 부정적 전이를 완화하며, 부분 경로 단순 모방 전략보다 뛰어난 일반화 능력을 발휘합니다.

### [SPIDER: A Comprehensive Multi-Organ Supervised Pathology Dataset and Baseline Models](https://arxiv.org/abs/2503.02876)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.02876.png)

Vote: 4

Authors: Ekaterina Ivanova, Alexey Pchelnikov, Dmitry Nechaev

- ***What's New***: SPIDER는 다양한 장기 유형을 포함하는 가장 큰 공개 가능한 병리 데이터세트로, 피부, 대장, 흉부 등의 포괄적인 클래스 커버리지를 제공합니다. 이 데이터세트는 전문가 병리학자들이 검증한 고품질의 주석을 제공하며, 주변 문맥 패치를 포함해 공간 컨텍스트로 분류 성능을 향상시킵니다. 데이터세트를 바탕으로 Hibou-L (Hibou-L Foundation Model)을 피쳐 추출기로 사용하여 주의 기반 분류 헤드를 결합한 기준 모델들을 제공하며, 이는 여러 조직 범주에서 최첨단 성능을 달성합니다.
- ***Technical Details***: SPIDER 데이터세트는 여러 장기 유형에 대해 패치 레벨에서 전문가가 주석한 이미지로 구성되어 있으며, 224×224 크기의 센트럴 패치와 추가적인 문맥 패치들로 이뤄진 1120×1120 크기의 영역을 포함합니다. Hibou-L 모델을 피쳐 추출기로 사용하고, 주의 기반 분류 헤드를 갖춘 모델 아키텍처를 설계하여 센트럴 패치의 분류 정확성을 높였습니다. 각 장기 유형마다 별도의 모델을 훈련하며 크로스 엔트로피 손실 함수를 사용하고, 훈련 중에는 Hibou 피쳐 추출기를 고정하여 사전 학습된 고품질 피쳐를 활용합니다.
- ***Performance Highlights***: 훈련된 모델들은 여러 장기 유형에 대해 강력한 성능을 보입니다. 예를 들어, 피부에서의 정확도는 94.0%, 대장은 91.4%, 흉부는 96.2%를 기록했습니다. 문맥의 크기를 줄이면 모델 정확도가 감소하며, 이는 컨텍스트가 모델 예측에서 중요한 역할을 한다는 것을 보여줍니다. 이러한 결과는 다양한 조직 유형에서 모델의 우수한 성능을 나타냅니다.

### [AppAgentX: Evolving GUI Agents as Proficient Smartphone Users](https://arxiv.org/abs/2503.02268)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.02268.png)

Vote: 3

Authors: Chi Zhang, Wenjia Jiang, Xu Yang, Yangyang Zhuang, Chenxi Song

- ***What's New***: AppAgentX는 GUI 에이전트가 작업 실행 기록에서 고수준의 작업을 추상화하여 효율성과 지능을 향상시키는 새로운 진화적 프레임워크를 제안합니다. 이는 반복적인 작업을 줄이고 지능과 효율성을 조화롭게 유지하는 것을 목표로 합니다.
- ***Technical Details***: AppAgentX의 핵심 방법론은 에이전트의 작업 실행 기록을 체인으로 저장하는 메모리 메커니즘, 효율성을 개선하기 위한 진화 메커니즘, 그리고 변형된 에이전트를 사용하는 실행 전략 등 세 가지 주요 구성 요소로 이루어져 있습니다. 또한 OmniParser를 활용하여 UI 요소를 인식하고 식별하여, 이를 바탕으로 행동을 계획하고 발전시키는 과정이 주요 기반을 이룹니다.
- ***Performance Highlights***: AppAgentX는 여러 벤치마크 작업에서 기존의 방법들에 비해 효율성과 정확성을 크게 개선했습니다. 작업 수행에 필요한 평균 단계를 줄였고, 고수준 작업에 필요한 진화된 행동 공간을 활용하여 평균 성공률을 높였습니다. 기존의 메모리 메커니즘이 없이 성공률이 16.9%에 그친 반면 체인 구조의 메모리를 활용해 70.8%로 대폭 향상되었습니다.

### [IterPref: Focal Preference Learning for Code Generation via Iterative Debugging](https://arxiv.org/abs/2503.02783)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.02783.png)

Vote: 3

Authors: Haoling Li, Yujiu Yang, Xin Zhang, Jianwen Luo, Ruihang Chu, Jie Wu, Yangyu Huang, Scarlett Li

- ***What's New***: IterPref는 인간의 반복적인 디버깅 과정을 모방하여 코드 생성의 정확성을 높이는 새로운 프레임워크입니다. 이 접근법은 에러 영역을 명시적으로 찾아내고 해당 토큰을 맞춤형 DPO(Direct Preference Optimization) 알고리즘을 통해 정렬합니다.
- ***Technical Details***: IterPref는 CodeFlow 데이터셋을 사용하여 선호 코드를 생성합니다. 여기서는 코드 LLM이 처음 코드를 생성한 후, 반복적으로 수정하여 모든 테스트를 통과하는 동안의 오류 수정을 기록합니다. 또한 IterPref는 선호 학습을 위한 새로운 DPO 알고리즘을 설계하여 오류 토큰을 표시하고, 맞춤 조정을 통해 모델을 학습했습니다.
- ***Performance Highlights***: 59,000개 선호 쌍만으로도 IterPref는 HumanEval 및 MBPP에서 유의미한 성능 향상을 이루었으며, BigCodeBench와 같은 복잡한 작업에서 뛰어난 결과를 보여주었습니다. DS-Coder-7B-Instruct와 Qwen2.5-Coder-7B 모델의 성능이 각각 pass@1에서 4.0%, 7.4% 향상되었습니다.

### [Q-Eval-100K: Evaluating Visual Quality and Alignment Level for Text-to-Vision Content](https://arxiv.org/abs/2503.02357)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.02357.png)

Vote: 3

Authors: Xiaohong Liu, Xiongkuo Min, Tengchuan Kou, Xiaoyu Li, Shushi Wang, Wei Wang, Xuezhi Cao, Zicheng Zhang, Wei Sun, Zongyu Wang, Guangtao Zhai, Chunyi Li

- ***What's New***: Q-Eval-100K는 텍스트에서 이미지와 동영상으로 변환된 콘텐츠의 시각적 품질과 일치도(Alignment) 수준을 평가하는 데 중점을 둔 최대 규모의 데이터셋을 제공합니다. 이는 60K 이미지와 40K 동영상의 100K 인스턴스에 대해 960K의 인간 주석을 포함하여 Mean Opinion Scores(MOS) 기반으로 구성되어 있습니다.
- ***Technical Details***: Q-Eval-100K 데이터셋은 인간 주석을 통해 시각적 품질과 일치도를 다차원적으로 분석합니다. Supervised Fine-Tuning(SFT) 데이터셋으로 변환하여, LMMs(Large Multimodal Models)에 지식을 주입하기 위해 시각적 품질과 맞춤 알고리즘에 초점을 맞춘 통합 모델 Q-Eval-Score를 제안합니다. 시각적 품질을 위한 데이터는 긍정과 부정의 시각적 요소를 식별하고, 세부 사항과 전반적인 정밀도를 평가하는 등 심층적인 평가 과정을 거칩니다.
- ***Performance Highlights***: Q-Eval-Score 모델은 시각적 품질과 일치도 평가에서 우수한 성과를 보였습니다. 이미지의 경우 모델 수준에서 0.94 이상의 성능을 달성하며, 이는 인간 평가와 밀접하게 일치합니다. 특히 긴 프롬프트 처리를 위한 Vague-to-Specific 전략을 도입하여 평가의 신뢰성을 더욱 강화했습니다.

### [Improve Representation for Imbalanced Regression through Geometric Constraints](https://arxiv.org/abs/2503.00876)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.00876.png)

Vote: 3

Authors: Yilei Wu, Zijian Dong, Yichi Zhang, Chongyao Chen, Yingtian Zou, Juan Helen Zhou

- ***What's New***: 이 논문은 불균형한 회귀(imbalanced regression) 문제를 해결하기 위해 기하학적 제약(geometric constraints)을 통합한 새로운 표현 학습 접근 방식을 소개합니다. 이는 불균형 레이블 분포에서 균일한 특징 분포를 촉진하는 두 가지 기하학적 손실 함수인 동봉 손실(enveloping loss)과 균질성 손실(homogeneity loss)을 도입한 최초의 연구입니다.
- ***Technical Details***: 제안된 방법은 대리 기반 표현 학습(Surrogate-driven Representation Learning, SRL) 프레임워크를 사용하여 기하학적 제약을 데이터 표현에 통합합니다. 동봉 손실은 하이퍼스피어의 표면을 충분히 채우기 위해 표현의 궤적 경로를 최적화하며, 균질성 손실은 그 궤적을 따라 균일하고 부드러운 분포를 확보합니다. 이 방법은 연속적인 라벨 범위를 효과적으로 커버하기 위해 미니 배치 내에서 동일한 값의 표현을 평균하여 중심점을 구성합니다.
- ***Performance Highlights***: SRL 프레임워크는 실제 회귀 및 연산자 학습 테스트에서 기존의 벤치마크를 능가했으며, 특히 미디엄 샷(medium-shot) 및 퓨 샷(few-shot) 영역에서 큰 성능 개선을 보여주었습니다. 예를 들어, AgeDB-DIR 데이터셋에서 MAE가미디엄 샷 영역에서 9.30에서 8.28로 개선되었습니다. OL-DIR에서는 선형 및 비선형 연산자 학습 모두에서 높은 정확성과 일반화 성능을 보였습니다.

### [A Multimodal Symphony: Integrating Taste and Sound through Generative AI](https://arxiv.org/abs/2503.02823)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.02823.png)

Vote: 2

Authors: Massimiliano Zampini, Franco Pierucci, Matteo Spanio, Antonio Rodà

- ***What's New***: 이 논문은 맛(Taste)과 소리(Sound)를 결합하여 음악을 생성하는 멀티모달 생성 모델을 소개합니다. 이는 인간의 오감을 기술로 통합하는 새로운 접근법을 제안하는 중요한 연구입니다.
- ***Technical Details***: MusicGEN이라는 기존의 생성 모델을 미세 조정하여 맛을 기반으로 음악을 생성하는 실험을 수행했습니다. 이를 위해 Taste & Affect Music Database를 확장하여 각 음악 조각의 맛과 관련한 감정적 특성을 상세히 캡션으로 작성했습니다. MusicGEN의 Transformer 기반 아키텍처는 텍스트 혹은 멜로디 조건에 맞추어 높은 품질의 음악을 생성합니다.
- ***Performance Highlights***: 사용자가 평가한 결과, 미세 조정된 모델은 비미세 조정 모델보다 입력 맛 설명에 더 일관된 음악을 생성하는 것으로 나타났습니다. 특히 단맛, 신맛, 쓴맛에는 효과적이었으나 짠맛은 상대적으로 적은 수준의 일관성을 보였습니다. Fréchet Audio Distance를 통해 생성된 음악과 훈련 데이터세트 간의 유사성을 측정한 결과, 미세 조정 모델이 더 나은 성능을 보였습니다.

### [Q-Filters: Leveraging QK Geometry for Efficient KV Cache Compression](https://arxiv.org/abs/2503.02812)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.02812.png)

Vote: 2

Authors: Simone Scardapane, Nathan Godey, Benoît Sagot, Éric de la Clergerie, Pasquale Minervini, Yu Zhao, Alessio Devoto

- ***What's New***: Q-Filters는 Query-Key 기하학(QK Geometry)을 활용하여 이전 Key-Value 쌍을 중요도 기준으로 필터링하는 최초의 훈련 불필요(Key-Value Cache; KV Cache) 압축 기법입니다. 이 기법은 FlashAttention과 호환 가능하여 주목을 받고 있습니다.
- ***Technical Details***: Q-Filters는 각 레이어와 헤드별 Query-Fi lters를 식별하고, 이를 바탕으로 Key-Value 쌍을 투영하여 중요도를 추정합니다. 첫 번째 중앙고유 벡터 방향으로 회전해 필터링하며, 이 방향이 컨텍스트에 무관하게 일관되다는 점을 활용합니다. 각 모델마다 한 번의 사전 보정 데이터셋으로 이 로직을 검정해 성능을 극대화합니다.
- ***Performance Highlights***: Q-Filters는 needle-in-a-haystack 과제에서 x32 압축률을 사용하여 99%의 정확도를 달성했고, 텍스트 생성에서 Streaming-LLM보다 최대 65% 낮은 당혹감 감소를 기록했습니다. 윤곽상에서 가장 인기 있는 Spot Compression 기법 중 하나인 SnapKV와 비교했을 때에도 성능이 비슷하거나 우수했습니다.

### [RSQ: Learning from Important Tokens Leads to Better Quantized LLMs](https://arxiv.org/abs/2503.01820)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.01820.png)

Vote: 2

Authors: Jialu Li, Yi-Lin Sung, Prateek Yadav, Mohit Bansal, Jaehong Yoon

- ***What's New***: RSQ는 중요한 토큰(Important Tokens)을 학습하는 방식으로 대형 언어 모델(LLMs)의 양자화 성능을 향상시키는 새로운 접근법을 제안합니다. 이 연구는 주목받는 토큰들(예: 높은 주의(attention) 점수를 가지는 토큰)로부터 학습이 더 나은 양자화 모델을 생성할 수 있음을 보여줍니다.
- ***Technical Details***: RSQ는 'Rotate, Scale, then Quantize'라는 세 가지 단계를 통해 모델을 양자화합니다. 먼저 회전(오소고날 변환)을 통해 이상치(outlier)를 줄이고, 각 토큰의 중요도에 따라 특징 크기를 조절한 후, GPTQ 프레임워크를 이용하여 두 번째 통계 계수로 모델을 양자화합니다. 토큰 중요도는 주의 집중도(attention concentration)를 사용하여 평가합니다.
- ***Performance Highlights***: RSQ는 LLaMA3, Mistral, Qwen2.5 모델군을 포함한 다양한 다운스트림 작업에서 기존 방법보다 지속적으로 우수한 성능을 보여주었습니다. 특히, 긴 문맥(long-context) 작업에서 더 나은 성능을 발휘하였으며, 다양한 설정, 모델 크기, 보정 데이터셋, 비트 정밀도 및 양자화 방법 능력을 통해 일반화 능력을 입증하였습니다.

### [Teaching Metric Distance to Autoregressive Multimodal Foundational Models](https://arxiv.org/abs/2503.02379)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.02379.png)

Vote: 2

Authors: Youngjae Yu, Saejin Kim, Jiwan Chung, Dongjun Min, Jaewoo Park, Yongrae Jo

- ***What's New***: 이 논문에서는 오토회귀 멀티모달 기본 모델(Autoregressive Multimodal Foundational Models)에 메트릭 거리 정보(Metric Distance)를 학습시키는 새로운 손실 함수(DIScreTized DISTance Loss; DIST2Loss)를 소개합니다. DIST2Loss는 출력 토큰 간의 미리 정의된 거리 관계를 활용하여, 모델이 토큰 생성 과정에서 의미 있는 거리 관계를 학습하고 유지할 수 있도록 지원합니다.
- ***Technical Details***: DIST2Loss는 연속적인 지수 분포(Exponential Family Distributions)를 이산적 카테고리형 최적화 타겟으로 변환하여, 모델의 아키텍처와 호환되도록 설계되었습니다. 이 손실 함수는 시각적 그라운딩(Visual Grounding), 로봇 조작(Robotic Manipulation), 생성적 보상 모델링(Generative Reward Modeling), 벡터 양자화 특성을 사용하는 이미지 생성(Image Generation)과 같은 다양한 멀티모달 응용 분야에 적용됩니다.
- ***Performance Highlights***: DIST2Loss는 제한된 학습 데이터를 가진 환경에서도 성능 개선을 보여주며, 특히 시각적 그라운딩과 로봇 조작에서의 정확도를 높이고, 생성적 보상 모델링과 벡터 양자화 이미지 생성에서의 학습 성능을 향상시킵니다. 이는 자원 제약이 있는 설정에서 DIST2Loss의 효과성을 보여줍니다.

### [Tabby: Tabular Data Synthesis with Language Models](https://arxiv.org/abs/2503.02152)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.02152.png)

Vote: 1

Authors: Nicholas Roberts, Frederic Sala, Sonia Cromp, Mohammed Alkhudhayri, Satya Sai Srinath Namburi GNVV, Catherine Cao, Samuel Guo

- ***What's New***: Tabby는 Transformer 기반 대형 언어 모델(LLMs)을 테이블 데이터 합성(Tabe synthesis)에 적합하게 만드는 최초의 아키텍처 수정입니다. Tabby는 언어 모델의 특정 블록을 선택하여 Mixture-of-Experts(MoE) 레이어로 대체, 각 데이터 열이 고유한 매개변수로 모델링되도록 합니다. 이는 기존 기법과 비교해 최대 44% 품질 향상을 제공합니다. 이 기술을 통해 Tabby는 테이블을 넘어 JSON과 같은 일반적인 구조 데이터에도 적용 가능합니다.
- ***Technical Details***: Tabby는 Transformer LLM 구조에 사후 훈련 수정(Post-training modification)을 적용, 특정 LLM 블록을 Mixture-of-Experts 레이어로 교체하여 테이블의 각 열을 고유한 매개변수 집합으로 모델링합니다. 추가로, Plain이라 불리는 간소화된 테이블 훈련 기법이 제안되어기존 기법에 비해 5/6 데이터세트에서 데이터 품질을 향상시킵니다.
- ***Performance Highlights***: Tabby는 6개의 테이블 데이터 세트 중 4개에서 실제 데이터와 유사한 또는 동일한 합성 데이터 품질을 제공합니다. 또한 Travel, Diabetes, Adult 데이터세트에서 상위 성능을 기록하며, 기존 SOTA(tab-DDPM)와 비교해서도 대부분의 설정에서 동급 또는 더 나은 성능을 발휘합니다. 각 열의 손실 추적이 가능하여, 훈련 중 모델 행동에 대한 더 나은 이해를 제공합니다.

### [A Token-level Text Image Foundation Model for Document Understanding](https://arxiv.org/abs/2503.02304)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.02304.png)

Vote: 1

Authors: Wei Shen, Chen Duan, Xiaokang Yang, Pei Fu, Zhengtao Guo, Junfeng Luo, Hao Sun, Zining Wang, Tiezhu Yue, Qianyi Jiang, Kai Zhou, Tongkun Guan

- ***What's New***: 이 연구에서는 텍스트 이미지 관련 작업에 특화된 최초의 토큰 수준 비주얼 모델인 TokenOCR을 개발하였습니다. 이를 지원하기 위해 첫 번째 토큰 수준 이미지 텍스트 데이터셋인 TokenIT을 구축하였으며, 2000만 개의 이미지와 18억 개의 토큰-마스크 쌍이 포함되어 있습니다. TokenOCR은 다양한 전통 다운스트림 응용 프로그램을 지원하도록 설계되었습니다.
- ***Technical Details***: TokenOCR은 이미지-텍스트 의미 정렬을 위해 각 토큰 수준 비주얼 임베딩이 해당 토큰 마스크 내의 비주얼 이미지 특징에 평균 풀링(mean pooling) 연산을 적용하여 파생됩니다. 단순한 토큰 임베딩 레이어를 사용하여 복잡한 텍스트 인코더 없이 비주얼-언어 모달리티를 토큰 수준에서 정렬하게 됩니다. 또한, Document-level MLLM인 TokenVL을 제안하여 문서 이해를 위한 VQA 기반의 작업에서 공간적 시각-언어 토큰 정렬을 강화하였습니다.
- ***Performance Highlights***: TokenVL은 8B 파라미터 그룹에서 OCRBench 작업에서 38포인트 개선된 결과를 보여주었으며, 10개의 문서 VQA 작업에서 평균 8.8%의 향상을 달성하였습니다. TokenOCR은 CLIP, SAM 및 InternViT2.5와 같은 다른 모델들에 비해 'zero-shot' 능력 및 유연성 면에서 뛰어난 성능을 보였으며, Text Segmentation 과 Visual Question Answering 작업에서 유의미한 성능 향상을 기록했습니다.

### [Unified Video Action Model](https://arxiv.org/abs/2503.00200)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.00200.png)

Vote: 0

Authors: Yihuai Gao, Shuran Song, Shuang Li, Dorsa Sadigh

- ***What's New***: Unified Video Action Model (UVA)는 로봇 공학에서 비디오 생성과 행동 예측을 효과적으로 결합하는 방식을 제시합니다. 이 모델은 비디오와 행동 데이터를 동시에 학습하여 높은 정확도와 효율적인 행동 추론을 이룰 수 있는 통합적인 비디오-행동 잠재 표현을 도입했습니다.
- ***Technical Details***: UVA는 비디오와 행동 데이터를 통합하여 잠재 표현을 학습합니다. 두 개의 가벼운 확산 헤드(diffusion heads)를 사용하여 비디오 관찰과 행동을 디코딩하며, 비디오 생성 없이 빠른 행동 예측을 할 수 있습니다. 모델은 임의 마스킹 학습(masked training)을 활용하여 다양한 입력과 출력을 지원하며, 이를 통해 정책(policy), 비디오 모델, 순방향 및 역방향 동력학 모델로 작동할 수 있습니다. 활용된 많은 기술 중 Transformer와 확산 모델(density diffusion models) 등의 요소가 있습니다.
- ***Performance Highlights***: UVA는 다양한 로봇 공학 과제에서 기존 최첨단 모델들을 능가하거나 동등한 성능을 보여줍니다. Multi-task 설정에서 특히 강한 성능을 보여 PushT-M에서 20%의 성공률을, Libero10에서는 13%의 성공률 향상을 기록했습니다. 이러한 강력한 성능은 특정 응용에 맞춰진 방식에 비해 성능 저하 없이 일반적 적용이 가능함을 보여줍니다.

### [Discrete-Time Hybrid Automata Learning: Legged Locomotion Meets Skateboarding](https://arxiv.org/abs/2503.01842)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.01842.png)

Vote: 0

Authors: Ben Liu, Maani Ghaffari, Wei Zhang, Sangli Teng, Hang Liu

- ***What's New***: 이 논문은 **Discrete-Time Hybrid Automata Learning (DHAL)** 프레임워크를 소개합니다. 이는 강화 학습을 활용하여 이산 모드 전환을 명시적으로 모델링함으로써 전통적 궤적 분할이나 사건 함수 학습 없이 하이브리드 역학 시스템의 모드 전환을 학습하고 실행할 수 있습니다. 특히, 이 프레임워크는 **강화 학습(RL)**과 **베타 분포(Beta Distribution) 정책**을 활용하여 모드 전환을 효과적으로 처리하며, 사족 로봇의 스케이트보드 타기 과제를 통해 검증되었습니다.
- ***Technical Details***: DHAL은 다양한 모드에서의 흐름 역학과 모드 간 전환을 명시적으로 모델링합니다. 제안된 **하이브리드 오토마타**는 이산 모드를 선택하고, **다중 크리틱 아키텍처(multi-critic architecture)**를 통해 각각의 모드에서 접촉 기반 운동을 모델링합니다. 또한, 사족 로봇이 스케이트보드라는 복잡한 과제를 수행할 수 있도록 **Sim2Real** 접근 방식을 사용하여 실제 환경에서도 높은 민첩성을 보여줍니다.
- ***Performance Highlights***: DHAL은 다양한 실내 및 실외 지형에서 강건한 성능을 발휘하며, 여러 종류의 방해와 하중을 포함한 시나리오에서 신뢰성 있는 모드 전환을 수행합니다. 특히, **Sim2Real** 테스트에서 적대적 조건에도 불구하고 스케이트보드를 사용하여 자연스러운 운동을 수행하는데 성공했습니다. 이는 접촉 기반 하이브리드 역학 시스템에서의 높은 성능을 입증합니다.

