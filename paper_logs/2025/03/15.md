## Daily Papers (2025-03-15)

### [PoseLess: Depth-Free Vision-to-Joint Control via Direct Image Mapping with VLM](https://arxiv.org/abs/2503.07111)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.07111.png)

Vote: 1

Authors: Alan Dao, Bui Quang Huy, Tuan Le Duc Anh, Dinh Bach Vu

- ***What's New***: PoseLess는 로봇 손 제어에서 명시적인 포즈 추정 없이 2D 이미지를 로봇 관절 각도로 직접 매핑하는 독창적인 프레임워크를 소개합니다. 이 접근법은 VLM(Vision Language Models)의 강력한 이미지를 사용하여 단일 이미지에서 직접 관절 명령을 추출하며, 데이터 레이블링 의존도를 없애고 다양한 손 형태에서의 일반화를 가능하게 합니다.
- ***Technical Details***: PoseLess는 랜덤화된 관절 구성 데이터를 생성하여 무인 일반화를 실현합니다. 이를 통해 수동 라벨링 데이터세트의 의존도를 없애고, 특히 단일 카메라 환경에서 깊이 추정이 어려운 경우에 대한 강건한 제어를 유지합니다. Qwen 2.5 3B Instruct 와 같은 VLM을 사용하여 이미지를 토큰화하고, 조인트 앵글(Joint Angles)로 매핑합니다.
- ***Performance Highlights***: 실험 결과, 'PoseLess'는 합성 데이터로만 학습했음에도 불구하고 관절 각도 예측에서 경쟁력 있는 성능을 보였으며, 이는 35-40% 정도의 평균 MSE 감소로 나타났습니다. 이러한 결과는 합성된 환경에서도 혁신적인 통제 모델의 가능성을 입증하였으며, 특히 단일 보기 이미지를 사용한 깊이 없는 제어의 가능성을 열어줍니다.

