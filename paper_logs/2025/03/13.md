## Daily Papers (2025-03-13)

### [TPDiff: Temporal Pyramid Video Diffusion Model](https://arxiv.org/abs/2503.09566)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.09566.png)

Vote: 33

Authors: Mike Zheng Shou, Lingmin Ran

- ***What's New***: TPDiff는 비디오 생성 과정의 시간적 중복성을 고려한 'Temporal Pyramid' 비디오 확산 모델을 제안합니다. 기존 확산 프로세스를 여러 단계로 나누고, 마지막 단계에서만 전체 프레임 속도를 유지하여, 훈련 및 추론 효율성을 크게 향상시킵니다. 이를 통해 훈련 비용을 50% 절감하고 추론 효율성을 1.5배 향상시켰습니다.
- ***Technical Details***: TPDiff는 비디오 확산 모델의 훈련과 추론에서 'stage-wise diffusion' 훈련 프레임워크를 도입하여 일반화된 솔루션을 제공합니다. 이 방법에서는 데이터-노이즈 정렬을 활용하여 다양한 확산 형태에 적용 가능하며, 분할된 확률 흐름 ODE(Ordinary Differential Equations)를 해결하여 각 단계의 프레임 속도를 점진적으로 증가시킵니다.
- ***Performance Highlights***: TPDiff는 기존의 Vanilla 확산 모델에 비해 훈련 속도에서 2배, 추론에서 1.5배 향상된 성능을 보여주었습니다. 또한, MiniFlux-vid와 AnimateDiff를 사용하여 동일한 데이터셋에서 실험한 결과, 성능 저하 없이 더 나은 효율성을 달성하였습니다.

### [Block Diffusion: Interpolating Between Autoregressive and Diffusion Language Models](https://arxiv.org/abs/2503.09573)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.09573.png)

Vote: 31

Authors: Zhihan Yang, Justin T Chiu, Subham Sekhar Sahoo, Zhixuan Qi, Marianne Arriola, Volodymyr Kuleshov, Aaron Gokaslan, Jiaqi Han

- ***What's New***: 이 논문에서는 차단 확산 언어 모델(Block Diffusion Language Models)을 소개하며, 이는 불연속 디노이징(Discrete Denoising)과 자율 회귀(Autoregressive) 모델 사이의 중간적 방법을 통해 더 유연한 길이의 생성과 증대된 추론 효율성(KV Caching 및 병렬 토큰 샘플링)을 지원합니다. 이는 차단 기반 확산 모델에서 최대 성능을 달성하며 임의 길이의 시퀀스를 생성할 수 있게 해줍니다.
- ***Technical Details***: 제안된 차단 확산 언어 모델(BD3-LMs)은 대량의 토큰 블록에 대해 자율 회귀 확률 분포를 정의하고 각 블록 내부에서 불연속 디노이징 확산을 수행합니다. 고정 길이 벡터만을 생성하는 기존 확산 아키텍처의 한계를 극복하여 KV 캐싱 및 병렬 샘플링으로 효율성을 높였습니다. 맞춤형 노이즈 스케줄을 사용하여 기울기 변동성을 줄이고, 이를 통해 학습 성능을 개선했습니다.
- ***Performance Highlights***: BD3-LMs은 LM1B와 OpenWebText 데이터셋에 대해 이전의 모든 확산 방식 대비 최대 13% 이상의 불확실성을 줄이고 성능을 개선하며 새로운 상태의 미학적 당황감을 설정하였습니다. 실험을 통해 BD3-LMs은 임의 길이 시퀀스의 생성을 지원하며, 생성적 복잡성이 적은 상태로 이전 방법과 비교할 때 훨씬 적은 생성 단계를 통해 향상된 샘플 품질을 제공합니다.

### [Reangle-A-Video: 4D Video Generation as Video-to-Video Translation](https://arxiv.org/abs/2503.09151)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.09151.png)

Vote: 24

Authors: Hyeonho Jeong, Suhyeon Lee, Jong Chul Ye

- ***What's New***: Reangle-A-Video는 단일 입력 비디오에서 동기화된 다중 뷰 비디오를 생성하는 통합 프레임워크입니다. 기존의 여러 뷰 비디오 확산 모델 훈련과는 달리, 이 방법은 이미지 및 비디오 확산 선행을 활용하여 비디오-비디오 번역으로 재구성합니다.
- ***Technical Details***: Reangle-A-Video는 두 단계로 작동합니다. 첫 번째 단계는 Multi-View Motion Learning으로, 이미지-비디오 확산 변환기를 자기 지도 학습 방식으로 민곡하며, 왜곡된 비디오 셋에서 보기에 불변인 움직임을 저장합니다. 두 번째 단계는 Multi-View Consistent Image-to-Images Translation이며, DUSt3R를 사용해 입력 비디오의 첫 프레임을 다양한 카메라 관점으로 왜곡하고 재촉색해 다중 뷰에 대해 일관성 있는 시점 이미지를 생성합니다.
- ***Performance Highlights***: 정적 뷰 전송과 동적 카메라 제어에 대한 광범위한 실험을 통해 Reangle-A-Video가 기존 방법들을 능가하는 성능을 입증했으며, 공개적으로 코드와 데이터를 제공할 예정입니다.

### [GTR: Guided Thought Reinforcement Prevents Thought Collapse in RL-based VLM Agent Training](https://arxiv.org/abs/2503.08525)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.08525.png)

Vote: 10

Authors: Junliang Xing, Deheng Ye, Zongqing Lu, Yuanchun Shi, Tong Wei, Yijun Yang

- ***What's New***: 이 연구는 강화학습(RL; Reinforcement Learning) 기반의 시각적 언어 모델(VLM; Vision-Language Model) 에이전트 훈련에서 발생하는 사고 붕괴(Thought Collapse) 문제를 해결하기 위한 새로운 프레임워크인 Guided Thought Reinforcement(GTR)를 제안합니다. GTR은 프로세스 지도를 통해 에이전트의 사고 다양성을 유지하고 올바른 행동 결정을 강화합니다.
- ***Technical Details***: GTR 프레임워크는 기존의 VLM 모델을 평가하고 교정하는 자동화된 Corrector 모델을 도입하여, 각 RL 훈련 단계에서 에이전트의 사고를 평가하고 개선합니다. 이 Corrector 모델은 에이전트의 사고와 행동을 동시에 훈련하며, 학습 과정에서 인간의 라벨링이 필요하지 않습니다. 이는 확장 가능하며, 다양한 비쥬얼 환경에서 에이전트를 효과적으로 훈련할 수 있게 합니다.
- ***Performance Highlights***: GTR을 사용한 LLaVA-7b 모델은 기존의 최첨단 모델 대비 최대 3~5배 높은 임무 성공률을 기록했습니다. 특히 복잡한 카드 게임인 24 포인트와, ALFWorld 내 다양한 임베디드 환경에서 더 높은 성과와 샘플 효율성을 보여주었습니다.

### [More Documents, Same Length: Isolating the Challenge of Multiple Documents in RAG](https://arxiv.org/abs/2503.04388)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.04388.png)

Vote: 10

Authors: Nir Mazor, Gabriel Stanovsky, Lihi Shalmon, Shahar Levy, Michael Hassid

- ***What's New***: 이 연구는 RAG(Retrieval-Augmented Generation) 시스템에서 여러 문서의 수가 모델 성능에 미치는 영향을 고정된 문맥 길이에서 평가한 최초의 연구 중 하나입니다. 문서 수를 늘리면 LLMs의 성능이 저하될 수 있으며, 이는 긴 문맥 처리뿐만 아니라 여러 문서 간의 복잡한 정보 처리가 추가적인 도전 과제임을 보여줍니다.
- ***Technical Details***: 연구팀은 MuSiQue 데이터셋을 기반으로 다양한 문서 세트를 구성했습니다. 문서 수를 줄이면서도 문맥 길이는 동일하게 유지함으로써 각 문서의 정보를 평가했습니다. LLMs의 성능은 Gold와 예측 결과 간의 F1 점수를 통해 평가되었습니다. 실험에는 Llama-3.1, Qwen2, Gemma2 모델이 활용되었으며, Together.ai 플랫폼과 A6000 GPU를 통해 실행되었습니다.
- ***Performance Highlights***: 실험 결과, 대부분의 모델에서 문서 수가 줄어들수록 성능이 최대 10% 개선되었습니다. 특히 Llama-3.1과 Gemma-2 모델의 경우 추가적인 문서는 성능 저하를 불러일으킬 수 있음을 확인했습니다. 다만 Qwen2 모델은 이러한 영향을 상대적으로 덜 받았으며, 여러 문서 처리가 더 잘 이루어질 수 있음을 시사했습니다.

### [RewardSDS: Aligning Score Distillation via Reward-Weighted Sampling](https://arxiv.org/abs/2503.09601)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.09601.png)

Vote: 10

Authors: Guy Yariv, Sagie Benaim, Itay Chachy

- ***What's New***: RewardSDS는 스코어 증류(Score Distillation; SDS) 모델을 리워드 가중 샘플링(Reward-Weighted Sampling)을 통해 사용자 의도에 맞게 조정하는 새로운 접근 방식을 제시합니다. 리워드 모델의 정렬 스코어에 기반하여 노이즈 샘플을 가중하고, 이를 통해 고성능 및 정렬 모델 생성을 가능하게 합니다.
- ***Technical Details***: RewardSDS는 다양한 노이즈 샘플 {ϵ(t)}를 가중하여 처리하여 생성 결과의 품질과 사용자 의도에의 정렬을 향상시킵니다. 각 노이즈 샘플은 디퓨전 모델을 통해 디노이징 후 리워드 모델에 입력되어 정렬 점수(alignment score)를 획득하며, 각 샘플의 손실은 이 정렬 점수에 따라 가중됩니다. RewardSDS는 특정 리워드 모델에 구애받지 않으며, 다양한 최적의 기법을 활용할 수 있는 확장성 있는 프레임워크입니다.
- ***Performance Highlights***: 텍스트-이미지, 2D 편집, 텍스트-3D 생성 작업에서 RewardSDS와 RewardVSD는 표준 SDS와 VSD에 비해 생성 품질 및 의도 정렬 측면에서 상당한 성능 향상을 보였습니다. 특히 CLIPScore, Aesthetic Score, ImageReward, LLM Grader의 다양한 메트릭에서 개선된 결과를 나타냈습니다. 예를 들어, ImageReward를 활용한 모델은 우수한 밸런스를 제공하며, 효과적인 최적화 성과를 보였습니다.

### [Motion Anything: Any to Motion Generation](https://arxiv.org/abs/2503.06955)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.06955.png)

Vote: 7

Authors: Rui Zhao, Biao Wu, Zeyu Zhang, Zirui Song, Yiran Wang, Bohan Zhuang, Danning Li, Wei Mao, Ian Reid, Richard Hartley

- ***What's New***: Motion Anything은 다양한 멀티모달 조건(예: 텍스트 쿼리, 배경 음악 등)을 통해 고품질의 인간 모션을 생성하는 혁신적인 any-to-motion 생성 프레임워크입니다. 저자들은 텍스트, 음악, 댄스의 2,153개 쌍으로 구성된 새로운 TMD(Text-Music-Dance) 데이터셋을 도입하여 커뮤니티의 멀티모달 모션 생성 연구를 더욱 발전시키고자 합니다.
- ***Technical Details***: Motion Anything은 주어진 조건에 따라 중요한 프레임과 동작에 세밀한 공간 및 시간적 제어를 가능하게 하는 Attention-based Mask Modeling 접근 방식을 도입했습니다. 이 모델은 조건이 텍스트든 음악이든 이에 맞춰 적응적으로 코딩되며, Spatial Aligning Transformer와 Temporal Adaptive Transformer를 사용하여 멀티모달 조건 간 정렬을 수행하고 조절 가능성을 향상합니다.
- ***Performance Highlights***: Motion Anything은 여러 벤치마크에서 최신 기법을 능가하며, HumanML3D에서 FID를 15% 개선하는 성과를 냈습니다. 또한 AIST++와 TMD 데이터셋에서도 일관된 성능 향상을 보여주었습니다.

### [Quantizing Large Language Models for Code Generation: A Differentiated Replication](https://arxiv.org/abs/2503.07103)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.07103.png)

Vote: 6

Authors: Alessandro Giagnorio, Antonio Mastropaolo, Massimiliano Di Penta, Gabriele Bavota, Saima Afrin

- ***What's New***: 본 연구에서는 최신 코드 관련 LLMs(Large Language Models)의 양자화(quantization) 기술을 차용하여 메모리 사용량을 극적으로 줄이고자 합니다. 기존 연구에서는 최대 16B 파라미터 모델을 int 8 비트로 양자화하였으나, 이번 연구에서는 최대 34B 파라미터 모델을 2비트까지 극단적인 양자화 수준으로 압축할 수 있는 최신 양자화 기술을 사용하여 성능을 유지하는 것을 실험적으로 확인했습니다.
- ***Technical Details***: 본 논문은 두 가지 코드 LLMs, CodeLlama와 DeepSeek-Coder를 사용하여 다양한 양자화 기술을 적용하였습니다. 특히 이 연구에서는 Additive Quantization with Learned Multi-Codebooks (AQLM)와 같은 최신 기술을 도입하였으며, 다양한 교정 데이터셋(calibration datasets)을 활용하여 양자화 과정에서 성능 저하를 최소화하였습니다. 실험의 정확성을 위해 MultiPL-E와 McEval 두 가지 벤치마크를 사용하였고, Java와 Python이라는 두 프로그래밍 언어에 대해 총 414개의 구현 문제를 제시하였습니다.
- ***Performance Highlights***: 실험 결과 4비트 양자화를 통해 모델의 메모리 풋프린트를 70%까지 줄이는 동시에 코드 생성 성능을 유지할 수 있었고, 2비트 양자화에서는 성능 개선을 보이긴 했지만 여전히 원본 모델과 유의미한 차이가 발생했습니다. 특히 100B 이상의 파라미터를 가진 더 큰 모델들에서는 2비트 양자화에도 불구하고 성능 저하가 덜한 것을 발견했으며, 이는 향후 대형 모델에서의 과도한 양자화에도 긍정적인 영향을 미칠 수 있음을 시사합니다.

### [WildIFEval: Instruction Following in the Wild](https://arxiv.org/abs/2503.06573)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.06573.png)

Vote: 5

Authors: Liat Ein-Dor, Ariel Gera, Asaf Yehudai, Gili Lior

- ***What's New***: WildIFEval은 다중 제약 조건을 가진 사용자 지시사항을 따르는 능력을 평가하기 위한 대규모 데이터셋입니다. 이 데이터셋은 자연 사용자 프롬프트에서 다양한 제약 조건을 다루며, 실제 사용자와의 상호작용을 통해 수집되었습니다.
- ***Technical Details***: WildIFEval 데이터셋은 LMSYS-Chat-1M 데이터셋에서 추출된 12,000개의 사용자 생성 예제를 포함하며, 각 작업은 개별 제약 조건 세트로 분해되었습니다. 이러한 제약 조건은 8가지 주요 유형으로 분류되어 상세한 평가가 가능합니다. 평가를 위해 WILDIFEVAL은 다양한 LLMs(대규모 언어 모델)를 테스트하여 여러 제약 조건을 따르는 능력을 시험합니다.
- ***Performance Highlights***: WILDIFEVAL 벤치마크는 모든 모델이 제약 조건의 수가 증가함에 따라 성능 저하를 겪는다는 점을 밝혔습니다. 특히, 길이 관련 제약 조건에서는 모든 모델이 상당한 어려움을 겪었습니다. 가장 높은 점수를 받은 모델도 0.65에 그쳤으며, 이는 해당 벤치마크가 최첨단 LLMs에게 도전적인 기준임을 보여줍니다.

### [LocAgent: Graph-Guided LLM Agents for Code Localization](https://arxiv.org/abs/2503.09089)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.09089.png)

Vote: 5

Authors: Gangda Deng, Viktor Prasanna, Xingyao Wang, Xiangru Tang, Zhiwei Jiang, Fang Wu, Jialong Wu, Zhaoling Chen, Arman Cohan

- ***What's New***: LOCAGENT는 코드베이스를 그래프 기반으로 표현하여 코드 로컬라이제이션(Code Localization) 문제를 해결하는 새로운 프레임워크입니다. 이 프레임워크는 코드 구조와 의존성을 포함하는 방향성 이종 그래프를 구축하여 LLM 에이전트가 복잡한 코드베이스를 효율적으로 탐색하고 관련 엔티티를 쉽게 찾을 수 있도록 합니다.
- ***Technical Details***: LOCAGENT는 주어진 코드베이스를 방향성 이종 그래프로 파싱하여 파일, 클래스, 함수와 같은 코드 구조와 그들 간의 의존성(예: import, invoke, inherit)을 캡처합니다. 그래프 기반 인덱싱을 통해 LLM 에이전트가 다중 홉(reasoning) 탐색을 통해 코드와 이슈의 관계를 이해할 수 있습니다. 이를 위해 Qwen-2.5-Coder-Instruct 모델을 세밀하게 조정하여 록알(tfine-tune)하여 사용자는 저렴한 비용으로 SOTA 모델에 준하는 성능을 얻을 수 있습니다.
- ***Performance Highlights***: LOCAGENT는 파일 수준 로컬라이제이션에서 최대 92.7%의 정확도를 달성하며, GitHub 문제 해결 성공률을 12% 향상 시켰습니다(Pass@10). 주목할만한 점은 프레임워크가 전체 API 비용을 86% 절감하면서도 높은 성능을 유지한다는 것입니다.

### [VLog: Video-Language Models by Generative Retrieval of Narration Vocabulary](https://arxiv.org/abs/2503.09402)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.09402.png)

Vote: 4

Authors: Kevin Qinghong Lin, Mike Zheng Shou

- ***What's New***: VLog는 비디오 이해를 위해 내레이션 어휘(Narration Vocabulary)를 생성적으로 검색하는 새로운 접근 방식을 제안합니다. 기존 비디오-언어 모델들이 언어의 하위어(Subword) 어휘를 사용하는 것과 달리, VLog는 비디오 내레이션을 최소 단위로 정의하고 어휘를 구축하여 처리 속도를 크게 향상시킵니다.
- ***Technical Details***: VLog는 GPT-2를 기반으로 구축되었으며, 대규모 비디오 내레이션에서 유도한 계층적 어휘 구조를 통해 비디오 이해를 효율적으로 수행합니다. 내레이션 쌍 인코딩(Narration Pair Encoding) 알고리즘을 사용하여 특정 이벤트를 효율적으로 인덱싱할 수 있으며, 발생하는 새로운 이벤트를 위해 어휘를 확장하는 전략도 포함하고 있습니다.
- ***Performance Highlights***: VLog는 EgoSchema, COIN 및 HiREST와 같은 데이터셋에서 실험을 통해 높은 정확도로 짧고 맥락에 맞는 내레이션을 생성할 수 있음을 입증하였습니다. 또한, 기존 생성 모델 대비 10배 이상의 속도 향상을 보여주며, 실시간 비디오 처리의 가능성을 시사합니다.

### [Cost-Optimal Grouped-Query Attention for Long-Context LLMs](https://arxiv.org/abs/2503.09579)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.09579.png)

Vote: 3

Authors: Xu Han, Zhiyuan Liu, Yingfa Chen, Yutong Wu, Maosong Sun

- ***What's New***: 이 연구는 Long-Context LLMs의 계산 비용과 메모리 비용을 최소화하기 위해 그룹화된 질의 어텐션(Grouped-Query Attention; GQA)을 활용한 방법론을 제시합니다. Attention head의 수를 모델 은닉 차원으로부터 독립시켜 더 유연하게 계산 리소스를 분배할 수 있도록 합니다.
- ***Technical Details***: Long-Context LLMs를 위한 그룹화된 질의 어텐션(GQA) 기반의 Transformer 모델은 Attention head 수를 은닉 차원과 분리하여 모델의 초모수로 사용합니다. 이를 통해 파라미터 기반과 비파라미터 기반 연산(예: KV 캐시)의 비용을 조정합니다. 특히, 긴 문맥을 처리할 때 비파라미터 비용이 크기 때문에, 이러한 비용 관리가 중요합니다.
- ***Performance Highlights***: GQA의 일반적인 구성은 특정 문맥 길이에서 비효율적일 수 있고, 다양한 헤드 구성을 통해 최적의 성능을 달성할 수 있습니다. 예를 들어, 128K 토큰 컨텍스트 길이에서 FLOPs와 메모리 사용량을 절반으로 줄이면서 동일한 손실을 달성할 수 있습니다. 이는 긴 문맥 시나리오에서 효율적인 LLM 개발에 중요한 통찰력을 제공합니다.

### [Self-Taught Self-Correction for Small Language Models](https://arxiv.org/abs/2503.08681)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.08681.png)

Vote: 3

Authors: Irina Nikishina, Chris Biemann, Viktor Moskvoretskii

- ***What's New***: 이 논문은 작은 언어 모델(Small Language Models; SLMs)이 자생적으로 생성한 데이터를 통해 스스로 교정(Self-Correction)할 수 있는 방법을 탐구합니다. Self-Taught Self-Correction(STaSC) 알고리즘을 소개하여 외부 도구나 대형 독점 모델에 의존하지 않고 자가 교정 기능을 강화했습니다.
- ***Technical Details***: STaSC 알고리즘은 STaR(Zelikman et al., 2022)로부터 영감을 받아 자생 데이터를 사용하여 반복적 미세 조정을 통해 자가 교정을 학습합니다. 여러 알고리즘 설계 선택 사항을 포함하여 이니셜 답변 탐색, 교정 필터링 및 반복적 미세 조정에 대한 통제 권한을 제공합니다. 이는 Natural Questions 데이터셋에서의 실험을 통해 입증되었습니다.
- ***Performance Highlights***: 자체 생성 데이터를 사용하여 교정 능력을 학습할 수 있으며, SLMs는 초기 답변의 질도 개선함을 보여줍니다. 예를 들어, Phi3-mini 모델은 교정 후 정확도가 0.384로 증가하였습니다. 실험은 Qwen-2.5-1.5B와 Phi3-Mini 모델을 사용하여 수행되었으며, 오류 누적이 없는 안정적인 향상을 보여주었습니다.

### [Alias-Free Latent Diffusion Models:Improving Fractional Shift Equivariance of Diffusion Latent Space](https://arxiv.org/abs/2503.09419)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.09419.png)

Vote: 3

Authors: Zeqi Xiao, Yifan Zhou, Xingang Pan, Shuai Yang

- ***What's New***: Alias-Free Latent Diffusion Models(AF-LDM)는 안정적인 결과를 생성하는 데 필요한 시프트 대응성(Shift-Equivariance)을 강화시켜, 기존의 잠재 디퓨전 모델(Latent Diffusion Models; LDM)의 불안정성을 해결한 새로운 프레임워크입니다. 이 모델은 영상 편집 및 이미지-이미지 변환과 같은 다양한 애플리케이션에서 높은 일관성을 유지합니다.
- ***Technical Details***: Alias-Free LDM은 두 가지 주요 개선점을 도입합니다. 첫 번째는 연속적인 잠재 표현을 위한 펄시 대역폭 제한 방식을 포함한 새로운 반-에일리어싱 설계와 응용 수업을 결합한 방식입니다. 두 번째는 시프트 불변성을 보장하기 위해, 주파수 및 값 기능들이 고정된 상태에서 입력과 함께 질의가 이동하는 구조를 구현하여 주의 모듈의 시프트 불변성을 확보했으며, 이는 CFA(Cross-Frame Attention)와 유사한 형식을 취하는 주의 기법으로 풀어냅니다.
- ***Performance Highlights***: AF-LDM은 기존의 'Stable Diffusion'과 비교할 때 다양한 애플리케이션에서 지속적으로 더 높은 시프트 대응성을 보여주었으며, 완전히 새로운 방식의 영상 및 이미지 변환 작업에서 신뢰성 있고 일관성 있는 결과를 만들어냅니다. 네트워크의 학습 과정 중 대역 제한을 직접 최적화하여 고주파 정보를 억제함으로써 높은 시프트 대응성을 달성하였습니다.

### [When Large Vision-Language Model Meets Large Remote Sensing Imagery: Coarse-to-Fine Text-Guided Token Pruning](https://arxiv.org/abs/2503.07588)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.07588.png)

Vote: 3

Authors: Yingying Zhang, Xue Yang, Kang Wu, Yansheng Li, Lei Liang, Qi Zhu, Junwei Luo, Jingdong Chen

- ***What's New***: 이 논문은 대형 비전-언어 모델(Large Vision-Language Models; LVLMs)이 초고해상도 원격 감지 영상(Remote Sensing Imagery; RSI)을 효율적으로 처리할 수 있도록 하는 텍스트 기반 토큰 정리(Token Pruning) 방법을 제안합니다. 새로운 벤치마크 LRS-VQA도 제안되어, 27,328 픽셀까지 길이가 늘어날 수 있는 이미지를 포함하여 다양한 질문 유형으로 구성됩니다.
- ***Technical Details***: 프레임워크는 텍스트와 비전 토큰 간의 주의력 매핑을 이용하여 중요한 비전 토큰을 식별하는 Region Focus Module (RFM)과 이를 바탕으로 한 Dynamic Image Pyramid (DIP)를 통합합니다. DIP는 이미지를 여러 해상도의 타일로 분할하며, 이 타일들 중 중요한 것들만 선택하여 세밀한 추론을 진행합니다. 이 과정은 가변적인 이미지 피라미드를 연속적으로 활용하여 원본 해상도로의 반복적 접근이 가능하도록 합니다.
- ***Performance Highlights***: 제안된 방법은 세밀 해상도와 효율성을 모두 충족할 수 있는 접근법으로, 기존의 고해상도 처리 전략보다 뛰어난 성능을 네 가지 데이터셋에서 발휘하였습니다. 특히, LRS-VQA 벤치마크에서 더 높은 결과를 기록하며, 다양한 질문 유형과 처리해야 할 이미지의 크기에서 기존 방법들의 한계를 극복하였습니다.

### [Multi Agent based Medical Assistant for Edge Devices](https://arxiv.org/abs/2503.05397)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.05397.png)

Vote: 2

Authors: Shivam Akhouri, Chinmay Kulkarni, Pragya Sahu, Jagdish Samant, Saswat Meher, Aastik, Sakharam Gawade, Jai Pahal

- ***What's New***: 이 논문에서는 에지 디바이스(Edge Devices)에서 사용자 데이터를 로컬로 처리하여 프라이버시를 보장하고, 다중 에이전트 구조를 활용해 확장성을 확보한 새로운 형태의 헬스케어 보조시스템을 소개합니다. 이는 약속 예약(appointment booking), 건강 모니터링(health monitoring), 약 복용 알림(medication reminders), 일일 건강 보고서(daily health reporting)를 포함한 다양한 헬스케어 기능을 제공합니다.
- ***Technical Details***: 제안된 시스템은 Qwen Code Instruct 2.5 7B 모델을 사용하여 플래너(Planner)와 콜러(Caller) 에이전트가 각각 계획(planning)과 호출(calling) 작업에서 평균 RougeL 점수 85.5와 96.5를 달성했습니다. 시스템 아키텍처는 액션 매니저(Action Manager), 건강 매니저(Health Manager), 메모리 유닛(Memory Unit)으로 구성됩니다. 액션 매니저는 작업 실행을, 건강 매니저는 사용자 건강 모니터링 및 리포트를, 메모리 유닛은 사용자와 관련된 장기 및 단기 정보를 저장하여 상황에 맞는 지원을 제공합니다.
- ***Performance Highlights***: 실험 결과 플래너 에이전트는 평균 RougeL 점수 85.5를, 콜러 에이전트는 96.5를 달성했으며, 호출 기능에서는 항상 적합한 툴을 정확히 예측하는 결과를 보여 주었습니다. 이 시스템은 효율적인 작업 수행을 위해 모델을 LoRA 방식으로 파인튜닝(LoRA fine-tune)하여 에지 디바이스에 적합한 모듈로 설계되었습니다.

### [Multimodal Language Modeling for High-Accuracy Single Cell Transcriptomics Analysis and Generation](https://arxiv.org/abs/2503.09427)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.09427.png)

Vote: 2

Authors: Junfeng Fang, Xiang Wang, Zhiyuan Liu, Yang Zhang, Sihang Li, Yaorui Shi, Jiaqi Yang

- ***What's New***: scMMGPT는 단일 세포 분석을 위한 새로운 멀티모달 프레임워크로, 단일 세포 RNA 서열 데이터(scRNA-seq data)와 텍스트를 연결하여 세포 설명 생성, 텍스트 기반 세포 생성, 세포 유형 주석과 같은 과제를 지원합니다. 이를 통해 세포 PLM(Pre-trained Language Model)과 텍스트 PLM을 교차 모달 투영기로 통합하여 학습하게 됩니다. CELLxGENE 데이터셋의 2천7백만 세포로 사전 훈련되어 단일 세포 분석 작업에서 뛰어난 성능을 보입니다.
- ***Technical Details***: scMMGPT는 scGPT와 Llama-2를 바탕으로 세포와 텍스트 모드를 위한 PLM을 각각 사용하여 세포와 텍스트를 이해하고 생성해냅니다. 교차 모달 투영기(cross-modal projectors)은 세포와 텍스트 PLM 사이에서 정보 공유를 가능하게 하여, 세포-텍스트와 텍스트-세포 번역을 가능하게 합니다. 세포-텍스트 프로젝트는 Q-Former를 통해, 텍스트-세포 프로젝트는 교차 주의(cross-attention) 레이어를 통해 정보를 전환합니다.
- ***Performance Highlights***: 텍스트 기반 pseudo-cell generation에서 scMMGPT는 k-NN 정확도(k-NN accuracy)에서 모든 기준 모델을 능가하며, 다양한 k 값(k=3,5,10,25)을 초월하여 일관된 높은 정확도와 낮은 표준 편차를 보여주었습니다. 세포 유형 주석에서는 Zero-shot 설정에서 Acc@1 49.1%, Acc@5 83.1%의 결과를 기록하며, 사전 훈련 없이도 탁월한 일반화 성능을 입증했습니다. 이러한 결과는 scMMGPT가 사전 훈련된 세포 및 텍스트 데이터의 지식을 통해 새로운 세포 유형에도 강력한 일반화를 제공할 수 있음을 시사합니다.

### [BIMBA: Selective-Scan Compression for Long-Range Video Question Answering](https://arxiv.org/abs/2503.09590)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.09590.png)

Vote: 2

Authors: Gedas Bertasius, Md Mohaiminul Islam, Huiyu Wang, Lorenzo Torresani, Tushar Nagarajan

- ***What's New***: BIMBA 모델은 긴 비디오의 질문응답(Question Answering) 문제를 해결하기 위한 효율적인 솔루션입니다. 이 모델은 선택적 스캔 알고리즘을 통해 고차원 비디오에서 중요한 정보를 선택하고 이를 압축하여 대형 언어 모델(LLM)에서 효율적으로 처리할 수 있는 토큰 시퀀스로 변환합니다.
- ***Technical Details***: BIMBA는 비디오의 spatiotemporal 토큰 시퀀스를 1차원 이상으로 압축하여 긴 범위 의존성을 유지합니다. 선택적 스캔 구조적 상태 공간 모델(SSM)을 사용하여 중요한 정보를 선택적으로 전파하며 중복된 데이터를 걸러냅니다. 또한, 영상 쿼리와 spatiotemporal 토큰을 일정한 간격으로 교차 배치하여 토큰의 상호작용을 균일하게 하며, 2D/3D spatiotemporal 구조를 더 효과적으로 캡처하기 위해 양방향 선택적 스캔 메커니즘을 활용합니다.
- ***Performance Highlights***: BIMBA는 다양한 긴 형식 비디오 QA 벤치마크에서 최첨단 정확도를 달성했습니다. 예를 들어, PerceptionTest, NExT-QA, EgoSchema, VNBench, LongVideoBench, Video-MME 등의 데이터셋에서 뛰어난 성능을 보이며, 메타 및 UNC Chapel Hill과의 협업을 통해 개발된 모델입니다.

### [MoC: Mixtures of Text Chunking Learners for Retrieval-Augmented Generation System](https://arxiv.org/abs/2503.09600)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.09600.png)

Vote: 1

Authors: Hanyu Wang, Zhiyu Li, Zhiyuan Ji, Simin Niu, Jihao Zhao, Zhaoxin Fan, Feiyu Xiong, Bo Tang

- ***What's New***: 이 논문에서는 Retrieval-Augmented Generation (RAG) 시스템에서 간과되었던 텍스트 청킹(Text Chunking)의 중요성을 강조하며, 이를 개선하기 위한 새로운 평가 메트릭인 Boundary Clarity와 Chunk Stickiness를 제안합니다. 또한, LLM 기반의 청킹의 필요성을 이론적으로 뒷받침하고, 자원 효율성을 고려한 다중 그라뉼러리티 인식 청킹 프레임워크인 MoC를 소개하고 있습니다.
- ***Technical Details***: MoC 프레임워크는 다중 그라뉼러리티 인식 라우터와 메타 청커(meta-chunker), 그리고 후처리 알고리즘으로 구성됩니다. 이 시스템은 각각의 텍스트 조각에 가장 적합한 청커를 선택하여 작업을 수행하도록 라우터가 동적으로 결정하며, 적은 연산 자원 소모로도 높은 정확도를 유지할 수 있도록 설계되었습니다. 메타 청커는 텍스트 청킹 규칙 목록을 생성하여 원본 텍스트에서 청크를 추출합니다. 오차 수정 알고리즘을 통해 생성된 청킹 규칙과 원문을 비교하여 정확성을 보장합니다.
- ***Performance Highlights***: 제안한 메트릭과 MoC 프레임워크는 4개의 QA 데이터셋에 대한 다각적 실험을 통해 그 효과성을 입증하였으며, 특히 Boundary Clarity와 Chunk Stickiness는 RAG 시스템에서 탁월한 성능을 발휘하는 것으로 나타났습니다. MoC는 기존의 청킹 방법보다 성능이 우수하였고, 시스템의 계산 효율성과 정확성의 균형을 잘 유지하였습니다.

### [PlainQAFact: Automatic Factuality Evaluation Metric for Biomedical Plain Language Summaries Generation](https://arxiv.org/abs/2503.08890)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.08890.png)

Vote: 1

Authors: Yue Guo, Zhiwen You

- ***What's New***: PLAINQAFACT는 Plain Language Summaries(PLS)의 사실성 평가를 위한 새로운 프레임워크입니다. 이 프레임워크는 PLS의 사실성을 자동으로 평가하며, 특히 기존의 평가 메트릭과 달리 설명형 정보(elaborative explanations)를 평가하는 데 초점을 맞추고 있습니다.
- ***Technical Details***: PLAINQAFACT는 두 단계의 QA 기반 사실성 평가 프레임워크로, MEDCPT 검색(도메인 지식 검색)을 통해 외부 정보를 활용합니다. 이 프레임워크는 먼저 문장 유형을 분류하고, 실제 필요에 따라 도메인 지식을 검색하며, 그 후 QA 기반 메트릭을 사용하여 문장 수준의 평가 점수를 종합하여 최종적인 사실성 점수를 산출합니다.
- ***Performance Highlights***: PLAINQAFACT는 기존 메트릭들이 설명형 정보에 대해 낮은 평가 성능을 보이는 반면, 최신 성능을 기록하여 사실성 평가에서 뛰어난 성능을 발휘합니다. 특히, PLS의 전체 평가에서 최상의 성능을 보여, 설명형 자료의 사실성 평가에 있어 탁월한 성과를 보였습니다.

### [Monte Carlo Diffusion for Generalizable Learning-Based RANSAC](https://arxiv.org/abs/2503.09410)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.09410.png)

Vote: 0

Authors: Wei Ke, Chen Zhao, Jiale Wang, Tong Zhang

- ***What's New***: 이 논문에서는 Monte Carlo diffusion 기법을 도입하여 기존 학습 기반 RANSAC의 일반화 능력을 강화합니다. 이 방법은 특정 데이터 분포에 의존하지 않고 다양한 잡음 패턴을 시뮬레이션하여 훈련 과정을 개선합니다. Monte Carlo 샘플링을 도입함으로써 다단계에서 다양한 랜덤성을 주입하여 데이터의 다양성과 견고성을 높였습니다.
- ***Technical Details***: Monte Carlo diffusion은 그라운드 트루스 데이터에 점진적으로 잡음을 주입하여 다양한 잡음 분포를 시뮬레이션합니다. 이 방법은 매칭된 픽셀 간 대응에 Monte Carlo 샘플링을 통합하여 추론 단계에서 다양한 데이터 분포를 근사합니다. 다단계 랜덤화를 통해 세 가지 하이퍼파라미터(timestep, diffusion ratio, noise scale)를 무작위로 샘플링함으로써 데이터 다양성을 보장합니다.
- ***Performance Highlights***: ScanNet 및 MegaDepth 데이터셋에서 Monte Carlo diffusion을 기반으로 훈련된 학습 기반 RANSAC은 기존 모델에 비해 일반화 능력에서 상당한 향상을 보였습니다. 구체적으로, ScanNet 데이터셋에서 AUC @20° 지표가 다른 매처에서 훈련된 모델에 비해 평균적으로 12% 이상 증가했으며, MegaDepth에서도 유사한 추세를 보였습니다. 이러한 결과는 실제 응용에서 다양한 알고리즘으로 생성된 데이터에 대한 RANSAC의 적용성을 강화합니다.

### [Search-R1: Training LLMs to Reason and Leverage Search Engines with Reinforcement Learning](https://arxiv.org/abs/2503.09516)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.09516.png)

Vote: 0

Authors: Zhenrui Yue, Hansi Zeng, Bowen Jin, Hamed Zamani, Dong Wang, Jiawei Han

- ***What's New***: SEARCH-R1은 대형 언어 모델(LLM)들이 실시간 검색 엔진 상호작용을 통해 자율적으로 이유하며 여러 검색 쿼리를 생성할 수 있도록 하는 강화 학습(이하 RL) 프레임워크입니다. 기존의 검색 증강 생성(RAG) 접근법이나 도구 사용 방식보다 다단계 검색에서 더 큰 유연성을 제공합니다.
- ***Technical Details***: SEARCH-R1은 검색엔진을 환경의 일부로 모델링하여 LLM과의 인터리브드 형태로 작동하도록 설계되었습니다. 검색 호출은 <search> 및 </search> 토큰으로 명시적으로 트리거되며, 검색된 콘텐츠는 <information> 및 </information> 형식으로 포함됩니다. 강화 학습 알고리즘 PPO(Proximal Policy Optimization)와 GRPO(Group Relative Policy Optimization)를 통해 안정적인 최적화를 달성하고, 간단한 결과 기반 보상 함수를 채택하여 트레이닝합니다. 네이버 웨이터 데이터셋을 비롯한 7개의 질문-응답 데이터셋에 대한 실험을 거쳤습니다.
- ***Performance Highlights***: SEARCH-R1은 최신 기술을 활용한 기준 모델 대비 Qwen2.5-7B에서 26%, Qwen2.5-3B에서 21%, LLaMA3.2-3B에서 10%의 성능 향상을 보여줍니다. 이는 특히 검색 증강을 통한 LLM의 복잡한 이유 해결 능력을 검증하는 데 있어서, 강화 학습(RL) 트레이닝을 통한 최적화가 효과적임을 시사합니다.

### [Understanding and Mitigating Distribution Shifts For Machine Learning Force Fields](https://arxiv.org/abs/2503.08674)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.08674.png)

Vote: 0

Authors: Tobias Kreiman, Aditi S. Krishnapriyan

- ***What's New***: 이번 연구는 머신러닝 포스 필드(MLFF; Machine Learning Force Fields)가 훈련 데이터의 분포를 넘어 얼마나 잘 일반화할 수 있는지를 이해하고, 이를 개선하기 위한 두 가지 새로운 방법을 제안합니다. 이 방법들은 비싼 reference label 없이 최소한의 계산 비용으로 테스트 시점에서 모델을 개선하는 것을 목표로 합니다.
- ***Technical Details***: 연구진은 케미칼 데이터셋 상의 진단 실험을 통해 MLFF에서 공통적으로 발생하는 분포 변화 문제를 파악하고, 두 가지 전략을 제안합니다. 첫 번째 전략은 spectral graph theory를 기반으로 하여 테스트 그래프의 구조를 훈련 시 사용된 그래프와 일치시키는 것이고, 두 번째는 저렴한 물리적 선험적 정보(cheap physical prior)를 이용해 테스트 시점에서 out-of-distribution 시스템의 표현을 개선하는 것입니다.
- ***Performance Highlights***: 실험 결과, 새로운 방법들로 인해 MLFF의 out-of-distribution 오류가 크게 줄어들었습니다. 이 연구는 현재 MLFF들이 다채로운 화학적 공간들을 모델링할 수 있는 잠재력을 갖고 있지만, 효과적으로 일반화하도록 훈련되지 않았음을 시사합니다. 제공된 방법들은 기존의 데이터와 아키텍처 개선과 함께 사용될 수 있는 강력한 일반화 도구가 될 가능성을 보여줍니다.

### [PhysicsGen: Can Generative Models Learn from Images to Predict Complex Physical Relations?](https://arxiv.org/abs/2503.05333)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.05333.png)

Vote: 0

Authors: Jan Vaillant, Janis Keuper, Martin Spitznagel

- ***What's New***: PhysicsGen은 이미지 쌍을 통해 복잡한 물리적 관계를 예측하는 능력을 가진 생성 모델(GANs, Diffusion models)을 평가하기 위한 새로운 벤치마크를 소개합니다. 이 벤치마크에서는 3가지 물리 시뮬레이션 과제를 사용하며, 기존의 미분 방정식 기반 시뮬레이션을 대체할 수 있는 가능성을 조사합니다.
- ***Technical Details***: PhysicsGen 벤치마크는 세 가지 주요 물리 시뮬레이션 문제를 기반으로 데이터세트를 제공합니다: 반복적인 파형 전파, 폐쇄 형식 렌즈 왜곡, 움직임 역학의 시간 연속 예측입니다. 각 문제는 100,000개의 이미지 쌍으로 구성되어 있으며, 다양한 생성적 이미지 변환 모델들을 평가합니다. 모델은 Generative Adversarial Networks(Pix2Pix, VAE), Convolutional Autoencoders(ConvAEs), Denoising Diffusion Probabilistic Models(DDPMs) 등의 구조를 사용하여 훈련됩니다.
- ***Performance Highlights***: Pix2Pix 및 UNet 모델은 간단한 1차 시뮬레이션 작업에서 높은 정확도를 보였으며, 복잡한 반사 및 굴절 관련 작업에서는 성능 한계를 드러냈습니다. 생성 모델들은 전통적인 시뮬레이션에 비해 최대 20,000배의 속도 향상을 보여주었지만, 물리적 정확성 측면에서 고차 방정식 작업을 예측하는 데 한계를 보였습니다.

