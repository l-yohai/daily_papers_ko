## Daily Papers (2025-04-22)

### [Learning to Reason under Off-Policy Guidance](https://arxiv.org/abs/2504.14945)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2504.14945.png)

Vote: 56

Authors: Zhi Wang, Xiaoye Qu, Yafu Li, Zican Hu, Ganqu Cui, Yu Cheng, Yue Zhang, Jianhao Yan

- ***What's New***: LUFFY는 전통적인 '제로 정책 강화 학습(zero-RL)'에 오프 폴리시 가이던스(off-policy guidance)를 통합한 프레임워크로, 고품질 외부 모델의 추론 데이터를 활용하여 모형의 탐색 및 학습 효과를 향상시킵니다. 이는 모형이 자체적으로 발견할 수 없는 새로운 해결책을 발견할 수 있게 합니다.
- ***Technical Details***: LUFFY는 오프 폴리시와 온 폴리시의 롤아웃을 결합하여 학습을 진행함으로써, 단순 모방에 그치지 않고 자체적으로 새로운 해결책을 탐색할 수 있도록 합니다. 정책 형성(policy shaping)은 '정규화된 중요도 샘플링(regularized importance sampling)'을 통해 습득 및 탐색 균형을 유지하게 합니다.
- ***Performance Highlights***: AIME, AMC, MATH-500 등 6개의 주요 수학 벤치마크에서 LUFFY는 평균 49.6점의 성적을 기록하여 기존 제로-RL 방법에 비해 평균 +7.0 점 이상의 향상을 보였습니다. 특히, 새로운 AIME 25 테스트 세트에서 +8.2 점의 성능 향상을 나타내어, 오프 폴리시 학습을 통한 일반화 효과를 명확히 보여주었습니다.

### [Eagle 2.5: Boosting Long-Context Post-Training for Frontier Vision-Language Models](https://arxiv.org/abs/2504.15271)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2504.15271.png)

Vote: 47

Authors: Zhiding Yu, Bryan Catanzaro, Tong Lu, Max Ehrlich, Limin Wang, Tuomas Rintamaki, De-An Huang, Shihao Wang, Guo Chen, Lidong Lu, Wonmin Byeon, Jan Kautz, Yicheng Liu, Jindong Jiang, Zhiqi Li, Tyler Poon, Andrew Tao, Guilin Liu, Matthieu Le

- ***What's New***: Eagle 2.5는 최첨단 비전-언어 모델(Vision-Language Models; VLMs)을 위해 긴 컨텍스트 학습을 강화하는 새로운 모델 패밀리입니다. Eagle 2.5는 긴 비디오 이해와 고해상도 이미지 이해를 아우르는 범용 프레임워크를 도입하며, Automatic Degrade Sampling과 Image Area Preservation 등의 기술을 통해 컨텍스트의 무결성과 시각적 세부 사항을 보존합니다.
- ***Technical Details***: Eagle 2.5의 훈련 프레임워크는 information-first sampling과 progressive training을 포함하여, 지속적인 입력 길이 증가와 함께 성능 향상을 보입니다. Eagle-Video-110K라는 새로운 데이터셋을 제안하여 이야기 수준과 클립 수준의 주석을 통합하여 긴 비디오 이해를 원활하게 합니다. Image Area Preservation 기술은 원본 이미지 영역을 유지하며, Automatic Degradation Sampling은 시각적 및 텍스트 입력을 균형 있게 최적화합니다.
- ***Performance Highlights***: Eagle 2.5-8B 모델은 Video-MME 벤치마크에서 512 입력 프레임으로 72.4%의 점수를 기록하여, GPT-4o와 같은 상업용 최고 모델과 동일한 성능을 보입니다. 다양한 비디오 이해 벤치마크에서 지속적인 개선을 보이며, 특히 긴 비디오와 이미지 이해에서 탁월함을 입증했습니다. GPT-4o와 같은 더 큰 프론티어 모델에 비해 더 적은 파라미터로 비디오 이해 성능을 유지합니다.

### [FlowReasoner: Reinforcing Query-Level Meta-Agents](https://arxiv.org/abs/2504.15257)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2504.15257.png)

Vote: 35

Authors: Yufei He, Chao Du, Longxu Dou, Zhijie Deng, Tianyu Pang, Bryan Hooi, Min Lin, Yue Liu, Hongcheng Gao

- ***What's New***: FlowReasoner는 사용자 쿼리당 멀티 에이전트 시스템(query-level multi-agent systems)을 자동으로 설계하는 새로운 쿼리 레벨 메타 에이전트(meta-agent)입니다. 이 시스템은 외부 수행 피드백을 통해 메타 에이전트를 강화하며, 각 사용자 쿼리에 대해 개인화된 멀티 에이전트 시스템을 생성합니다.
- ***Technical Details***: FlowReasoner는 DeepSeek R1을 활용해 기본적인 멀티 에이전트 시스템 생성 능력을 제공한 후, RL(강화학습; reinforcement learning)을 통해 외부 수행 피드백을 이용해 이를 더욱 강화합니다. 다목적 보상(multi-purpose reward)을 설계하여 성능, 복잡성, 효율성을 기준으로 훈련을 지도합니다. 이러한 방식을 통해, FlowReasoner는 사용자의 쿼리마다 새로운 시스템을 생성하고 평가할 수 있습니다.
- ***Performance Highlights***: FlowReasoner는 세 가지 벤치마크에서 최첨단 메소드 대비 10.52% 높은 정확도를 기록하며 우수성을 입증하였습니다. 특히, 코드 생성 정확성에서 o1-mini 모델을 10% 이상 능가하는 성능을 보였습니다.

### [ToolRL: Reward is All Tool Learning Needs](https://arxiv.org/abs/2504.13958)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2504.13958.png)

Vote: 32

Authors: Cheng Qian, Heng Ji, Xiusi Chen, Gokhan Tur, Hongru Wang, Dilek Hakkani-Tür, Emre Can Acikgoz, Qi He

- ***What's New***: ToolRL은 도구 학습에서 보상을 중심으로 한 최초의 포괄적 연구입니다. 이는 강화 학습(Reinforcement Learning; RL) 패러다임을 활용해 도구 선택 및 응용 과제에서 LLMs를 훈련시키는데, 보상 설계를 중점적으로 연구한 최초의 시도입니다.
- ***Technical Details***: ToolRL에서는 Group Relative Policy Optimization(GRPO) 알고리즘을 사용하여 LLMs를 훈련시킵니다. 우리는 도구 사용 작업에 대한 보상 설계에 대해 다양한 전략을 체계적으로 탐구하며, 보상 유형, 스케일, 세분화, 그리고 시간적 변화에 대해 분석합니다.
- ***Performance Highlights***: 우리의 접근 방식은 다양한 벤치마크에서 LLMs의 도구 사용 성능을 크게 향상시켰으며, 기존의 SFT(Supervised Fine-Tuning) 모델에 비해 15% 이상의 성능 향상을 보였습니다. 또한, GRPO Cold Start는 포맷 및 정확성 보상 곡선에서 빠른 증가를 보여주며, 훈련 동안 최고의 성능을 달성했습니다.

### [X-Teaming: Multi-Turn Jailbreaks and Defenses with Adaptive Multi-Agents](https://arxiv.org/abs/2504.13203)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2504.13203.png)

Vote: 24

Authors: Yejin Choi, Kai-Wei Chang, Salman Rahman, Saadia Gabriel, Md Rizwan Parvez, Liwei Jiang, Genglin Liu, Sheriff Issaka, Hamid Palangi, James Shiffer

- ***What's New***: 이 논문은 X-Teaming이라 불리는 적응형 멀티에이전트 프레임워크를 소개하며, 멀티턴 대화에서 발생할 수 있는 해로운 의도를 효과적으로 탐지하고 이에 대응하는 방법론을 제안합니다. X-Teaming은 최신 언어 모델에 대한 멀티턴 'jailbreak' 공격 시나리오를 생성하여, 최대 98.1%의 성공률을 기록하였습니다.
- ***Technical Details***: X-Teaming은 협력적인 멀티에이전트 시스템을 통해 사람이 수행하는 적팀 전략을 모방하여 공격 계획(Planner), 공격 실행(Attacker), 검증(Verifier), 프롬프트 최적화(Prompt Optimizer)로 구성됩니다. 이를 통해 공격 경로를 생성하고, 해당 경로를 통해 대화형 AI 시스템의 취약점을 체계적으로 발견할 수 있습니다.
- ***Performance Highlights***: X-Teaming은 대표적인 상용과 오픈소스 모델을 대상으로 ASR(Attack Success Rate) 98.1%를 달성하며, 기존의 멀티턴 공격 방법보다 훨씬 높은 성능을 보였습니다. 특히, Claude 3.7 Sonnet 모델에 대해서는 96.2%의 성공률을 기록하며, 포괄적이고 공격적인 대화 시나리오에서 높은 다양성을 보여줍니다.

### [SphereDiff: Tuning-free Omnidirectional Panoramic Image and Video Generation via Spherical Latent Representation](https://arxiv.org/abs/2504.14396)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2504.14396.png)

Vote: 22

Authors: Sungwon Hwang, Minho Park, Taewoong Kang, Jooyeol Yun, Jaegul Choo

- ***What's New***: SphereDiff는 새로운 스페어(hyperrealistic) 라운드 시각적 표현을 통해, 튜닝 없이도 최첨단 확산 모델을 활용하여 360도 파노라마 이미지 및 비디오를 매끄럽게 생성할 수 있는 혁신적인 접근 방식을 제공합니다. 이를 통해 기존의 ERP 기반 기법에서 발생했던 대규모 왜곡 문제를 완화하고, AR/VR 애플리케이션을 위한 고품질의 파노라마 콘텐츠 생성을 가능하게 했습니다.
- ***Technical Details***: SphereDiff는 모든 시점을 균일하게 다룰 수 있는 스페리컬 잠재 표현(Spherical Latent Representation)을 정의합니다. 이를 통해 ERP의 본래 문제를 해결하고자 새로운 스페리컬 서브샘플링 방법을 제안했습니다. 또한, 왜곡 인식 가중 평균 기법(Distortion-aware Weighted Averaging)을 도입하여 투명성을 유지하면서 투영 과정에서 발생할 수 있는 잠재적인 왜곡을 개선하고자 했습니다.
- ***Performance Highlights***: SphereDiff는 시각적 품질 및 왜곡 내성 면에서 기존 방법들을 크게 능가하는 성과를 보였습니다. 특히, ERP 기반 기법에서 발생하는 폴 근처의 인위적 경계 및 왜곡 없이 연속적인 파노라마 영상 생성이 가능했습니다. 다양한 질적 평가 결과는 SphereDiff의 우수한 성능을 뒷받침합니다.

### [OTC: Optimal Tool Calls via Reinforcement Learning](https://arxiv.org/abs/2504.14870)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2504.14870.png)

Vote: 21

Authors: Cheng Qian, Shijue Huang, Heng Ji, Bowen Jin, Xiusi Chen, Mengdi Wang, Jiahao Qiu, Hongru Wang, Wanjun Zhong, Kam-Fai Wong

- ***What's New***: OTC (Optimal Tool Calls)는 강화 학습(Reinforcement Learning; RL)을 통해 대형 언어 모델(Large Language Models; LLMs)에서의 도구 사용 최적화를 목표로 하는 간단하면서도 효과적인 RL 기반 프레임워크입니다. 이는 외부 도구 호출 빈도를 줄여 비용 절감과 효율성을 높이는 방향으로 모델을 훈련시킵니다.
- ***Technical Details***: OTC는 Proximal Policy Optimization (PPO)과 Group Relative Preference Optimization (GRPO)을 기반으로 한 OTC-PPO와 OTC-GRPO라는 두 가지 변형을 통해 구현됩니다. 도구 통합 보상이 도구 사용의 효율성을 평가하여 목표 정답을 도출하는 데 필요한 최소한의 도구 사용을 권장합니다. 또한 웹 검색과 코드 실행 두 가지 도구 모달리티에서 이 프레임워크를 검증했습니다.
- ***Performance Highlights***: OTC 접근 방식은 도구 호출을 최대 73.1% 감축하고 도구 생산성을 최대 229.4% 향상시키면서 기존 성능을 유지하며, 이에 따라 도구 사용의 효율성과 정확성을 동시에 증진하는 데 성공했습니다. 다양한 QA 벤치마크에서의 실험 결과도 이를 뒷받침하고 있습니다.

### [UFO2: The Desktop AgentOS](https://arxiv.org/abs/2504.14603)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2504.14603.png)

Vote: 21

Authors: Chao Du, Jian Mu, Saravan Rajmohan, Liqun Li, Lu Wang, Dongmei Zhang, Pu Zhao, Fangkai Yang, Jiaxu Qian, Yu Kang, Si Qin, Jian-Guang Lou, Chiming Ni, Rujia Wang, Qingwei Lin, He Huang, Zhao Jiang, Chaoyun Zhang, Suzhen Zheng, Minghua Ma, Shilin He

- ***What's New***: UFO2는 Windows 데스크탑용 새로운 AgentOS로, 기존의 컴퓨터 사용 에이전트(CUAs)를 시스템 수준의 자동화 솔루션으로 업그레이드합니다. 중앙 집중식 HostAgent와 특정 애플리케이션에 맞춘 AppAgent를 결합하여 강력한 태스크 실행과 함께 모듈성과 확장성을 갖춘 아키텍처를 제공합니다.
- ***Technical Details***: UFO2는 Windows UI Automation(UIA)과 비전 기반 파싱을 결합한 하이브리드 제어 감지 파이프라인을 통해 다양한 인터페이스 스타일을 지원하며, 추측적 다중 액션 계획을 통해 실행 효율성을 높입니다. 이를 통해 AppAgent는 GUI 액션과 애플리케이션 고유 API 호출을 유연하게 조합하여 작업을 실행할 수 있습니다. 또한, Picture-in-Picture(PiP) 인터페이스를 사용하여 가상 데스크탑에서 에이전트와 사용자가 동시에 작업할 수 있도록 지원합니다.
- ***Performance Highlights***: UFO2는 20개 이상의 실세계 Windows 애플리케이션에서 평가되어 기존 CUAs 대비 성공률과 실행 정확도가 크게 개선되었으며, 깊은 OS 통합이 확장 가능한 신뢰성 있는 데스크탑 자동화를 가능하게 합니다. 특히, Windows OS와 애플리케이션 API와의 깊은 통합을 통해 실행 효율성과 신뢰성을 높이고 사용자와의 충돌을 최소화하면서 동시에 작업을 자동화할 수 있습니다.

### [StyleMe3D: Stylization with Disentangled Priors by Multiple Encoders on 3D Gaussians](https://arxiv.org/abs/2504.15281)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2504.15281.png)

Vote: 20

Authors: Wei Cheng, Ming Li, Yaoqi Hu, Xianfang Zeng, Gang Yu, Cailin Zhuang, Xuanyang Zhang, Shengqi Liu, Yiying Yang, Jiacheng Bao

- **What's New**: StyleMe3D는 3D 장면의 예술적 스타일화(stylization)를 가능하게 하는 새로운 프레임워크로, 다양한 구성 요소를 통해 3D Gaussian Splatting(3D GS)의 스타일 전이를 실현합니다. 이를 통해 게임, 가상 세계, 디지털 아트 등의 응용 분야에서 활용이 가능합니다.
- **Technical Details**: StyleMe3D는 네 가지 주된 기술 요소인 Dynamic Style Score Distillation(DSSD), Simultaneously Optimized Scale(SOS), Contrastive Style Descriptor(CSD), 그리고 3D Gaussian Quality Assessment(3DG-QA)을 도입하여 스타일 전이의 품질을 높입니다. Stable Diffusion의 잠재 공간을 활용하여 DSSD가 3D 콘텐츠와 스타일 패턴의 의미적 정렬을 동적으로 수행하고, CSD는 대조 학습을 통해 스타일과 콘텐츠를 구분하여 지역적, 콘텐츠 인식 스타일화를 가능하게 합니다. 3DG-QA는 인간 평가 데이터를 바탕으로 훈련된 미학적 기준을 사용하여 시각적 하모니를 개선합니다.
- **Performance Highlights**: StyleMe3D는 NeRF synthetic dataset과 tandt db dataset에서 평가되었으며, 기존 방법보다 뛰어난 세부 사항 보존과 스타일 일관성을 보여주었습니다. 실험 결과는 다양한 객체와 장면에서 뛰어난 스타일 일관성과 세부 사항 보존을 입증하였습니다.

### [EasyEdit2: An Easy-to-use Steering Framework for Editing Large Language Models](https://arxiv.org/abs/2504.15133)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2504.15133.png)

Vote: 15

Authors: Mengru Wang, Ziwen Xu, Huajun Chen, Shuxun Wang, Kewei Xu, Yunzhi Yao, Haoming Xu, Xinle Deng, Ningyu Zhang, Guozhou Zheng

- ***What's New***: EasyEdit2는 대형 언어 모델(Large Language Models; LLMs)을 편집할 수 있는 새로운 플러그 앤 플레이 조정 프레임워크로서, 테스트 시점에서 모델의 대응을 안전성, 감정, 성격, 추론 패턴, 사실성, 언어적 특징 등 다양한 측면에서 유연하게 조정할 수 있게 합니다. 사용자는 기술 지식이 없어도 단 한 가지 예시만으로 모델의 응답을 조정할 수 있어 접근성과 효율성 측면에서 큰 장점이 있습니다.
- ***Technical Details***: EasyEdit2는 조정 벡터 생성기(Steering Vector Generator)와 조정 벡터 적용기(Steering Vector Applier)라는 두 가지 핵심 모듈로 구성되어 있으며, 이를 통해 모델의 매개변수를 수정하지 않고도 행동을 조정할 수 있습니다. 또한, 조정 벡터 라이브러리가 있어 사용자가 기존 벡터를 재사용할 수 있도록 지원하며, 사용자 정의 시나리오에 맞추어 평가할 수 있는 다양한 방법을 제공합니다.
- ***Performance Highlights***: EasyEdit2는 대형 언어 모델의 행동 조정에 있어 CAA, LM-Steer, STA, PromptAuto 등의 다양한 방법을 통합하여 강력한 성능을 보이며, 안전성 방어율(Defense Rate) 및 감정 긍정률(Positive Rate) 측면에서 기본값을 뛰어넘는 결과를 제공합니다. 특히 CAA와 STA는 높은 방어율과 감정 점수를 기록하며 그 효과를 입증하였습니다.

### [THOUGHTTERMINATOR: Benchmarking, Calibrating, and Mitigating Overthinking in Reasoning Models](https://arxiv.org/abs/2504.13367)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2504.13367.png)

Vote: 14

Authors: Michael Saxon, Xiao Pu, Wenyue Hua, William Yang Wang

- ***What's New***: THOUGHTTERMINATOR는 추론 모델(Reasoning Models)의 과도한 사고(Overthinking)를 완화하기 위한 새로운 훈련 없이도 사용할 수 있는 블랙 박스 디코딩 방법입니다. 문제 난이도와 최적의 토큰 사용량 간의 관계를 칼리브레이션하여 효율적인 토큰 사용을 보장합니다. 또한, 매우 쉬운 문제에 대한 과도한 사고를 평가하기 위해 DUMB500이라는 새로운 데이터셋이 출시되었습니다.
- ***Technical Details***: 이 연구에서는 여러 추론 데이터셋에 걸쳐 문제 난이도와 토큰 사용량 간의 관계를 분석합니다. 또한, DUMB500이라는 쉬운 수학, 추론, 코드, 작업 문제들로 구성된 데이터셋을 도입하여 추론 모델의 과도한 사고를 평가합니다. THOUGHTTERMINATOR는 생성 과정에서 미리 설정된 간격에 따라 간섭 메시지를 추가하여 남은 토큰을 모델에게 알리고, 시간이 초과되면 최종 답변을 생성하도록 강제합니다.
- ***Performance Highlights***: THOUGHTTERMINATOR를 사용한 모델은 대부분의 데이터셋에서 과도한 사고 점수가 크게 감소했으며, 이는 동일하거나 더 나은 Pass@10 성능을 보였습니다. 결과적으로 글로벌로 과도한 사고 점수가 급격히 감소하고 정확도가 향상되었습니다. 토큰 사용 예산이 LLM에 의해 직접 정의되므로 THOUGHTTERMINATOR는 추론 모델의 토큰 효율성을 크게 향상시키는 간단하고 효과적인 도구입니다.

### [Seeing from Another Perspective: Evaluating Multi-View Understanding in MLLMs](https://arxiv.org/abs/2504.15280)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2504.15280.png)

Vote: 13

Authors: Chenyu Wang, Rouyu Wang, Ta-Ying Cheng, Chun-Hsiao Yeh, Shengbang Tong, Tianzhe Chu, Yubei Chen, Yi Ma, Shenghua Gao, Yuexiang Zhai

- ***What's New***: 이 논문에서는 멀티모달 대형 언어 모델(Multi-Modal Large Language Models, MLLMs)의 다중 뷰 이해 능력을 평가하기 위해 All-Angles Bench라는 벤치마크를 소개합니다. 90가지의 다양한 실제 장면에서 2,100개 이상의 질문-답변 쌍을 통해 다중 뷰 장면 추론의 도전 과제를 포괄적으로 평가합니다.
- ***Technical Details***: All-Angles Bench는 다중 뷰 장면에 대한 MLLMs의 기하학적 이해 및 시점을 일관되게 정렬하는 능력을 평가하는 여섯 가지 과제(카운팅, 속성 식별, 상대적 거리, 상대적 방향, 객체 조작, 카메라 포즈 추정)로 구성됩니다. 실험에서는 Gemini-2.0-Flash, Claude-3.7-Sonnet, GPT-4o를 포함한 27개의 대표적인 MLLMs가 인간 평가자와 비교됩니다.
- ***Performance Highlights***: 실험 결과, 인간과 현재의 MLLMs 사이에 상당한 성능 차이가 존재합니다. 특히, 기하학적 일관성과 크로스 뷰 대응에서 MLLMs의 성능은 인간 수준에 크게 미치지 못했습니다. 일부 오픈소스 모델, 예를 들어 Ovis2-34B 및 Qwen2.5-VL-72B는 특정 방향 민감 작업에서 상용 모델을 능가하기도 했습니다.

### [LeetCodeDataset: A Temporal Dataset for Robust Evaluation and Efficient Training of Code LLMs](https://arxiv.org/abs/2504.14655)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2504.14655.png)

Vote: 13

Authors: Wei Shen, Xiaolong Xu, Huifeng Sun, Yan Wang, Siyue Wu, Jian Hu, Jason Klein Liu, Yunhui Xia

- ***What's New***: LeetCodeDataset는 코딩 LLMs의 평가와 훈련을 위한 고품질 벤치마크로, LeetCode의 다양한 Python 문제를 포함하고 있습니다. 이 데이터셋은 풍부한 메타데이터와 100개 이상의 테스트 케이스를 제공하며, 시간에 따라 pre/post July 2024로 나누어 데이터 누출을 방지하고 효율적인 SFT(Supervised Fine-Tuning)를 지원합니다.
- ***Technical Details***: LeetCodeDataset는 LeetCode의 대략 3,115개의 Python 문제를 커버하며 각 문제는 난이도, 출시일, 주제 태그 등의 메타데이터로 주석이 달려 있습니다. 문제는 100개 이상의 다양한 테스트 케이스로 보완되어 있으며, 내장된 평가 도구는 빠르고 신뢰할 수 있는 평가를 보장합니다. 또한, 문제는 출시 날짜에 따라 시간 기반으로 나누어져 모델 훈련 및 평가에 사용됩니다.
- ***Performance Highlights***: LeetCodeDataset를 사용한 평가에서는 Reasoning 모델이 Non-Reasoning 모델을 능가했으며, Claude 3.7 Sonnet이 해당 부문에서 최고 성능을 발휘했습니다. 또한 2.6K 샘플로 SFT 훈련된 모델이 110K 예제를 사용한 모델과 유사한 성능을 보이며 높은 훈련 효율성을 보여주었습니다.

### [InfiGUI-R1: Advancing Multimodal GUI Agents from Reactive Actors to Deliberative Reasoners](https://arxiv.org/abs/2504.14239)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2504.14239.png)

Vote: 11

Authors: Yuhang Liu, Xavier Hu, Hongxia Yang, Xiaotian Han, Fei Wu, Congkai Xie, Pengxiang Li, Shengyu Zhang

- ***What's New***: InfiGUI-R1은 다중 모달 GUI 에이전트(Multimodal GUI Agents)를 반응적 행위자(reactive actors)에서 고유한 추론(deliberative reasoners) 능력을 가진 에이전트로 전환시키기 위한 Actor2Reasoner 프레임워크를 소개합니다. 이 프레임워크는 에이전트를 반응적 행위자에서 고의적 추론자로 발전시키기 위한 이론 중심의 2단계 훈련 접근 방식을 사용합니다.
- ***Technical Details***: Actor2Reasoner 프레임워크는 Reasoning Injection과 Deliberation Enhancement라는 두 가지 핵심 단계로 구성되어 있습니다. 첫 번째 단계에서는 Spatial Reasoning Distillation을 통해 GUI 시각-공간 정보를 논리적 추론과 통합하여 행동 생성 이전의 명시적 추론 단계를 지원합니다. 두 번째 단계에서는 강화학습(Reinforcement Learning; RL)을 사용하여 계획 능력과 자가 수정 능력을 향상시키기 위한 Sub-goal Guidance와 Error Recovery Scenarios를 도입합니다.
- ***Performance Highlights***: InfiGUI-R1-3B 모델은 다양한 플랫폼의 크로스 플랫폼 grounding에서 최첨단 성능을 달성했으며, ScreenSpot에서 평균 87.5% 정확도를 기록했습니다. 또한 AndroidControl-High에서 71.1%의 성공률을 보여, 비슷한 파라미터 수를 가진 기존 모델들을 능가했습니다. 이러한 결과는 InfiGUI-R1-3B의 계획 및 반영 능력 향상을 통한 과제 자동화의 진전을 입증합니다.

### [Uni3C: Unifying Precisely 3D-Enhanced Camera and Human Motion Controls for Video Generation](https://arxiv.org/abs/2504.14899)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2504.14899.png)

Vote: 10

Authors: Yanwei Fu, Fan Wang, Jingyun Liang, Xiangyang Xue, Chaohui Yu, Shikai Li, Jingkai Zhou, Chenjie Cao

- ***What's New***: Uni3C는 비디오 생성에서 카메라 움직임과 인간 모션을 정밀하게 제어할 수 있게 해주는 통합 3D-향상 프레임워크입니다. 이 논문은 Uni3C가 3D 포인트 클라우드(Point Clouds)와 SMPL-X를 통합함으로써 카메라와 인간 모션 제어를 동시에 진행할 수 있게 하는 방법을 제안합니다.
- ***Technical Details***: Uni3C는 PCDController라는 플러그-앤-플레이 방식의 컨트롤 모듈을 통해 이루어집니다. 이는 단안 깊이 추정을 통해 얻은 3D 포인트 클라우드를 사용하여 카메라 제어의 정확성을 확보합니다. PCDController는 동결된(frozen) 비디오 생성 백본과 기조를 함께 사용해도 좋은 성과를 보이며, 다양한 도메인에서 개별적으로 인간 모션 제어와 카메라 제어를 학습할 수 있는 유연성을 제공합니다.
- ***Performance Highlights***: Uni3C는 카메라 제어와 인간 모션 품질 모두에서 경쟁 모델들보다 뛰어난 성능을 보이며, 특히 도전적인 카메라 움직임과 인간 모션을 테스트하기 위한 맞춤형 검증 세트를 수집하여 그 효과성을 입증했습니다.

### [LearnAct: Few-Shot Mobile GUI Agent with a Unified Demonstration Benchmark](https://arxiv.org/abs/2504.13805)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2504.13805.png)

Vote: 8

Authors: Zhiming Chen, Shuai Ren, Hao Wang, Wenchao Meng, Guangyi Liu, Liang Liu, Shibo He, Pengxiang Zhao, Yuxiang Chai

- ***What's New***: LearnAct는 모바일 GUI 에이전트의 성능을 개선하기 위한 시연 기반 학습(유니파이드 데몬스트레이션)을 도입한 새로운 프레임워크입니다. 이는 모바일 애플리케이션의 다양한 시나리오에서 개인화된 작업 완료를 목표로 하며, LearnGUI라는 데이터셋을 처음으로 소개하여 모바일 GUI 에이전트를 위한 데몬스트레이션 기반 학습을 연구할 수 있도록 지원합니다.
- ***Technical Details***: LearnGUI는 2,252개의 오프라인 작업과 101개의 온라인 작업을 포함하며, 시연을 기반으로 지식을 자동으로 추출하여 작업 수행을 향상시키기 위한 복잡한 다중 에이전트 프레임워크, LearnAct를 개발했습니다. 이 프레임워크는 DemoParser를 통한 지식 추출, KnowSeeker를 통한 관련 지식 검색, ActExecutor를 통한 시연 기반 작업 수행의 세 가지 전문화된 에이전트로 구성됩니다.
- ***Performance Highlights***: 실험 결과, 오프라인 평가에서 Gemini-1.5-Pro의 정확도가 19.3%에서 51.7%로 198.9% 상대 개선되었으며, 온라인 평가에서는 UI-TARS-7B-SFT의 성공률이 18.1%에서 32.8%로 증가했습니다. 이와 같은 성과는 시연 기반 학습이 다양한 모바일 GUI 에이전트에 대한 적응성과 실용성을 획기적으로 개선할 가능성을 갖고 있음을 보여줍니다.

### [LookingGlass: Generative Anamorphoses via Laplacian Pyramid Warping](https://arxiv.org/abs/2504.08902)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2504.08902.png)

Vote: 7

Authors: Pascal Chang, Jingwei Tang, Vinicius C. Azevedo, Markus Gross, Sergio Sancho

- ***What's New***: 이 논문에서는 거울이나 렌즈를 통해 숨겨진 이미지를 드러내는 애매모호한 왜상(anamorphoses)을 생성하는 새로운 방법을 제안합니다. 이를 위해 라플라시안 피라미드 워핑(Laplacian Pyramid Warping)이라는 고주파 디테일을 보존하면서 복잡한 이미지 변형을 처리할 수 있는 빈도 인식 이미지 워핑 기술을 소개합니다. 이 방법은 Visual Anagrams 프레임워크를 확장하여 잠재 공간 모델(latent space models) 및 더 넓은 범위의 공간 변환을 가능하게 하여 새로운 생성적 지각적 착시를 구현합니다.
- ***Technical Details***: 제안된 방법은 여러 시점에서의 이미지 왜상생성에 잠재 확산 모델(latent diffusion models)과 흐름 모델(flow models)을 사용하는 것을 가능하게 하며, 이는 무작위 변환과 곡면 거울 또는 렌즈를 통해 볼 때 발생할 수 있는 왜곡 문제를 해결합니다. 라플라시안 피라미드 워핑을 사용해 각 픽셀에 대해 불규칙한 고주파 디테일을 효과적으로 처리하여 복잡한 반사 및 굴절 표면을 포함하는 정교한 왜상을 생성합니다.
- ***Performance Highlights***: 제안된 방법은 이전 작업보다 생성된 결과의 품질과 표현력이 크게 향상되었습니다. 특히 3D 왜상 생성에 있어서 복합적인 변형을 담당하면서 이미지 품질의 손실을 최소화하는 데 성공했습니다. 실험 결과는 여러 시점에서 일관되게 고품질의 왜상을 생성할 수 있음을 보여줍니다.

### [An LMM for Efficient Video Understanding via Reinforced Compression of Video Cubes](https://arxiv.org/abs/2504.15270)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2504.15270.png)

Vote: 6

Authors: Zhiyuan Liu, Yuan Yao, Ji Qi, Yushi Bai, Juanzi Li, Tat-Seng Chua, Bin Xu

- ***What's New***: Quicksviewer는 새로운 비디오 이해 방식인 비디오 큐브(dynamic cubing)를 통해 비디오를 효율적으로 비디오 이해를 수행할 수 있는 대형 멀티모달 모델(Large Multimodal Model; LMM)입니다. 이 모델은 비디오 내의 비균일한 큐브로 분할하여 온라인 환경에서도 적응적으로 비디오를 압축하고, 45배의 데이터 압축률을 달성함으로써 대규모 수용 영역(receptive field)을 가능케 합니다.
- ***Technical Details***: Quicksviewer는 시각적 인코더(visual encoder)를 통해 받은 비디오를 작은 큐빙 네트워크(cubing network)를 통해 비균일한 큐브로 나누고, 각 큐브에 대해 통합된 리샘플링(resampling)을 적용하여 적응형 압축을 이룹니다. 이어지는 단계로, 시각적 토큰을 LLM에 투입하여 추론을 합니다. Gumbel Softmax 기반의 큐빙 네트워크 학습을 통해 경계 레이블 없이 효율적인 학습을 지원합니다. 세 단계의 훈련 과정(멀티모달 정렬, 대규모 사전 훈련, 감독된 미세조정)을 통해 모델을 훈련시킵니다.
- ***Performance Highlights***: Quicksviewer는 Video-MME 벤치마크에서 기존 고정 파티셔닝 전략을 사용하는 직접적인 기준선 모델을 최대 8.72의 정확도로 능가하며, Video-MME, MVBench, MLVU 등 다양한 비디오 이해 벤치마크에서 경쟁력 있는 성능을 만끽합니다. 특히, 비디오 텍스트 샘플이 0.8M만 사용하였음에도 상당히 높은 SOTA 성과를 거두며, 기존 대비 적은 비디오-텍스트(Token) 샘플을 활용하여 탁월한 성능을 보여 줍니다.

### [NEMOTRON-CROSSTHINK: Scaling Self-Learning beyond Math Reasoning](https://arxiv.org/abs/2504.13941)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2504.13941.png)

Vote: 5

Authors: Ying Lin, Mohammad Shoeybi, Yejin Choi, Mostofa Patwary, Bryan Catanzaro, Shrimai Prabhumoye, Syeda Nahida Akter, Eric Nyberg, Evelina Bakhturi, Matvei Novikov, Seungju Han

- ***What's New***: NEMOTRON-CROSSTHINK은 강화 학습(RL)을 통해 다양한 추론 작업에 대한 일반화를 향상시키기 위해 다중 도메인 코퍼스를 체계적으로 통합하는 프레임워크입니다. 다양한 출처에서 데이터를 수집함으로써 폭넓은 추론 도메인에 대한 일반화를 증진시키고 있습니다.
- ***Technical Details***: NEMOTRON-CROSSTHINK은 수학, 인문학, 사회과학 등 다양한 도메인을 아우르는 실제 및 생성 질문-답변 쌍을 강화학습에 체계적으로 통합하여 다양한 추론 작업에서 일반화를 향상시킵니다. 질문 유형을 제한하고 검증 가능한 답변을 필터링하며, 여러 소스의 데이터를 효과적으로 혼합하는 전략을 최적화합니다.
- ***Performance Highlights***: 이 방법을 사용하여 수학적 추론(MATH-500:+30.1%, AMC23:+27.5%) 및 비수학적 추론 벤치마크(MMLU-PRO:+12.8%, GPQA-DIAMOND:+11.3%, AGIEVAL:+15.1%, SUPERGPQA:+3.8%)에서 정확도를 개선하였고, 정답을 위해 28% 적은 토큰을 사용하여 더욱 효율적으로 응답하는 데 성공했습니다.

### [DRAGON: Distributional Rewards Optimize Diffusion Generative Models](https://arxiv.org/abs/2504.15217)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2504.15217.png)

Vote: 5

Authors: Nicholas J. Bryan, Yatong Bai, Somayeh Sojoudi, Jonah Casebeer

- ***What's New***: DRAGON은 생성 모델의 보상 최적화를 위한 다재다능한 프레임워크로, 인스턴스 수준의 보상의 한계를 넘어 배포(...reward functions)의 최적화도 가능하게 합니다. 모드 간 임베딩 공간을 활용하여 음악 생성 품질을 텍스트 설명만으로도 향상시킬 수 있습니다.
- ***Technical Details***: DRAGON은 사전 훈련된 임베딩 추출기와 (교차 모달) 참조 예제를 사용하여 긍정적인 시연 세트와 부정적인 세트를 만듭니다. 그런 다음, 두 세트의 대비를 이용하여 보상을 최대화합니다. 다양한 보상 함수를 최적화할 수 있으며, 예를 들어 인스턴스별 FAD, 풀-데이터셋 FAD 등을 포함하여 프로세스를 통합합니다.
- ***Performance Highlights***: DRAGON은 20가지 목표 보상 중 평균 81.45%의 승률을 달성했습니다. 예제 세트를 기반으로 한 보상 함수는 생성 향상에 큰 영향을 미쳤으며, 인간 선호 주석없이 60.95%의 음악 품질 승률을 달성했습니다. 이는 DRAGON이 인간 인식 품질 향상을 위한 보상 함수 설계 및 최적화의 새로운 접근 방식을 포함하고 있음을 보여줍니다.

### [RainbowPlus: Enhancing Adversarial Prompt Generation via Evolutionary Quality-Diversity Search](https://arxiv.org/abs/2504.15047)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2504.15047.png)

Vote: 4

Authors: Chris Ngo, Quy-Anh Dang, Truong-Son Hy

- ***What's New***: RAINBOWPLUS는 진화적 계산을 활용하여 적대적 프롬프트 생성을 개선한 새로운 레드 팀 구성 프레임워크입니다. 이는 기존 언어 모델의 약점을 더욱 효율적으로 탐지할 수 있도록 진화적 품질-다양성(Quality-Diversity; QD) 탐색 방식을 적용하여 기존의 MAP-Elites 알고리즘을 확장하였습니다.
- ***Technical Details***: RAINBOWPLUS는 다요소 아카이브를 사용하여 다양한 고품질의 프롬프트를 저장하고, 확률적 점수 매커니즘을 통해 여러 프롬프트를 동시에 평가하는 종합적인 적합도 함수를 채용합니다. 이러한 접근 방식은 단일 프롬프트 아카이브의 한계를 극복하고, 이전 QD 방법론에서의 쌍대 비교를 개선합니다. 이를 통해 더 넓은 진화적 탐색이 가능해집니다.
- ***Performance Highlights***: RAINBOWPLUS는 6개의 벤치마크 데이터셋과 4개의 오픈 소스 LLM을 통해 기존 QD 방법론에 비해 뛰어난 성과를 보였습니다. 공격 성공률(ASR)이 평균 81.1%를 기록하며, AutoDAN-Turbo 대비 3.9% 더 높은 성과를 냈고 9배 더 빠른 속도(1.45시간 대 13.50시간)를 보였습니다. 이는 현재 LLM의 안전성 향상에 기여할 수 있는 확장 가능하고 효율적인 도구를 제공합니다.

### [TAPIP3D: Tracking Any Point in Persistent 3D Geometry](https://arxiv.org/abs/2504.14717)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2504.14717.png)

Vote: 4

Authors: Bowei Zhang, Katerina Fragkiadaki, Lei Ke, Adam W. Harley

- ***What's New***: TAPIP3D는 RGB 및 RGB-D 비디오에서 장기적인 3D 포인트 추적을 위한 새로운 접근법으로, 비디오를 카메라 안정화된 시공간적 특징 클라우드로 표현합니다. 이를 통해 카메라 움직임 정보를 활용하여 2D 비디오 특징을 3D 월드 공간으로 끌어올리면서 카메라 움직임을 효과적으로 제거하고자 합니다. TAPIP3D는 시공간적 주의 메커니즘을 통해 멀티 프레임 3D 움직임 추정치를 반복적으로 개선하여 장기적인 3D 포인트 추적을 구현합니다.
- ***Technical Details***: TAPIP3D는 깊이 및 카메라 움직임 정보를 사용하여 2D 비디오 특징을 3D 공간으로 들어 올려 특징 클라우드를 형성합니다. 로컬 페어 어텐션(Local Pair Attention) 메커니즘을 사용하여 각각의 쿼리 트랙의 3D 포인트와 이웃한 포인트 간의 3D 관계를 캡쳐하며, 3D 특징 지도에서 바이-디렉셔널 크로스 어텐션 과정을 통해 특징을 추출합니다. 이를 통해 주어진 시간 단위에 대해 각 쿼리 트랙에 대한 딥 피처 표현이 가능하게 합니다. 또한, 쿼리 트랙 포인트와 이웃 타겟 포인트 간의 3D 상대 오프셋을 주의 값에 통합하였습니다.
- ***Performance Highlights***: TAPIP3D는 깊이가 정확히 제공되는 경우 기존의 모든 방법들보다 3D 추적 지표에서 큰 차이로 성능을 우월히 발휘하며, 카메라 및 월드 3D 좌표 프레임에서 특징 추출과 트래킹을 수행할 수 있어 다양한 3D 포인트 트래킹 벤치마크에서 더 견고하고 정확한 결과를 보여줍니다. MegaSaM과 같은 최신의 카메라 및 깊이 추정 방법과 결합하면 기존의 3D 포인트 트래커들보다 뛰어난 성과를 보여줍니다.

### [CoMotion: Concurrent Multi-person 3D Motion](https://arxiv.org/abs/2504.12186)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2504.12186.png)

Vote: 2

Authors: Stephan R. Richter, Lahav Lipson, Peiyun Hu, Vladlen Koltun, Alejandro Newell

- ***What's New***: CoMotion는 단일 단안 카메라 스트림에서 다수의 사람의 3D 자세를 동시에 감지하고 추적하는 혁신적인 접근 방법을 소개합니다. 주요 기술적 혁신은 장면 내 모든 사람의 자세를 새로운 프레임 입력에서 직접 업데이트하여 폐색을 통해서도 온라인 추적이 가능하게 하는 것입니다.
- ***Technical Details***: CoMotion은 ConvNextV2 모델을 기반으로 이미지 인코더를 사용하여 각 프레임에서 이미지 특징(feature)을 추출합니다. 업데이트 단계는 모든 추적된 사람의 자세를 최신 입력 이미지에 대한 크로스 어텐션(cross-attention)과 반복적인 GRU(hidden state)를 통해 수행합니다. 크게 3단계 학습 커리큘럼을 따라 각 단계마다 다이내믹한 데이터를 사용하여 모델을 최적화합니다.
- ***Performance Highlights***: PoseTrack21 데이터셋에서 CoMotion은 이전 최첨단 기술보다 MOTA는 14%, IDF1은 12% 향상되었습니다. CoMotion은 또한 이전 시스템보다 10배 이상 빠르게 다수의 사람을 추적합니다. 이러한 강력한 성능은 다양한 유형의 데이터셋을 사용하여 학습된 결과로, 특히 도전적인 실세계 비디오에서 향상된 성능을 보여줍니다.

### [RF-DETR Object Detection vs YOLOv12 : A Study of Transformer-based and CNN-based Architectures for Single-Class and Multi-Class Greenfruit Detection in Complex Orchard Environments Under Label Ambiguity](https://arxiv.org/abs/2504.13099)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2504.13099.png)

Vote: 2

Authors: Manoj Karkee, Ranjan Sapkota, Ajay Sharda, Rahul Harsha Cheppally

- ***What's New***: 이번 연구는 복잡한 과수원 환경에서 라벨 모호성을 특징으로 하는 녹색 과일 인식을 위해 RF-DETR 객체 탐지 모델과 YOLOv12 객체 탐지 모델을 비교합니다. RF-DETR은 Deformable Attention Mechanism을 활용하여 부분적으로 가려지거나 시각적 모호성이 있는 과일을 식별하는 데 효과적이었던 반면, YOLOv12는 CNN 기반의 Attention Mechanism으로 지역적 특징 추출을 최적화하여 계산 효율성을 향상시킵니다.
- ***Technical Details***: 맞춤형 데이터셋은 단일 클래스와 다중 클래스 주석을 포함하여 모델의 성능을 평가했습니다. RF-DETR은 DINOv2 백본에 기반을 두고 있으며, 전역적 컨텍스트 모델링에 우수하며, YOLOv12는 R-ELAN 백본을 사용하여 다중 스케일 특징 융합을 효율화하였습니다. 단일 클래스 탐지 상황에서 RF-DETR은 mAP@50에서 0.9464를 기록하였고, YOLOv12N은 mAP@50:95에서 0.7620을 기록하였습니다. 다중 클래스 탐지에서는 RF-DETR이 occluded 및 non-occluded 과일을 구별하는 데 mAP@50 0.8298로 우수한 성능을 보였습니다.
- ***Performance Highlights***: RF-DETR은 학습 속도가 빠르며 단일 클래스 설정에서 10 epochs 이내에 수렴을 이루었습니다. mAP@50에서 최고를 기록하여 복잡한 공간 시나리오에서 안정적인 성능을 보였으며, YOLOv12는 다중 클래스 설정에서 좀 더 높은 mAP@50:95를 보였습니다. 이러한 결과는 RF-DETR이 시각적 복잡성이 높은 상황에서 뛰어난 정확성을 제공하며 YOLOv12는 속도 민감형 배치에 이상적임을 보여줍니다.

### [SilVar-Med: A Speech-Driven Visual Language Model for Explainable Abnormality Detection in Medical Imaging](https://arxiv.org/abs/2504.10642)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2504.10642.png)

Vote: 1

Authors: Trong-Duong Bui, Chris Ngo, Tan-Huong Pham, Minh Luu Quang, Tan-Hanh Pham, Truong-Son Hy

- ***What's New***: SilVar-Med는 음성 기반 상호작용이 가능한 의료 비주얼 언어 모델(Visual Language Model; VLM)로, 의료 이미징에서 설명 가능한 이상 탐지를 지원합니다. 이 모델은 음성 지시에 의한 비정상 탐지(reasoning abnormality detection)에서의 해석력을 강화하고, 의료 VLM의 투명성과 상호작용성을 증진시키기 위해 설계되었습니다.
- ***Technical Details***: SilVar-Med는 SilVar 모델 기반의 멀티모달 모델로, 음성 및 시각 입력을 통합하여 이상 탐지에 대한 추론 텍스트 응답을 생성합니다. VLM 사용자들이 음성을 통해 모델과 상호작용할 수 있으며, PubMedCLIP으로 수정된 비전 인코더(vision encoder)와 Deepseek R1로 대체된 언어 모델이 포함되어 있습니다. 훈련 프로세스는 일반에서 의료로의 적응 단계와 의료 이상 특화 단계로 이루어져 있으며, 각 단계에서 Whisper 모델로 음성 인코더를 트레이닝하여 의료 도메인에서의 스피치-텍스트 작업의 성능을 보장합니다.
- ***Performance Highlights***: SilVar-Med는 평가에서 BERTScore 0.82, BLEU 20.87%, ROUGE 55.18%를 기록하여, 상업적인 모델인 GPT-4o mini와 Gemini Flash 1.5보다 높은 성능을 보여주었습니다. 이는 SilVar-Med가 음성 기반 의료 VQA에서의 높은 추론 성능을 지닌다고 평가됩니다. Whisper Tiny 모델은 트레이닝과 테스트에서 WER 2.01%, 2.67% 및 CER 2.01%, 2.99%를 보여, 훈련에서의 안정성을 나타내었습니다.

### [PROMPTEVALS: A Dataset of Assertions and Guardrails for Custom Production Large Language Model Pipelines](https://arxiv.org/abs/2504.14738)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2504.14738.png)

Vote: 0

Authors: Shreya Shankar, Harrison Chase, Aditya Parameswaran, Will Fu-Hinthorn, Reya Vir

- ***What's New***: PROMPTEVALS는 대형 언어 모델 파이프라인의 출력에 대한 주장(assertions)과 가드레일(guardrails)을 위한 최초의 데이터셋입니다. 이 데이터셋은 2087개의 LLM 파이프라인 프롬프트와 12623개의 대응 주장 기준(assertion criteria)을 포함하여 기존 컬렉션보다 5배 더 큰 규모를 자랑합니다.
- ***Technical Details***: PROMPTEVALS 데이터셋은 코드가 아닌 프롬프트를 사용하여 LLM의 출력 품질을 평가하기 위한 맞춤형 주장을 생성하는 데 중점을 둡니다. Mistral과 Llama 3 모델을 미세 조정(fine-tune)하여 프롬프트 템플릿에 대해 관련 주장을 쉽게 생성할 수 있도록 하였고, 이 모델은 GPT-4o보다 평균적으로 20.93% 더 우수한 성능을 보였습니다.
- ***Performance Highlights***: 미세 조정된 Mistral 모델은 평균적으로 0.8199의 Semantic F1 점수를 기록하며, 이는 독점 GPT-4o 모델보다 20.43% 높은 성능을 제공합니다. 이러한 성능 향상은 더 빠른 실행 시간과 낮은 비용으로 다른 모델에 비해 경쟁력을 갖추게 합니다.

### [LoftUp: Learning a Coordinate-Based Feature Upsampler for Vision Foundation Models](https://arxiv.org/abs/2504.14032)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2504.14032.png)

Vote: 0

Authors: Volodymyr Havrylov, Dan Zhang, Andreas Geiger, Haiwen Huang, Anpei Chen

- ***What's New***: LoftUp는 영상 기반 모델(Vision Foundation Models; VFMs)에서 사용되는 기능 업샘플링(feature upsampling) 기술을 향상시키기 위한 새로운 접근 방식을 제안합니다. 이 방법은 고해상도 이미지를 좌표와 결합하고 낮은 해상도의 VFM 기능을 통합하여 날카롭고 고품질의 기능을 생성하는 좌표 기반 교차 주의 변환기(coordinate-based cross-attention transformer)를 도입하였습니다.
- ***Technical Details***: LoftUp의 업샘플러 아키텍처는 좌표 기반 방법론을 활용하여 각 픽셀에 대한 고해상도 기능을 직접 예측합니다. 모델은 이미지 좌표와 RGB 값을 입력으로 받아 저해상도 VFM 기능 맵과 교차 주의를 수행하여 상관있는 매핑을 생성합니다. 자가 증류(self-distillation) 전략을 도입하여 고품질의 가짜 그라운드 트루스(pseudo-groundtruth) 기능을 생성, 이를 기반으로 고해상도 손실을 계산합니다.
- ***Performance Highlights***: LoftUp는 기존의 업샘플러 기술을 여러 다운스트림 작업에서 크게 능가하였습니다. 특히, 비디오 객체 분할(video object segmentation) 작업에서는 이전의 기술 대비 약 50% 이상의 성능 향상을 보였습니다. 다양한 입력 및 기능 해상도에 적응 가능하며, 여러 다운스트림 응용 프로그램의 다양한 요구를 충족시킬 수 있습니다.

