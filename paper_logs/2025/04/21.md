## Daily Papers (2025-04-21)

### [Does Reinforcement Learning Really Incentivize Reasoning Capacity in LLMs Beyond the Base Model?](https://arxiv.org/abs/2504.13837)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2504.13837.png)

Vote: 60

Authors: Zhaokai Wang, Shiji Song, Gao Huang, Zhiqi Chen, Yang Yue, Rui Lu, Andrew Zhao

- ***What's New***: 이번 연구는 Reinforcement Learning with Verifiable Rewards (RLVR)이 LLMs의 기존 모델을 넘어 새로운 추론 능력을 유도하는지 여부를 재검토합니다. 일반적으로 RLVR이 LLMs의 수학 및 프로그래밍 작업에서의 성능 향상에 기여한다고 여겨져 왔지만, 이 연구에서는 RLVR 훈련이 본질적으로 새로운 추론 패턴을 끌어내지 못한다는 것을 발견했습니다.
- ***Technical Details***: 연구에서는 다양한 모델 계열, RL 알고리즘 및 수학/코딩 벤치마크에서 모델의 추론 능력 경계를 탐구하기 위해 pass@k 메트릭을 사용합니다. RLVR 훈련이 모델의 출력 분포를 보상 가능성이 높은 경로로 향하게 하여 보다 효율적으로 올바른 응답을 추출하게 만듭니다. 하지만 이는 모델의 탐색 능력을 제한하여 기저 모델에 비해 좁은 추론 능력 경계를 초래합니다. RLVR와는 다르게, Distillation은 모델에 실제로 새로운 지식을 도입할 수 있습니다.
- ***Performance Highlights***: 실험 결과 RL로 훈련된 모델은 작은 k 값에서는 기저 모델보다 뛰어난 성능을 보이지만, 큰 k 값에서는 기저 모델이 RL 훈련 모델보다 더 높은 pass@k 점수를 기록합니다. 이는 RLVR이 현재 형태로는 LLM의 추론 능력을 기저 모델의 한계 너머로 확장하는 데 충분치 않음을 시사하며, 새로운 학습 패러다임의 필요성을 강조합니다.

### [MIG: Automatic Data Selection for Instruction Tuning by Maximizing Information Gain in Semantic Space](https://arxiv.org/abs/2504.13835)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2504.13835.png)

Vote: 30

Authors: Zerun Ma, Kai Hu, Yining Li, Haochen Ye, Kai Chen, Yicheng Chen

- ***What's New***: 이 연구에서는 대규모 데이터 풀에서 고품질의 다양성 있는 하위 집합을 자동으로 선택하기 위한 새로운 방법을 제안합니다. 이 방법은 의미적 공간에서 정보 이득(Informatoin Gain)을 최대화함으로써 명령어 튜닝 데이터셋을 구성합니다. 다양한 데이터셋과 기본 모델에 걸친 실험에서 MIG(Most Informative Gradient Sampling)가 기존 최첨단 방법을 일관되게 능가함을 입증했습니다.
- ***Technical Details***: 본 연구는 데이터셋의 정보 콘텐츠를 정량화하기 위해 레이블 그래프(Label Graph)를 구축하고, 그래프 내 정보 분포를 기반으로 데이터 다각화를 측정하는 방법을 통합하여 제시합니다. 이를 바탕으로 광범위한 데이터에서 반복적으로 샘플을 선택하여 의미적 공간에서 정보 이득을 극대화하는 효율적인 샘플링 방법을 도입했습니다. MIG의 데이터 측정은 정보 전파를 통해 의미적 상관관계와 주석 바이어스를 해결하며 효율적인 탐욕적(greedy) 알고리즘을 구현하여 레이블 그래프의 현재 상태에 따라 정보 이득을 최대화하게 합니다.
- ***Performance Highlights***: MIG는 다양한 아키텍처와 데이터 풀에서 일관되게 우수한 성능을 보여주었습니다. 특히, MIG를 통해 5%의 Tulu3 데이터를 사용한 모델은 전체 데이터셋을 사용한 공식 SFT 모델보다 1.73% 더 높은 성능을 기록했습니다. 사람의 요구를 바탕으로 한 평가에서는 상당히 개선된 4.59% 성능 향상을 보였습니다. 또한, MIG는 임베딩 기반 메서드에 비해 샘플링 효율성이 100배 이상 향상되었습니다.

### [NodeRAG: Structuring Graph-based RAG with Heterogeneous Nodes](https://arxiv.org/abs/2504.11544)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2504.11544.png)

Vote: 25

Authors: Tianyang Xu, Yixin Liu, Haoxiang Chen, Chengze Li, Lichao Sun, Ruoxi Chen, Haojie Zheng

- ***What's New***: NodeRAG는 그래프 기반 RAG 시스템의 설계 한계를 극복하기 위해 제안된 프레임워크입니다. 이 새로운 시스템은 이질적인 그래프 구조(Heterogeneous Graph Structures)를 도입하여 다양한 그래프 알고리즘의 통합을 용이하게 하고, 효율적인 끝에서 끝까지의 처리 과정을 제공합니다.
- ***Technical Details***: NodeRAG는 이질적인 그래프(Heterograph)를 중심으로 설계되어 기존의 세부 정보뿐만 아니라 새로운 통찰력과 고급 발견을 통합합니다. 이러한 구조는 엔티티와 관계, 원본 텍스트 청크, 그리고 요약된 이벤트를 노드로 나타내며, 이는 LLM(대형 언어 모델) 및 그래프 알고리즘을 활용하여 완전히 조화로운 프로세스를 보장합니다.
- ***Performance Highlights***: NodeRAG는 여러 벤치마크에서 기존의 GraphRAG 및 LightRAG 방법보다 우수한 성능을 보였으며, 멀티홉 질의(multi-hop)와 개방형 평가에서 더 높은 질의 응답 성능을 발휘했습니다. 또한, 인덱싱 시간, 질의 시간 및 저장 효율성 측면에서도 탁월한 성능을 나타내었습니다.

### [Could Thinking Multilingually Empower LLM Reasoning?](https://arxiv.org/abs/2504.11833)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2504.11833.png)

Vote: 15

Authors: Changjiang Gao, Fei Yuan, Shujian Huang, Lei Li, Xu Huang, Wenhao Zhu

- ***What's New***: 이 연구는 다국어 사고를 통해 LLM의 추론 능력을 향상시킬 수 있는지를 탐구했으며, 영어로만 문제를 제시했을 때보다 다국어로 문제를 제시했을 때 모델의 성능이 개선될 수 있음을 보였습니다.
- ***Technical Details***: 이 연구는 GPQA 및 MGSM과 같은 추론 설정에서 다국어 사고의 성능 상한선을 평가하기 위해 모델 반응을 수집했습니다. LLaMA3.1-70B, Qwen2.5-72B 및 R1-Distill-LLaMA3.1-70B 모델을 사용하여 Acc@k 등 구체적인 성능 지표를 통해 비교 실험을 수행했습니다. 또한 다국어 변환의 혜택과 패턴에 대한 심층 분석을 진행했습니다.
- ***Performance Highlights***: 다국어 사고는 GPQA에서 정확성을 약 45에서 약 90으로, MGSM에서 약 90에서 약 100으로 향상시킬 가능성이 있으며, 이는 독점적으로 영어를 사용한 경우와 비교하여 약 10 Acc@k 포인트 더 높은 성과를 보여줍니다. 이는 다양한 언어를 사용하는 추론이 모델의 성능을 크게 증대시킬 수 있음을 시사합니다.

### [It's All Connected: A Journey Through Test-Time Memorization, Attentional Bias, Retention, and Online Optimization](https://arxiv.org/abs/2504.13173)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2504.13173.png)

Vote: 11

Authors: Meisam Razaviyayn, Ali Behrouz, Vahab Mirrokni, Peilin Zhong

- ***What's New***: 이 논문에서는 인간의 인지 현상 중 하나인 주의 편향(Attentional Bias)을 기반으로 트랜스포머, 타이탄(Titans) 및 최신의 선형 순환 신경망을 재구성하여 연관기억모듈로 개념화합니다. 이들은 입력의 키-값 매핑을 내적 목표를 사용하여 학습합니다. Miras라는 일반적인 프레임워크를 발표하여 연관 기억 아키텍처, 주의 편향 목표, 유지 게이트(Retention Gate), 메모리 학습 알고리즘으로 딥러닝 아키텍처를 설계할 수 있는 네 가지 선택 사항을 제공합니다.
- ***Technical Details***: Miras 프레임워크는 메모리 아키텍처, 주의 편향(Attentional Bias) 목표, 유지 게이트, 메모리 학습 알고리즘을 통해 새로운 시퀀스 모델링 아키텍처를 설계합니다. Miras는 기존의 많은 모델들이 사용하는 동일한 유형의 주의 편향을 활용하는 연관 기억으로서 시퀀스 모델을 재해석하고, 이를 통해 새로운 유지 게이트를 제공하여 이전에 학습한 개념을 유지하면서 새로운 개념을 학습할 수 있습니다.
- ***Performance Highlights***: Moneta, Yaad 및 Memora와 같은 세 가지 새로운 시퀀스 모델은 기존의 선형 RNN과 트랜스포머를 능가하는 성능을 보였습니다. 특히, Moneta는 특정 작업에서 탁월한 성능을 나타내며, 이는 범용적인 메모리 설계의 중요성을 보여 줍니다. 이 세 모델은 긴 문맥 길이에서 우수한 성능을 보였으며, 모델 크기가 증가할수록 확장 패턴이 개선되었습니다.

### [CLASH: Evaluating Language Models on Judging High-Stakes Dilemmas from Multiple Perspectives](https://arxiv.org/abs/2504.10823)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2504.10823.png)

Vote: 10

Authors: Peter Railton, Ryan Sungmo Kwon, Ayoung Lee, Lu Wang

- ***What's New***: CLASH는 대형 언어 모델(Large Language Models; LLMs)이 고위험 딜레마 상황에서 다양한 관점을 평가할 수 있도록 설계된 새로운 평가 프레임워크입니다. 이 데이터셋은 345개의 인간이 직접 작성한 고위험 딜레마와 3,795개의 다양한 가치관을 담은 개별 관점으로 구성되어 있어 LLM이 복잡한 가치에 대해 추론하고 다양한 관점에서 판단할 수 있도록 합니다.
- ***Technical Details***: CLASH 데이터셋은 520단어의 평균 길이를 가지는 고품질의 딜레마로 구성되어 있으며, 각 딜레마는 다양한 가치관의 초상적(또는 내러티브적) 관점을 통해 표현됩니다. 이 접근 방식을 통해 결정을 내리기 어려운 상황에서의 가치 기반 추론을 보다 심층적으로 연구할 수 있습니다. 실험에서는 10개의 오픈 및 클로즈드 LLM 프론티어 모델을 벤치마크하여 HLLM의 가치 편향 및 조정 가능성에 대한 여러 주요 발견사항을 제시합니다.
- ***Performance Highlights***: 고급 모델인 GPT-4o와 Claude-Sonnet도 결정의 양면성을 식별하는 데 있어 50% 미만의 정확도를 기록하며, 명료한 상황에 비해 성능이 크게 저하되었습니다. 심리적 불편함을 예측하는 데는 어느 정도의 성공을 거뒀지만, 가치의 변화가 포함된 관점에 대한 이해는 충분하지 않음을 드러냈습니다. 특히, 변화된 가치와의 추론에서 GPT-4o-mini는 최대 66.43%, Llama3.3-70B는 53.62%의 성능 저하를 보였습니다. 이러한 결과는 LLMs가 복잡한 가치 추론에서 어려움을 겪고 있음을 보여줍니다.

### [AerialMegaDepth: Learning Aerial-Ground Reconstruction and View Synthesis](https://arxiv.org/abs/2504.13157)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2504.13157.png)

Vote: 9

Authors: Deva Ramanan, Shubham Tulsiani, Anurag Ghosh, Khiem Vuong, Srinivasa Narasimhan

- ***What's New***: AerialMegaDepth는 항공-지상 이미지 간의 대규모 구조 학습을 위한 새로운 데이터셋 및 방법론을 소개하고 있습니다. 이는 3D 도시 메쉬와 실제 군중 소스 이미지를 결합하여 생성된 하이브리드 데이터셋을 활용하여, 특히 어렵게 여겨져 왔던 항공-지상 뷰포인트 변경 문제를 극복하고자 합니다.
- ***Technical Details***: 이 논문은 Google Earth와 같은 지리정보 플랫폼과 MegaDepth와 같은 대중 소스 이미지를 활용하여, 다양한 고도에서의 의사-합성(pseudo-synthetic) 이미지를 생성하고, 실제 이미지를 조합하여 고유의 코디네이트 시스템에서 일치시키는 프레임워크를 제안합니다. 생성된 하이브리드 데이터셋을 DUSt3R 및 MASt3R와 같은 최첨단 알고리즘에 미세 조정하여 사용함으로써, 카메라 위치 추정 및 새로운 뷰 생성과 같은 다운스트림 작업에서 성능이 개선됨을 보였습니다.
- ***Performance Highlights***: 기존 DUSt3R 모델이 항공-지상 쌍에서 카메라 등록을 5% 미만의 성공률로 수행하는 와중에, 본 데이터로 미세 조정 시 정확도가 56%에 달했습니다. 또한, 새로운 뷰 생성에서도 큰 성능 향상을 보였으며, 이는 특히 항공-지상 시나리오에서의 현실 세계 응용에서의 가치를 입증하였습니다.

### [Tokenize Image Patches: Global Context Fusion for Effective Haze Removal in Large Images](https://arxiv.org/abs/2504.09621)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2504.09621.png)

Vote: 6

Authors: Kaiqi Li, Xinyu Yan, Jiuchen Chen, Qizhi Xu

- ***What's New***: 새로운 DehazeXL 모델은 대형 이미지에서 안개를 제거하는 데 있어 글로벌 문맥 정보와 로컬 세부 특징을 효과적으로 결합해 GPU 메모리 사용을 최소화하는 솔루션입니다. 이 접근 방식은 특히 초고해상도 이미지를 효율적으로 처리할 수 있도록 설계되었습니다.
- ***Technical Details***: DehazeXL은 입력 이미지를 균일한 크기의 패치로 분할한 후 각 패치를 특징 벡터로 인코딩하여 글로벌 Attention Module에서 글로벌 문맥 정보를 통합합니다. 패치 크기를 고정함으로써 입력 크기와 메모리 사용량을 분리하고, 더욱 효율적인 모델 학습과 추론이 가능하게 만듭니다. 또한, Dehazing Attribution Map (DAM)을 고안하여 각 필드가 모델 성능에 미치는 영향을 분석함으로써 결과 해석을 용이하게 합니다.
- ***Performance Highlights***: DehazeXL은 10240 × 10240 픽셀까지의 이미지를 21 GB 메모리로 처리할 수 있으며, 다양한 고해상도 데이터세트에서 최고의 성능을 기록했습니다. PSNR과 SSIM에서 기존의 모든 방법 중 가장 높은 점수를 받았으며, 이는 안개 제거의 정확성과 처리 속도 모두에서 우수함을 시사합니다.

### [HiScene: Creating Hierarchical 3D Scenes with Isometric View Generation](https://arxiv.org/abs/2504.13072)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2504.13072.png)

Vote: 5

Authors: Wenqi Dong, Tao Hu, Zesong Yang, Yuan Li, Hujun Bao, Yuewen Ma, Zhaopeng Cui, Bangbang Yang

- ***What's New***: HiScene는 계층적 3D 장면 생성 프레임워크로, 등각 뷰(이소메트릭 뷰; Isometric View)를 통해 복잡한 장면을 객체로 취급함으로써, 2D 이미지 생성과 3D 객체 생성 간의 차이를 메웁니다. 새로운 계층적 접근으로 3D 콘텐츠를 생성하여 직관적인 장면 구조를 유지합니다.
- ***Technical Details***: HiScene은 영상 차분 기반의 무형 완성(video-diffusion-based amodal completion) 기법을 개발하여 객체 간 가려짐과 그림자를 효과적으로 처리합니다. 또한, 다중 뷰 재구성 모델(Multi-View Large Reconstruction Model; LRM)을 활용하여 공간 정렬 및 기하학적 구조를 개선합니다. TRELLIS와 같은 네이티브 3D 생성 모델을 사용하여, 기본 객체 생성에서부터 정밀한 세부 구조 생성까지 일관된 처리 과정을 거칩니다.
- ***Performance Highlights***: 계층적 씬 파싱을 위한 3D 가우시안 스플래팅(3D Gaussian Splatting) 장면 초기화 이후, 비디오 차분을 사용한 복구 과정을 통해 복잡한 시각 장애 요소를 성공적으로 제거하며, 생성된 장면은 고품질의 객체 품질과 자연스러운 배열을 보여줍니다. 또한, 사용자 연구에서도 가장 높은 점수를 기록하여, 기존의 발전된 방법들보다 탁월한 성능을 입증하였습니다.

### [Thought Manipulation: External Thought Can Be Efficient for Large Reasoning Models](https://arxiv.org/abs/2504.13626)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2504.13626.png)

Vote: 4

Authors: Zifan Peng, Zhen Sun, Wenhan Dong, Jingyi Zheng, Xinlei He, Shiwen Cui, Weiqiang Wang, Yule Liu, Zeyang Sha

- ***What's New***: 이 논문에서는 대형 추론 모델(large reasoning models; LRMs)의 과도한 사고(Overthinking) 문제를 해결하기 위해, 외부 CoT(chain-of-thought)를 활용하여 효율적인 사고 조작 방법을 제안합니다. 이를 통해 훈련 없이도 중간 사고 단계를 줄이고 계산 비용을 크게 절감할 수 있습니다.
- ***Technical Details***: 이 연구는 작은 모델이 생성한 외부 CoT를 <think>와 </think> 태그 사이에 배치하여 모델이 불필요한 사고 단계를 건너뛰게 하는 ThoughtMani 파이프라인을 제안합니다. 실험을 통해 RL 기반과 증류 기반 LRM의 행동 차이를 분석하여 RL 기반 모델에서는 CoT가 제공되어도 추가 사고를 생성하지만, 증류 기반 모델은 종료 태그를 만나면 즉시 사고를 멈춥니다.
- ***Performance Highlights***: ThoughtMani를 사용할 경우 QwQ-32B 모델에서 대응 토큰 수를 약 30% 줄였고 안전 정렬은 평균 10% 증가한 반면, 다른 미세 조정 기반 방법들은 안전 감소를 보였습니다. ThoughtMani는 다양한 실험에서 실효성과 효율성을 입증하며, 실제 시나리오에서 적용 가능한 견고함을 강조합니다.

### [Generative AI Act II: Test Time Scaling Drives Cognition Engineering](https://arxiv.org/abs/2504.13828)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2504.13828.png)

Vote: 4

Authors: Yanheng He, Xuefeng Li, Jiahe Jin, Yixin Ye, Pengfei Liu, Xiangkun Hu, Shijie Xia, Yan Ma, Steffi Chern, Fan Zhou, Yixiu Liu, Run-Ze Fan, Haoyang Zou, Yiwei Qin

- ***What's New***: 액트 II는 지식 검색 시스템에서 '생각 건설 엔진(Thought-construction Engines)'으로 모델을 발전시킴으로써, 언어와 사고의 연결을 강화했습니다. 이를 통해 AI와 인간의 지적 교류가 보다 깊어질 수 있는 가능성을 열었습니다.
- ***Technical Details***: 테스트 타임 스케일링(Test Time Scaling) 기술을 통해 모델이 사고 과정을 시뮬레이션할 수 있는 코그니션 엔지니어링(Cognition Engineering)을 소개합니다. 이 방법론은 강화 학습(Reinforcement Learning)과 자습(Self-Training)을 통해 AI의 사고 능력을 강화하는 데 초점을 두고 있습니다.
- ***Performance Highlights***: 모델의 성능은 알고리즘을 최적화하여 테스트 타임(사고 시간)을 늘림으로써 향상되었으며, 이를 통해 복합적이고 심층적인 사고가 가능해졌습니다. 특히, 이러한 접근은 주문형 복잡한 과제에서 더욱 상당한 성과를 보여주었습니다.

### [Analyzing LLMs' Knowledge Boundary Cognition Across Languages Through the Lens of Internal Representations](https://arxiv.org/abs/2504.13816)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2504.13816.png)

Vote: 2

Authors: Hou Pong Chan, Noura Al Moubayed, Hao Zhang, Lidong Bing, Chenghao Xiao, Mahani Aljunied, Yu Rong

- ***What's New***: 이 논문은 대형 언어 모델(LLMs)의 지식 경계를 다양한 언어에서 분석하는 최초의 연구로, 영어에 국한되지 않고 여러 언어에서의 인식과 전이를 통해 착각의 위험을 줄이려는 목표를 설정하고 있습니다.
- ***Technical Details***: 이 연구에서는 여러 언어의 알 수 있거나 알 수 없는 질문을 처리할 때 LLMs의 내부 표현을 조사하며, 중간에서 중상층(Layers)에서 언어 간 교차 전이에 효과적인 선형 구조를 발견하였습니다. 이 연구는 훈련 없이도 언어 간 지식 경계 인식을 전이할 수 있는 방법과 언어 간에 더욱 잘 일반화할 수 있는 미세 조정 (Fine-Tuning) 방법을 제시합니다.
- ***Performance Highlights***: 힐루시네이션 위험을 줄이고 언어 간 지식 경계 인식을 개선하는 데 있어 주요 성과로는 고자원 언어에서 저자원 언어로의 지식 경계 전이 및 선형 프로젝션(Linear Projection)을 통한 전이가 가능하여 SR Convolution 이론, 넣기 적합화 된 기록이 있습니다. 이 방법은 인식률 면에서 ID와 OOD의 성능 격차를 거의 없앴습니다.

### [Self-alignment of Large Video Language Models with Refined Regularized Preference Optimization](https://arxiv.org/abs/2504.12083)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2504.12083.png)

Vote: 2

Authors: Ali Etemad, Pritam Sarkar

- ***What's New***: 새로운 프레임워크는 대형 비디오 언어 모델(LVLMs; Large Video Language Models)이 자신감과 정확성을 개선할 수 있도록 자신의 오류를 통해 학습하는 방법을 제시합니다. 이를 위해, 'Refined Regularized Preference Optimization (RRPO)'라는 새로운 최적화 방법론을 도입하여 모델의 성능을 높은 수준으로 유지하면서 미세 조정을 가능하게 만듭니다.
- ***Technical Details***: RRPO는 각 토큰에 대한 KL 정규화를 사용하여 서브 시퀀스 레벨 장려책(fine-grained sub-sequence-level rewards)을 부여하고, Direct Preference Optimization(DPO)의 한계를 해결합니다. 이를 통해 LVLMs가 자신의 오류에서 스스로를 더욱 정교하게 정렬하고 학습할 수 있습니다. 이 방법론은 다양한 비디오 과제, 특히 비디오 환각 문제(video hallucination), 짧고 긴 비디오 이해, 세밀한 시간 추론 등에서 그 효과를 입증했습니다.
- ***Performance Highlights***: RRPO는 DPO에 비해 더 정확한 정렬과 안정적인 훈련 결과를 보여주었습니다. 다양한 비디오 관련 과제에서 실험과 분석을 통해 LVLMs의 성능이 개선됨을 증명하였습니다. 이를 통해 비디오 이해 능력을 상당히 향상시켰으며, 코드, 데이터, 모델 가중치를 공개하여 빠르고 정확한 재현성을 가능하게 합니다.

### [Filter2Noise: Interpretable Self-Supervised Single-Image Denoising for Low-Dose CT with Attention-Guided Bilateral Filtering](https://arxiv.org/abs/2504.13519)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2504.13519.png)

Vote: 0

Authors: Siyuan Mei, Mingxuan Gu, Yipeng Sun, Chengze Ye, Fabian Wagner, Siming Bayer, Andreas Maier, Linda-Sophie Schneider

- ***What's New***: Filter2Noise (F2N)는 저선량 CT(Computed Tomography; CT) 스캔에서의 새로운 해석 가능한 자체 지도 학습 기반 단일 이미지 노이즈 제거 프레임워크입니다. 이 방법은 주의 집중 방식의 Bilateral Filter (Attention-Guided Bilateral Filter; AGBF)를 도입하여 각 노이즈 이미지에 적응하고 사용자가 특정 관심 영역에서 노이즈 제거 강도를 조절할 수 있도록 합니다.
- ***Technical Details***: F2N은 주의 집중이 된 Bilateral Filter (AGBF)를 사용하여 이미지의 특정 노이즈 특성에 적응하여 공간적으로 가변적인 필터 매개변수를 예측하고 이를 통해 필터링 과정을 시각적으로 확인할 수 있습니다. 또한, 단일 이미지 학습을 위해 Euclidean Local Shuffle (ELS) 기법을 포함한 다운샘플링 셔플 전략을 도입하여 공간적으로 상관된 노이즈를 처리합니다.
- ***Performance Highlights***: Mayo Clinic 2016 저선량 CT 데이터셋에서, F2N은 최신 자체 지도 학습 단일 이미지 방법(ZS-N2N)보다 4.59 dB PSNR이 높은 성능을 보였으며, 더불어 투명성과 사용자 제어 능력, 그리고 매개변수 효율성을 향상시켰습니다. F2N가 3.6k의 적은 매개변수를 사용하면서도 일관되게 뛰어난 성과를 보여주었습니다.

### [Revisiting Uncertainty Quantification Evaluation in Language Models: Spurious Interactions with Response Length Bias Results](https://arxiv.org/abs/2504.13677)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2504.13677.png)

Vote: 0

Authors: Luca Zappella, Adam Golinski, Sinead Williamson, Federico Danieli, Miao Xiong, Andrea Santilli, Michael Kirchhof, Arno Blaas

- ***What's New***: 본 논문은 언어 모델(Language Models; LMs)에서의 불확실성 정량화 평가(Uncertainty Quantification Evaluation)에 관련된 새로운 관점을 제시합니다. 특히, 일반적으로 사용되는 평가 지표들에서 응답 길이에 따른 편향이 불확실성 평가에 미치는 영향을 분석하며, 불확실성을 측정하는 방법과 정확성 평가 함수(Correctness Function)간의 상관관계로 인한 왜곡을 지적합니다.
- ***Technical Details***: 연구는 4개의 데이터셋과 4개의 모델, 6개의 UQ 방법을 통해 7개의 정확성 평가 함수(lexical-based, embedding-based, LM-as-a-judge approaches)를 종합적으로 비교 평가하였습니다. 특히 LM-judge 접근법이 응답 길이에 덜 편향적이며, 불확실성 평가에서의 잠재적인 해결책으로 제안됩니다.
- ***Performance Highlights***: 실험 결과, LM-as-a-judge 접근법은 인간 평가자와의 높은 일치도를 보이며 이러한 접근법은 불확실성 양에 상대적으로 낮은 오차를 유도하여 더 신뢰할 수 있는 평가를 지원함을 확인했습니다. 반면에 단순한 lexical-based와 embedding-based 정확성 평가 함수들은 시스템적인 편향을 도입하여 불확실성 평가를 왜곡할 수 있음을 보였습니다.

### [Cost-of-Pass: An Economic Framework for Evaluating Language Models](https://arxiv.org/abs/2504.13359)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2504.13359.png)

Vote: 0

Authors: Mert Yuksekgonul, Batu El, Mirac Suzgun, Mehmet Hamza Erol, James Zou

- ***What's New***: Cost-of-Pass는 경제적 가치와 추론 비용을 평가하여 언어 모델(Language Models)을 평가하는 새로운 프레임워크를 제안합니다. 우리는 정확성 및 추론 비용을 결합한 cost-of-pass라는 새로운 메트릭을 도입했으며, 사람 전문가와 비교하여 최소 비용으로 올바른 솔루션을 생성할 수 있는 능력을 측정합니다.
- ***Technical Details***: 이 프레임워크는 경제학의 생산 이론(Production Theory)을 바탕으로 하며, 주어진 문제에 대한 올바른 솔루션을 얻기 위한 예상 금전적 비용을 cost-of-pass로 정의합니다. 우리는 경계 비용(piece frontier cost-of-pass)을 모든 사용 가능한 모델 또는 사람 전문가와 비교하여 정의하며, 분석을 통해 각 모델 군이 생성하는 경제적 가치를 식별합니다.
- ***Performance Highlights***: 가벼운 모델은 기본적인 양적 작업에서 가장 경제적이며, 대형 모델은 지식집약적 과제에서 강점을 보입니다. 최근 1년 동안 복잡한 정량적 작업에서 비용이 수개월마다 절반으로 줄어들어 중요한 진전을 보였습니다. 또한, 다수결 투표 및 자기 정련과 같은 일반적인 추론 기법은 비용 대비 정확성 개선이 드물게 나타나, 모델 레벨 혁신이 주요 비용 효율성의 원동력임을 시사합니다.

