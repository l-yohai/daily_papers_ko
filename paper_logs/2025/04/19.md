## Daily Papers (2025-04-19)

### [Learning Occlusion-Robust Vision Transformers for Real-Time UAV Tracking](https://arxiv.org/abs/2504.09228)

![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2504.09228.png)

Vote: 2

Authors: Dan Zeng, You Wu, Xucheng Wang, Mengyuan Liu, Hengzhou Ye, Xiangyang Yang, Shuiwang Li

- **What's New**: 이 논문은 비전 트랜스포머(Vision Transformers; ViT) 기반의 오클루션(축가리) 강인성을 학습하여 UAV 실시간 추적 성능을 향상시키는 새로운 접근 방식을 소개합니다. 논문에서 제안하는 ORTrack 프레임워크는 공간적 코스(Cox) 프로세스를 이용하여 무작위 마스킹을 통해 목표 특성 표현의 불변성을 구축하며, 적응형 특성 기반 지식 증류(Adaptive Feature-Based Knowledge Distillation; AFKD)를 통해 효율성을 높입니다.
- **Technical Details**: ORTrack는 두 개의 훈련 단계로 구성되어 있으며, 첫 번째 단계에서는 교사 모델을 통해 오클루션 강인 특성을 학습하고, 그 후 학생 모델을 통해 적응형 지식 증류를 수행합니다. 여기서 무작위 마스킹은 공간적 코스(Cox) 프로세스를 통해 모델되고, 이는 MAE와 비교하여 목표가 더 잘 마스크링 되도록 설계되었습니다. 적응형 지식 증류는 GIoU 손실의 평균에서의 편차를 기반으로 하고, 교사 모델의 무거운 특징을 학생 모델이 튜닝할 수 있도록 돕습니다.
- **Performance Highlights**: 실험 결과, ORTrack-DeiT는 평균 정밀도(Precision) 85.6%와 성공률(Success Rate) 65.0%로 모든 경쟁 추적기를 능가하였습니다. 게다가, 학생 모델인 ORTrack-D-DeiT는 CPU에서 16.8%의 속도 향상과 GPU에서 29.1%의 속도 향상을 시현하면서도 약간의 성능 저하만을 보였습니다. 이는 UAV 응용 분야에서 자원 제한 환경에 이상적으로 적합함을 증명합니다.

